'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/','title':"Docs",'content':""});index.add({'id':1,'href':'/docs/shortcodes/','title':"Shortcodes",'content':"꿜 팁~\n"});index.add({'id':2,'href':'/posts/creating-a-new-theme/','title':"Creating a New Theme",'content':"Introduction This tutorial will show you how to create a simple theme in Hugo. I assume that you are familiar with HTML, the bash command line, and that you are comfortable using Markdown to format content. I\u0026rsquo;ll explain how Hugo uses templates and how you can organize your templates to create a theme. I won\u0026rsquo;t cover using CSS to style your theme.\nWe\u0026rsquo;ll start with creating a new site with a very basic template. Then we\u0026rsquo;ll add in a few pages and posts. With small variations on that, you will be able to create many different types of web sites.\nIn this tutorial, commands that you enter will start with the \u0026ldquo;$\u0026rdquo; prompt. The output will follow. Lines that start with \u0026ldquo;#\u0026rdquo; are comments that I\u0026rsquo;ve added to explain a point. When I show updates to a file, the \u0026ldquo;:wq\u0026rdquo; on the last line means to save the file.\nHere\u0026rsquo;s an example:\n## this is a comment $ echo this is a command this is a command ## edit the file $ vi foo.md +++ date = \u0026quot;2014-09-28\u0026quot; title = \u0026quot;creating a new theme\u0026quot; +++ bah and humbug :wq ## show it $ cat foo.md +++ date = \u0026quot;2014-09-28\u0026quot; title = \u0026quot;creating a new theme\u0026quot; +++ bah and humbug $ Some Definitions There are a few concepts that you need to understand before creating a theme.\nSkins Skins are the files responsible for the look and feel of your site. It’s the CSS that controls colors and fonts, it’s the Javascript that determines actions and reactions. It’s also the rules that Hugo uses to transform your content into the HTML that the site will serve to visitors.\nYou have two ways to create a skin. The simplest way is to create it in the layouts/ directory. If you do, then you don’t have to worry about configuring Hugo to recognize it. The first place that Hugo will look for rules and files is in the layouts/ directory so it will always find the skin.\nYour second choice is to create it in a sub-directory of the themes/ directory. If you do, then you must always tell Hugo where to search for the skin. It’s extra work, though, so why bother with it?\nThe difference between creating a skin in layouts/ and creating it in themes/ is very subtle. A skin in layouts/ can’t be customized without updating the templates and static files that it is built from. A skin created in themes/, on the other hand, can be and that makes it easier for other people to use it.\nThe rest of this tutorial will call a skin created in the themes/ directory a theme.\nNote that you can use this tutorial to create a skin in the layouts/ directory if you wish to. The main difference will be that you won’t need to update the site’s configuration file to use a theme.\nThe Home Page The home page, or landing page, is the first page that many visitors to a site see. It is the index.html file in the root directory of the web site. Since Hugo writes files to the public/ directory, our home page is public/index.html.\nSite Configuration File When Hugo runs, it looks for a configuration file that contains settings that override default values for the entire site. The file can use TOML, YAML, or JSON. I prefer to use TOML for my configuration files. If you prefer to use JSON or YAML, you’ll need to translate my examples. You’ll also need to change the name of the file since Hugo uses the extension to determine how to process it.\nHugo translates Markdown files into HTML. By default, Hugo expects to find Markdown files in your content/ directory and template files in your themes/ directory. It will create HTML files in your public/ directory. You can change this by specifying alternate locations in the configuration file.\nContent Content is stored in text files that contain two sections. The first section is the “front matter,” which is the meta-information on the content. The second section contains Markdown that will be converted to HTML.\nFront Matter The front matter is information about the content. Like the configuration file, it can be written in TOML, YAML, or JSON. Unlike the configuration file, Hugo doesn’t use the file’s extension to know the format. It looks for markers to signal the type. TOML is surrounded by “+++”, YAML by “---”, and JSON is enclosed in curly braces. I prefer to use TOML, so you’ll need to translate my examples if you prefer YAML or JSON.\nThe information in the front matter is passed into the template before the content is rendered into HTML.\nMarkdown Content is written in Markdown which makes it easier to create the content. Hugo runs the content through a Markdown engine to create the HTML which will be written to the output file.\nTemplate Files Hugo uses template files to render content into HTML. Template files are a bridge between the content and presentation. Rules in the template define what content is published, where it\u0026rsquo;s published to, and how it will rendered to the HTML file. The template guides the presentation by specifying the style to use.\nThere are three types of templates: single, list, and partial. Each type takes a bit of content as input and transforms it based on the commands in the template.\nHugo uses its knowledge of the content to find the template file used to render the content. If it can’t find a template that is an exact match for the content, it will shift up a level and search from there. It will continue to do so until it finds a matching template or runs out of templates to try. If it can’t find a template, it will use the default template for the site.\nPlease note that you can use the front matter to influence Hugo’s choice of templates.\nSingle Template A single template is used to render a single piece of content. For example, an article or post would be a single piece of content and use a single template.\nList Template A list template renders a group of related content. That could be a summary of recent postings or all articles in a category. List templates can contain multiple groups.\nThe homepage template is a special type of list template. Hugo assumes that the home page of your site will act as the portal for the rest of the content in the site.\nPartial Template A partial template is a template that can be included in other templates. Partial templates must be called using the “partial” template command. They are very handy for rolling up common behavior. For example, your site may have a banner that all pages use. Instead of copying the text of the banner into every single and list template, you could create a partial with the banner in it. That way if you decide to change the banner, you only have to change the partial template.\nCreate a New Site Let\u0026rsquo;s use Hugo to create a new web site. I\u0026rsquo;m a Mac user, so I\u0026rsquo;ll create mine in my home directory, in the Sites folder. If you\u0026rsquo;re using Linux, you might have to create the folder first.\nThe \u0026ldquo;new site\u0026rdquo; command will create a skeleton of a site. It will give you the basic directory structure and a useable configuration file.\n$ hugo new site ~/Sites/zafta $ cd ~/Sites/zafta $ ls -l total 8 drwxr-xr-x 7 quoha staff 238 Sep 29 16:49 . drwxr-xr-x 3 quoha staff 102 Sep 29 16:49 .. drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 archetypes -rw-r--r-- 1 quoha staff 82 Sep 29 16:49 config.toml drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 content drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 layouts drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 static $ Take a look in the content/ directory to confirm that it is empty.\nThe other directories (archetypes/, layouts/, and static/) are used when customizing a theme. That\u0026rsquo;s a topic for a different tutorial, so please ignore them for now.\nGenerate the HTML For the New Site Running the hugo command with no options will read all the available content and generate the HTML files. It will also copy all static files (that\u0026rsquo;s everything that\u0026rsquo;s not content). Since we have an empty site, it won\u0026rsquo;t do much, but it will do it very quickly.\n$ hugo --verbose INFO: 2014/09/29 Using config file: config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html] WARN: 2014/09/29 Unable to locate layout: [404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms $ The \u0026ldquo;--verbose\u0026rdquo; flag gives extra information that will be helpful when we build the template. Every line of the output that starts with \u0026ldquo;INFO:\u0026rdquo; or \u0026ldquo;WARN:\u0026rdquo; is present because we used that flag. The lines that start with \u0026ldquo;WARN:\u0026rdquo; are warning messages. We\u0026rsquo;ll go over them later.\nWe can verify that the command worked by looking at the directory again.\n$ ls -l total 8 drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 archetypes -rw-r--r-- 1 quoha staff 82 Sep 29 16:49 config.toml drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 content drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 layouts drwxr-xr-x 4 quoha staff 136 Sep 29 17:02 public drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 static $ See that new public/ directory? Hugo placed all generated content there. When you\u0026rsquo;re ready to publish your web site, that\u0026rsquo;s the place to start. For now, though, let\u0026rsquo;s just confirm that we have what we\u0026rsquo;d expect from a site with no content.\n$ ls -l public total 16 -rw-r--r-- 1 quoha staff 416 Sep 29 17:02 index.xml -rw-r--r-- 1 quoha staff 262 Sep 29 17:02 sitemap.xml $ Hugo created two XML files, which is standard, but there are no HTML files.\nTest the New Site Verify that you can run the built-in web server. It will dramatically shorten your development cycle if you do. Start it by running the \u0026ldquo;server\u0026rdquo; command. If it is successful, you will see output similar to the following:\n$ hugo server --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html] WARN: 2014/09/29 Unable to locate layout: [404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms Serving pages from /Users/quoha/Sites/zafta/public Web Server is available at http://localhost:1313 Press Ctrl+C to stop Connect to the listed URL (it\u0026rsquo;s on the line that starts with \u0026ldquo;Web Server\u0026rdquo;). If everything is working correctly, you should get a page that shows the following:\nindex.xml sitemap.xml That\u0026rsquo;s a listing of your public/ directory. Hugo didn\u0026rsquo;t create a home page because our site has no content. When there\u0026rsquo;s no index.html file in a directory, the server lists the files in the directory, which is what you should see in your browser.\nLet’s go back and look at those warnings again.\nWARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html] WARN: 2014/09/29 Unable to locate layout: [404.html] That second warning is easier to explain. We haven’t created a template to be used to generate “page not found errors.” The 404 message is a topic for a separate tutorial.\nNow for the first warning. It is for the home page. You can tell because the first layout that it looked for was “index.html.” That’s only used by the home page.\nI like that the verbose flag causes Hugo to list the files that it\u0026rsquo;s searching for. For the home page, they are index.html, _default/list.html, and _default/single.html. There are some rules that we\u0026rsquo;ll cover later that explain the names and paths. For now, just remember that Hugo couldn\u0026rsquo;t find a template for the home page and it told you so.\nAt this point, you\u0026rsquo;ve got a working installation and site that we can build upon. All that’s left is to add some content and a theme to display it.\nCreate a New Theme Hugo doesn\u0026rsquo;t ship with a default theme. There are a few available (I counted a dozen when I first installed Hugo) and Hugo comes with a command to create new themes.\nWe\u0026rsquo;re going to create a new theme called \u0026ldquo;zafta.\u0026rdquo; Since the goal of this tutorial is to show you how to fill out the files to pull in your content, the theme will not contain any CSS. In other words, ugly but functional.\nAll themes have opinions on content and layout. For example, Zafta uses \u0026ldquo;post\u0026rdquo; over \u0026ldquo;blog\u0026rdquo;. Strong opinions make for simpler templates but differing opinions make it tougher to use themes. When you build a theme, consider using the terms that other themes do.\nCreate a Skeleton Use the hugo \u0026ldquo;new\u0026rdquo; command to create the skeleton of a theme. This creates the directory structure and places empty files for you to fill out.\n$ hugo new theme zafta $ ls -l total 8 drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 archetypes -rw-r--r-- 1 quoha staff 82 Sep 29 16:49 config.toml drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 content drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 layouts drwxr-xr-x 4 quoha staff 136 Sep 29 17:02 public drwxr-xr-x 2 quoha staff 68 Sep 29 16:49 static drwxr-xr-x 3 quoha staff 102 Sep 29 17:31 themes $ find themes -type f | xargs ls -l -rw-r--r-- 1 quoha staff 1081 Sep 29 17:31 themes/zafta/LICENSE.md -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/archetypes/default.md -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/list.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/single.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/footer.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/header.html -rw-r--r-- 1 quoha staff 93 Sep 29 17:31 themes/zafta/theme.toml $ The skeleton includes templates (the files ending in .html), license file, a description of your theme (the theme.toml file), and an empty archetype.\nPlease take a minute to fill out the theme.toml and LICENSE.md files. They\u0026rsquo;re optional, but if you\u0026rsquo;re going to be distributing your theme, it tells the world who to praise (or blame). It\u0026rsquo;s also nice to declare the license so that people will know how they can use the theme.\n$ vi themes/zafta/theme.toml author = \u0026quot;michael d henderson\u0026quot; description = \u0026quot;a minimal working template\u0026quot; license = \u0026quot;MIT\u0026quot; name = \u0026quot;zafta\u0026quot; source_repo = \u0026quot;\u0026quot; tags = [\u0026quot;tags\u0026quot;, \u0026quot;categories\u0026quot;] :wq ## also edit themes/zafta/LICENSE.md and change ## the bit that says \u0026quot;YOUR_NAME_HERE\u0026quot; Note that the the skeleton\u0026rsquo;s template files are empty. Don\u0026rsquo;t worry, we\u0026rsquo;ll be changing that shortly.\n$ find themes/zafta -name '*.html' | xargs ls -l -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/list.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/single.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/footer.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/partials/header.html $ Update the Configuration File to Use the Theme Now that we\u0026rsquo;ve got a theme to work with, it\u0026rsquo;s a good idea to add the theme name to the configuration file. This is optional, because you can always add \u0026ldquo;-t zafta\u0026rdquo; on all your commands. I like to put it the configuration file because I like shorter command lines. If you don\u0026rsquo;t put it in the configuration file or specify it on the command line, you won\u0026rsquo;t use the template that you\u0026rsquo;re expecting to.\nEdit the file to add the theme, add a title for the site, and specify that all of our content will use the TOML format.\n$ vi config.toml theme = \u0026quot;zafta\u0026quot; baseurl = \u0026quot;\u0026quot; languageCode = \u0026quot;en-us\u0026quot; title = \u0026quot;zafta - totally refreshing\u0026quot; MetaDataFormat = \u0026quot;toml\u0026quot; :wq $ Generate the Site Now that we have an empty theme, let\u0026rsquo;s generate the site again.\n$ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms $ Did you notice that the output is different? The warning message for the home page has disappeared and we have an additional information line saying that Hugo is syncing from the theme\u0026rsquo;s directory.\nLet\u0026rsquo;s check the public/ directory to see what Hugo\u0026rsquo;s created.\n$ ls -l public total 16 drwxr-xr-x 2 quoha staff 68 Sep 29 17:56 css -rw-r--r-- 1 quoha staff 0 Sep 29 17:56 index.html -rw-r--r-- 1 quoha staff 407 Sep 29 17:56 index.xml drwxr-xr-x 2 quoha staff 68 Sep 29 17:56 js -rw-r--r-- 1 quoha staff 243 Sep 29 17:56 sitemap.xml $ Notice four things:\n Hugo created a home page. This is the file public/index.html. Hugo created a css/ directory. Hugo created a js/ directory. Hugo claimed that it created 0 pages. It created a file and copied over static files, but didn\u0026rsquo;t create any pages. That\u0026rsquo;s because it considers a \u0026ldquo;page\u0026rdquo; to be a file created directly from a content file. It doesn\u0026rsquo;t count things like the index.html files that it creates automatically.  The Home Page Hugo supports many different types of templates. The home page is special because it gets its own type of template and its own template file. The file, layouts/index.html, is used to generate the HTML for the home page. The Hugo documentation says that this is the only required template, but that depends. Hugo\u0026rsquo;s warning message shows that it looks for three different templates:\nWARN: 2014/09/29 Unable to locate layout: [index.html _default/list.html _default/single.html] If it can\u0026rsquo;t find any of these, it completely skips creating the home page. We noticed that when we built the site without having a theme installed.\nWhen Hugo created our theme, it created an empty home page template. Now, when we build the site, Hugo finds the template and uses it to generate the HTML for the home page. Since the template file is empty, the HTML file is empty, too. If the template had any rules in it, then Hugo would have used them to generate the home page.\n$ find . -name index.html | xargs ls -l -rw-r--r-- 1 quoha staff 0 Sep 29 20:21 ./public/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 ./themes/zafta/layouts/index.html $ The Magic of Static Hugo does two things when generating the site. It uses templates to transform content into HTML and it copies static files into the site. Unlike content, static files are not transformed. They are copied exactly as they are.\nHugo assumes that your site will use both CSS and JavaScript, so it creates directories in your theme to hold them. Remember opinions? Well, Hugo\u0026rsquo;s opinion is that you\u0026rsquo;ll store your CSS in a directory named css/ and your JavaScript in a directory named js/. If you don\u0026rsquo;t like that, you can change the directory names in your theme directory or even delete them completely. Hugo\u0026rsquo;s nice enough to offer its opinion, then behave nicely if you disagree.\n$ find themes/zafta -type d | xargs ls -ld drwxr-xr-x 7 quoha staff 238 Sep 29 17:38 themes/zafta drwxr-xr-x 3 quoha staff 102 Sep 29 17:31 themes/zafta/archetypes drwxr-xr-x 5 quoha staff 170 Sep 29 17:31 themes/zafta/layouts drwxr-xr-x 4 quoha staff 136 Sep 29 17:31 themes/zafta/layouts/_default drwxr-xr-x 4 quoha staff 136 Sep 29 17:31 themes/zafta/layouts/partials drwxr-xr-x 4 quoha staff 136 Sep 29 17:31 themes/zafta/static drwxr-xr-x 2 quoha staff 68 Sep 29 17:31 themes/zafta/static/css drwxr-xr-x 2 quoha staff 68 Sep 29 17:31 themes/zafta/static/js $ The Theme Development Cycle When you\u0026rsquo;re working on a theme, you will make changes in the theme\u0026rsquo;s directory, rebuild the site, and check your changes in the browser. Hugo makes this very easy:\n Purge the public/ directory. Run the built in web server in watch mode. Open your site in a browser. Update the theme. Glance at your browser window to see changes. Return to step 4.  I’ll throw in one more opinion: never work on a theme on a live site. Always work on a copy of your site. Make changes to your theme, test them, then copy them up to your site. For added safety, use a tool like Git to keep a revision history of your content and your theme. Believe me when I say that it is too easy to lose both your mind and your changes.\nCheck the main Hugo site for information on using Git with Hugo.\nPurge the public/ Directory When generating the site, Hugo will create new files and update existing ones in the public/ directory. It will not delete files that are no longer used. For example, files that were created in the wrong directory or with the wrong title will remain. If you leave them, you might get confused by them later. I recommend cleaning out your site prior to generating it.\nNote: If you\u0026rsquo;re building on an SSD, you should ignore this. Churning on a SSD can be costly.\nHugo\u0026rsquo;s Watch Option Hugo\u0026rsquo;s \u0026ldquo;--watch\u0026rdquo; option will monitor the content/ and your theme directories for changes and rebuild the site automatically.\nLive Reload Hugo\u0026rsquo;s built in web server supports live reload. As pages are saved on the server, the browser is told to refresh the page. Usually, this happens faster than you can say, \u0026ldquo;Wow, that\u0026rsquo;s totally amazing.\u0026rdquo;\nDevelopment Commands Use the following commands as the basis for your workflow.\n## purge old files. hugo will recreate the public directory. ## $ rm -rf public ## ## run hugo in watch mode ## $ hugo server --watch --verbose Here\u0026rsquo;s sample output showing Hugo detecting a change to the template for the home page. Once generated, the web browser automatically reloaded the page. I\u0026rsquo;ve said this before, it\u0026rsquo;s amazing.\n$ rm -rf public $ hugo server --watch --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms Watching for changes in /Users/quoha/Sites/zafta/content Serving pages from /Users/quoha/Sites/zafta/public Web Server is available at http://localhost:1313 Press Ctrl+C to stop INFO: 2014/09/29 File System Event: [\u0026quot;/Users/quoha/Sites/zafta/themes/zafta/layouts/index.html\u0026quot;: MODIFY|ATTRIB] Change detected, rebuilding site WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 1 ms Update the Home Page Template The home page is one of a few special pages that Hugo creates automatically. As mentioned earlier, it looks for one of three files in the theme\u0026rsquo;s layout/ directory:\n index.html _default/list.html _default/single.html  We could update one of the default templates, but a good design decision is to update the most specific template available. That\u0026rsquo;s not a hard and fast rule (in fact, we\u0026rsquo;ll break it a few times in this tutorial), but it is a good generalization.\nMake a Static Home Page Right now, that page is empty because we don\u0026rsquo;t have any content and we don\u0026rsquo;t have any logic in the template. Let\u0026rsquo;s change that by adding some text to the template.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;hugo says hello!\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq $ Build the web site and then verify the results.\n$ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 0 pages created 0 tags created 0 categories created in 2 ms $ find public -type f -name '*.html' | xargs ls -l -rw-r--r-- 1 quoha staff 78 Sep 29 21:26 public/index.html $ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;hugo says hello!\u0026lt;/p\u0026gt; \u0026lt;/html\u0026gt; Live Reload Note: If you\u0026rsquo;re running the server with the --watch option, you\u0026rsquo;ll see different content in the file:\n$ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;hugo says hello!\u0026lt;/p\u0026gt; \u0026lt;script\u0026gt;document.write('\u0026lt;script src=\u0026quot;http://' + (location.host || 'localhost').split(':')[0] + ':1313/livereload.js?mindelay=10\u0026quot;\u0026gt;\u0026lt;/' + 'script\u0026gt;')\u0026lt;/script\u0026gt;\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; When you use --watch, the Live Reload script is added by Hugo. Look for live reload in the documentation to see what it does and how to disable it.\nBuild a \u0026ldquo;Dynamic\u0026rdquo; Home Page \u0026ldquo;Dynamic home page?\u0026rdquo; Hugo\u0026rsquo;s a static web site generator, so this seems an odd thing to say. I mean let\u0026rsquo;s have the home page automatically reflect the content in the site every time Hugo builds it. We\u0026rsquo;ll use iteration in the template to do that.\nCreate New Posts Now that we have the home page generating static content, let\u0026rsquo;s add some content to the site. We\u0026rsquo;ll display these posts as a list on the home page and on their own page, too.\nHugo has a command to generate a skeleton post, just like it does for sites and themes.\n$ hugo --verbose new post/first.md INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 attempting to create post/first.md of post INFO: 2014/09/29 curpath: /Users/quoha/Sites/zafta/themes/zafta/archetypes/default.md ERROR: 2014/09/29 Unable to Cast \u0026lt;nil\u0026gt; to map[string]interface{} $ That wasn\u0026rsquo;t very nice, was it?\nThe \u0026ldquo;new\u0026rdquo; command uses an archetype to create the post file. Hugo created an empty default archetype file, but that causes an error when there\u0026rsquo;s a theme. For me, the workaround was to create an archetypes file specifically for the post type.\n$ vi themes/zafta/archetypes/post.md +++ Description = \u0026quot;\u0026quot; Tags = [] Categories = [] +++ :wq $ find themes/zafta/archetypes -type f | xargs ls -l -rw-r--r-- 1 quoha staff 0 Sep 29 21:53 themes/zafta/archetypes/default.md -rw-r--r-- 1 quoha staff 51 Sep 29 21:54 themes/zafta/archetypes/post.md $ hugo --verbose new post/first.md INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 attempting to create post/first.md of post INFO: 2014/09/29 curpath: /Users/quoha/Sites/zafta/themes/zafta/archetypes/post.md INFO: 2014/09/29 creating /Users/quoha/Sites/zafta/content/post/first.md /Users/quoha/Sites/zafta/content/post/first.md created $ hugo --verbose new post/second.md INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 attempting to create post/second.md of post INFO: 2014/09/29 curpath: /Users/quoha/Sites/zafta/themes/zafta/archetypes/post.md INFO: 2014/09/29 creating /Users/quoha/Sites/zafta/content/post/second.md /Users/quoha/Sites/zafta/content/post/second.md created $ ls -l content/post total 16 -rw-r--r-- 1 quoha staff 104 Sep 29 21:54 first.md -rw-r--r-- 1 quoha staff 105 Sep 29 21:57 second.md $ cat content/post/first.md +++ Categories = [] Description = \u0026quot;\u0026quot; Tags = [] date = \u0026quot;2014-09-29T21:54:53-05:00\u0026quot; title = \u0026quot;first\u0026quot; +++ my first post $ cat content/post/second.md +++ Categories = [] Description = \u0026quot;\u0026quot; Tags = [] date = \u0026quot;2014-09-29T21:57:09-05:00\u0026quot; title = \u0026quot;second\u0026quot; +++ my second post $ Build the web site and then verify the results.\n$ rm -rf public $ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 found taxonomies: map[string]string{\u0026quot;category\u0026quot;:\u0026quot;categories\u0026quot;, \u0026quot;tag\u0026quot;:\u0026quot;tags\u0026quot;} WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 2 pages created 0 tags created 0 categories created in 4 ms $ The output says that it created 2 pages. Those are our new posts:\n$ find public -type f -name '*.html' | xargs ls -l -rw-r--r-- 1 quoha staff 78 Sep 29 22:13 public/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:13 public/post/first/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:13 public/post/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:13 public/post/second/index.html $ The new files are empty because because the templates used to generate the content are empty. The homepage doesn\u0026rsquo;t show the new content, either. We have to update the templates to add the posts.\nList and Single Templates In Hugo, we have three major kinds of templates. There\u0026rsquo;s the home page template that we updated previously. It is used only by the home page. We also have \u0026ldquo;single\u0026rdquo; templates which are used to generate output for a single content file. We also have \u0026ldquo;list\u0026rdquo; templates that are used to group multiple pieces of content before generating output.\nGenerally speaking, list templates are named \u0026ldquo;list.html\u0026rdquo; and single templates are named \u0026ldquo;single.html.\u0026rdquo;\nThere are three other types of templates: partials, content views, and terms. We will not go into much detail on these.\nAdd Content to the Homepage The home page will contain a list of posts. Let\u0026rsquo;s update its template to add the posts that we just created. The logic in the template will run every time we build the site.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; {{ range first 10 .Data.Pages }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; {{ end }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq $ Hugo uses the Go template engine. That engine scans the template files for commands which are enclosed between \u0026ldquo;{{\u0026rdquo; and \u0026ldquo;}}\u0026quot;. In our template, the commands are:\n range .Title end  The \u0026ldquo;range\u0026rdquo; command is an iterator. We\u0026rsquo;re going to use it to go through the first ten pages. Every HTML file that Hugo creates is treated as a page, so looping through the list of pages will look at every file that will be created.\nThe \u0026ldquo;.Title\u0026rdquo; command prints the value of the \u0026ldquo;title\u0026rdquo; variable. Hugo pulls it from the front matter in the Markdown file.\nThe \u0026ldquo;end\u0026rdquo; command signals the end of the range iterator. The engine loops back to the top of the iteration when it finds \u0026ldquo;end.\u0026rdquo; Everything between the \u0026ldquo;range\u0026rdquo; and \u0026ldquo;end\u0026rdquo; is evaluated every time the engine goes through the iteration. In this file, that would cause the title from the first ten pages to be output as heading level one.\nIt\u0026rsquo;s helpful to remember that some variables, like .Data, are created before any output files. Hugo loads every content file into the variable and then gives the template a chance to process before creating the HTML files.\nBuild the web site and then verify the results.\n$ rm -rf public $ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 found taxonomies: map[string]string{\u0026quot;tag\u0026quot;:\u0026quot;tags\u0026quot;, \u0026quot;category\u0026quot;:\u0026quot;categories\u0026quot;} WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 2 pages created 0 tags created 0 categories created in 4 ms $ find public -type f -name '*.html' | xargs ls -l -rw-r--r-- 1 quoha staff 94 Sep 29 22:23 public/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:23 public/post/first/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:23 public/post/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:23 public/post/second/index.html $ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;second\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;first\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $ Congratulations, the home page shows the title of the two posts. The posts themselves are still empty, but let\u0026rsquo;s take a moment to appreciate what we\u0026rsquo;ve done. Your template now generates output dynamically. Believe it or not, by inserting the range command inside of those curly braces, you\u0026rsquo;ve learned everything you need to know to build a theme. All that\u0026rsquo;s really left is understanding which template will be used to generate each content file and becoming familiar with the commands for the template engine.\nAnd, if that were entirely true, this tutorial would be much shorter. There are a few things to know that will make creating a new template much easier. Don\u0026rsquo;t worry, though, that\u0026rsquo;s all to come.\nAdd Content to the Posts We\u0026rsquo;re working with posts, which are in the content/post/ directory. That means that their section is \u0026ldquo;post\u0026rdquo; (and if we don\u0026rsquo;t do something weird, their type is also \u0026ldquo;post\u0026rdquo;).\nHugo uses the section and type to find the template file for every piece of content. Hugo will first look for a template file that matches the section or type name. If it can\u0026rsquo;t find one, then it will look in the _default/ directory. There are some twists that we\u0026rsquo;ll cover when we get to categories and tags, but for now we can assume that Hugo will try post/single.html, then _default/single.html.\nNow that we know the search rule, let\u0026rsquo;s see what we actually have available:\n$ find themes/zafta -name single.html | xargs ls -l -rw-r--r-- 1 quoha staff 132 Sep 29 17:31 themes/zafta/layouts/_default/single.html We could create a new template, post/single.html, or change the default. Since we don\u0026rsquo;t know of any other content types, let\u0026rsquo;s start with updating the default.\nRemember, any content that we haven\u0026rsquo;t created a template for will end up using this template. That can be good or bad. Bad because I know that we\u0026rsquo;re going to be adding different types of content and we\u0026rsquo;re going to end up undoing some of the changes we\u0026rsquo;ve made. It\u0026rsquo;s good because we\u0026rsquo;ll be able to see immediate results. It\u0026rsquo;s also good to start here because we can start to build the basic layout for the site. As we add more content types, we\u0026rsquo;ll refactor this file and move logic around. Hugo makes that fairly painless, so we\u0026rsquo;ll accept the cost and proceed.\nPlease see the Hugo documentation on template rendering for all the details on determining which template to use. And, as the docs mention, if you\u0026rsquo;re building a single page application (SPA) web site, you can delete all of the other templates and work with just the default single page. That\u0026rsquo;s a refreshing amount of joy right there.\nUpdate the Template File $ vi themes/zafta/layouts/_default/single.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;{{ .Title }}\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; {{ .Content }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq $ Build the web site and verify the results.\n$ rm -rf public $ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 found taxonomies: map[string]string{\u0026quot;tag\u0026quot;:\u0026quot;tags\u0026quot;, \u0026quot;category\u0026quot;:\u0026quot;categories\u0026quot;} WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 2 pages created 0 tags created 0 categories created in 4 ms $ find public -type f -name '*.html' | xargs ls -l -rw-r--r-- 1 quoha staff 94 Sep 29 22:40 public/index.html -rw-r--r-- 1 quoha staff 125 Sep 29 22:40 public/post/first/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:40 public/post/index.html -rw-r--r-- 1 quoha staff 128 Sep 29 22:40 public/post/second/index.html $ cat public/post/first/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;first\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;first\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;my first post\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $ cat public/post/second/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;second\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;second\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;my second post\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $ Notice that the posts now have content. You can go to localhost:1313/post/first to verify.\nLinking to Content The posts are on the home page. Let\u0026rsquo;s add a link from there to the post. Since this is the home page, we\u0026rsquo;ll update its template.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; {{ range first 10 .Data.Pages }} \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026quot;{{ .Permalink }}\u0026quot;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; {{ end }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Build the web site and verify the results.\n$ rm -rf public $ hugo --verbose INFO: 2014/09/29 Using config file: /Users/quoha/Sites/zafta/config.toml INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/themes/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 syncing from /Users/quoha/Sites/zafta/static/ to /Users/quoha/Sites/zafta/public/ INFO: 2014/09/29 found taxonomies: map[string]string{\u0026quot;tag\u0026quot;:\u0026quot;tags\u0026quot;, \u0026quot;category\u0026quot;:\u0026quot;categories\u0026quot;} WARN: 2014/09/29 Unable to locate layout: [404.html theme/404.html] 0 draft content 0 future content 2 pages created 0 tags created 0 categories created in 4 ms $ find public -type f -name '*.html' | xargs ls -l -rw-r--r-- 1 quoha staff 149 Sep 29 22:44 public/index.html -rw-r--r-- 1 quoha staff 125 Sep 29 22:44 public/post/first/index.html -rw-r--r-- 1 quoha staff 0 Sep 29 22:44 public/post/index.html -rw-r--r-- 1 quoha staff 128 Sep 29 22:44 public/post/second/index.html $ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026quot;/post/second/\u0026quot;\u0026gt;second\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026quot;/post/first/\u0026quot;\u0026gt;first\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; $ Create a Post Listing We have the posts displaying on the home page and on their own page. We also have a file public/post/index.html that is empty. Let\u0026rsquo;s make it show a list of all posts (not just the first ten).\nWe need to decide which template to update. This will be a listing, so it should be a list template. Let\u0026rsquo;s take a quick look and see which list templates are available.\n$ find themes/zafta -name list.html | xargs ls -l -rw-r--r-- 1 quoha staff 0 Sep 29 17:31 themes/zafta/layouts/_default/list.html As with the single post, we have to decide to update _default/list.html or create post/list.html. We still don\u0026rsquo;t have multiple content types, so let\u0026rsquo;s stay consistent and update the default list template.\nCreating Top Level Pages Let\u0026rsquo;s add an \u0026ldquo;about\u0026rdquo; page and display it at the top level (as opposed to a sub-level like we did with posts).\nThe default in Hugo is to use the directory structure of the content/ directory to guide the location of the generated html in the public/ directory. Let\u0026rsquo;s verify that by creating an \u0026ldquo;about\u0026rdquo; page at the top level:\n$ vi content/about.md +++ title = \u0026quot;about\u0026quot; description = \u0026quot;about this site\u0026quot; date = \u0026quot;2014-09-27\u0026quot; slug = \u0026quot;about time\u0026quot; +++ ## about us i'm speechless :wq Generate the web site and verify the results.\n$ find public -name '*.html' | xargs ls -l -rw-rw-r-- 1 mdhender staff 334 Sep 27 15:08 public/about-time/index.html -rw-rw-r-- 1 mdhender staff 527 Sep 27 15:08 public/index.html -rw-rw-r-- 1 mdhender staff 358 Sep 27 15:08 public/post/first-post/index.html -rw-rw-r-- 1 mdhender staff 0 Sep 27 15:08 public/post/index.html -rw-rw-r-- 1 mdhender staff 342 Sep 27 15:08 public/post/second-post/index.html Notice that the page wasn\u0026rsquo;t created at the top level. It was created in a sub-directory named \u0026lsquo;about-time/'. That name came from our slug. Hugo will use the slug to name the generated content. It\u0026rsquo;s a reasonable default, by the way, but we can learn a few things by fighting it for this file.\nOne other thing. Take a look at the home page.\n$ cat public/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026quot;http://localhost:1313/post/theme/\u0026quot;\u0026gt;creating a new theme\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026quot;http://localhost:1313/about-time/\u0026quot;\u0026gt;about\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026quot;http://localhost:1313/post/second-post/\u0026quot;\u0026gt;second\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;h1\u0026gt;\u0026lt;a href=\u0026quot;http://localhost:1313/post/first-post/\u0026quot;\u0026gt;first\u0026lt;/a\u0026gt;\u0026lt;/h1\u0026gt; \u0026lt;script\u0026gt;document.write('\u0026lt;script src=\u0026quot;http://' + (location.host || 'localhost').split(':')[0] + ':1313/livereload.js?mindelay=10\u0026quot;\u0026gt;\u0026lt;/' + 'script\u0026gt;')\u0026lt;/script\u0026gt;\u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Notice that the \u0026ldquo;about\u0026rdquo; link is listed with the posts? That\u0026rsquo;s not desirable, so let\u0026rsquo;s change that first.\n$ vi themes/zafta/layouts/index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;posts\u0026lt;/h1\u0026gt; {{ range first 10 .Data.Pages }} {{ if eq .Type \u0026quot;post\u0026quot;}} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026quot;{{ .Permalink }}\u0026quot;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} {{ end }} \u0026lt;h1\u0026gt;pages\u0026lt;/h1\u0026gt; {{ range .Data.Pages }} {{ if eq .Type \u0026quot;page\u0026quot; }} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026quot;{{ .Permalink }}\u0026quot;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} {{ end }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq Generate the web site and verify the results. The home page has two sections, posts and pages, and each section has the right set of headings and links in it.\nBut, that about page still renders to about-time/index.html.\n$ find public -name '*.html' | xargs ls -l -rw-rw-r-- 1 mdhender staff 334 Sep 27 15:33 public/about-time/index.html -rw-rw-r-- 1 mdhender staff 645 Sep 27 15:33 public/index.html -rw-rw-r-- 1 mdhender staff 358 Sep 27 15:33 public/post/first-post/index.html -rw-rw-r-- 1 mdhender staff 0 Sep 27 15:33 public/post/index.html -rw-rw-r-- 1 mdhender staff 342 Sep 27 15:33 public/post/second-post/index.html Knowing that hugo is using the slug to generate the file name, the simplest solution is to change the slug. Let\u0026rsquo;s do it the hard way and change the permalink in the configuration file.\n$ vi config.toml [permalinks] page = \u0026quot;/:title/\u0026quot; about = \u0026quot;/:filename/\u0026quot; Generate the web site and verify that this didn\u0026rsquo;t work. Hugo lets \u0026ldquo;slug\u0026rdquo; or \u0026ldquo;URL\u0026rdquo; override the permalinks setting in the configuration file. Go ahead and comment out the slug in content/about.md, then generate the web site to get it to be created in the right place.\nSharing Templates If you\u0026rsquo;ve been following along, you probably noticed that posts have titles in the browser and the home page doesn\u0026rsquo;t. That\u0026rsquo;s because we didn\u0026rsquo;t put the title in the home page\u0026rsquo;s template (layouts/index.html). That\u0026rsquo;s an easy thing to do, but let\u0026rsquo;s look at a different option.\nWe can put the common bits into a shared template that\u0026rsquo;s stored in the themes/zafta/layouts/partials/ directory.\nCreate the Header and Footer Partials In Hugo, a partial is a sugar-coated template. Normally a template reference has a path specified. Partials are different. Hugo searches for them along a TODO defined search path. This makes it easier for end-users to override the theme\u0026rsquo;s presentation.\n$ vi themes/zafta/layouts/partials/header.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;{{ .Title }}\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; :wq $ vi themes/zafta/layouts/partials/footer.html \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; :wq Update the Home Page Template to Use the Partials The most noticeable difference between a template call and a partials call is the lack of path:\n{{ template \u0026quot;theme/partials/header.html\u0026quot; . }} versus\n{{ partial \u0026quot;header.html\u0026quot; . }} Both pass in the context.\nLet\u0026rsquo;s change the home page template to use these new partials.\n$ vi themes/zafta/layouts/index.html {{ partial \u0026quot;header.html\u0026quot; . }} \u0026lt;h1\u0026gt;posts\u0026lt;/h1\u0026gt; {{ range first 10 .Data.Pages }} {{ if eq .Type \u0026quot;post\u0026quot;}} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026quot;{{ .Permalink }}\u0026quot;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} {{ end }} \u0026lt;h1\u0026gt;pages\u0026lt;/h1\u0026gt; {{ range .Data.Pages }} {{ if or (eq .Type \u0026quot;page\u0026quot;) (eq .Type \u0026quot;about\u0026quot;) }} \u0026lt;h2\u0026gt;\u0026lt;a href=\u0026quot;{{ .Permalink }}\u0026quot;\u0026gt;{{ .Type }} - {{ .Title }} - {{ .RelPermalink }}\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt; {{ end }} {{ end }} {{ partial \u0026quot;footer.html\u0026quot; . }} :wq Generate the web site and verify the results. The title on the home page is now \u0026ldquo;your title here\u0026rdquo;, which comes from the \u0026ldquo;title\u0026rdquo; variable in the config.toml file.\nUpdate the Default Single Template to Use the Partials $ vi themes/zafta/layouts/_default/single.html {{ partial \u0026quot;header.html\u0026quot; . }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; {{ .Content }} {{ partial \u0026quot;footer.html\u0026quot; . }} :wq Generate the web site and verify the results. The title on the posts and the about page should both reflect the value in the markdown file.\nAdd “Date Published” to Posts It\u0026rsquo;s common to have posts display the date that they were written or published, so let\u0026rsquo;s add that. The front matter of our posts has a variable named \u0026ldquo;date.\u0026rdquo; It\u0026rsquo;s usually the date the content was created, but let\u0026rsquo;s pretend that\u0026rsquo;s the value we want to display.\nAdd “Date Published” to the Template We\u0026rsquo;ll start by updating the template used to render the posts. The template code will look like:\n{{ .Date.Format \u0026quot;Mon, Jan 2, 2006\u0026quot; }} Posts use the default single template, so we\u0026rsquo;ll change that file.\n$ vi themes/zafta/layouts/_default/single.html {{ partial \u0026quot;header.html\u0026quot; . }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;{{ .Date.Format \u0026quot;Mon, Jan 2, 2006\u0026quot; }}\u0026lt;/h2\u0026gt; {{ .Content }} {{ partial \u0026quot;footer.html\u0026quot; . }} :wq Generate the web site and verify the results. The posts now have the date displayed in them. There\u0026rsquo;s a problem, though. The \u0026ldquo;about\u0026rdquo; page also has the date displayed.\nAs usual, there are a couple of ways to make the date display only on posts. We could do an \u0026ldquo;if\u0026rdquo; statement like we did on the home page. Another way would be to create a separate template for posts.\nThe \u0026ldquo;if\u0026rdquo; solution works for sites that have just a couple of content types. It aligns with the principle of \u0026ldquo;code for today,\u0026rdquo; too.\nLet\u0026rsquo;s assume, though, that we\u0026rsquo;ve made our site so complex that we feel we have to create a new template type. In Hugo-speak, we\u0026rsquo;re going to create a section template.\nLet\u0026rsquo;s restore the default single template before we forget.\n$ mkdir themes/zafta/layouts/post $ vi themes/zafta/layouts/_default/single.html {{ partial \u0026quot;header.html\u0026quot; . }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; {{ .Content }} {{ partial \u0026quot;footer.html\u0026quot; . }} :wq Now we\u0026rsquo;ll update the post\u0026rsquo;s version of the single template. If you remember Hugo\u0026rsquo;s rules, the template engine will use this version over the default.\n$ vi themes/zafta/layouts/post/single.html {{ partial \u0026quot;header.html\u0026quot; . }} \u0026lt;h1\u0026gt;{{ .Title }}\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;{{ .Date.Format \u0026quot;Mon, Jan 2, 2006\u0026quot; }}\u0026lt;/h2\u0026gt; {{ .Content }} {{ partial \u0026quot;footer.html\u0026quot; . }} :wq Note that we removed the date logic from the default template and put it in the post template. Generate the web site and verify the results. Posts have dates and the about page doesn\u0026rsquo;t.\nDon\u0026rsquo;t Repeat Yourself DRY is a good design goal and Hugo does a great job supporting it. Part of the art of a good template is knowing when to add a new template and when to update an existing one. While you\u0026rsquo;re figuring that out, accept that you\u0026rsquo;ll be doing some refactoring. Hugo makes that easy and fast, so it\u0026rsquo;s okay to delay splitting up a template.\n"});index.add({'id':3,'href':'/posts/migrate-from-jekyll/','title':"Migrate to Hugo from Jekyll",'content':"Move static content to static Jekyll has a rule that any directory not starting with _ will be copied as-is to the _site output. Hugo keeps all static content under static. You should therefore move it all there. With Jekyll, something that looked like\n▾ \u0026lt;root\u0026gt;/ ▾ images/ logo.png  should become\n▾ \u0026lt;root\u0026gt;/ ▾ static/ ▾ images/ logo.png  Additionally, you\u0026rsquo;ll want any files that should reside at the root (such as CNAME) to be moved to static.\nCreate your Hugo configuration file Hugo can read your configuration as JSON, YAML or TOML. Hugo supports parameters custom configuration too. Refer to the Hugo configuration documentation for details.\nSet your configuration publish folder to _site The default is for Jekyll to publish to _site and for Hugo to publish to public. If, like me, you have _site mapped to a git submodule on the gh-pages branch, you\u0026rsquo;ll want to do one of two alternatives:\n  Change your submodule to point to map gh-pages to public instead of _site (recommended).\n git submodule deinit _site git rm _site git submodule add -b gh-pages git@github.com:your-username/your-repo.git public    Or, change the Hugo configuration to use _site instead of public.\n { .. \u0026quot;publishdir\u0026quot;: \u0026quot;_site\u0026quot;, .. }    Convert Jekyll templates to Hugo templates That\u0026rsquo;s the bulk of the work right here. The documentation is your friend. You should refer to Jekyll\u0026rsquo;s template documentation if you need to refresh your memory on how you built your blog and Hugo\u0026rsquo;s template to learn Hugo\u0026rsquo;s way.\nAs a single reference data point, converting my templates for heyitsalex.net took me no more than a few hours.\nConvert Jekyll plugins to Hugo shortcodes Jekyll has plugins; Hugo has shortcodes. It\u0026rsquo;s fairly trivial to do a port.\nImplementation As an example, I was using a custom image_tag plugin to generate figures with caption when running Jekyll. As I read about shortcodes, I found Hugo had a nice built-in shortcode that does exactly the same thing.\nJekyll\u0026rsquo;s plugin:\nmodule Jekyll class ImageTag \u0026lt; Liquid::Tag @url = nil @caption = nil @class = nil @link = nil // Patterns IMAGE_URL_WITH_CLASS_AND_CAPTION = IMAGE_URL_WITH_CLASS_AND_CAPTION_AND_LINK = /(\\w+)(\\s+)((https?:\\/\\/|\\/)(\\S+))(\\s+)\u0026quot;(.*?)\u0026quot;(\\s+)-\u0026gt;((https?:\\/\\/|\\/)(\\S+))(\\s*)/i IMAGE_URL_WITH_CAPTION = /((https?:\\/\\/|\\/)(\\S+))(\\s+)\u0026quot;(.*?)\u0026quot;/i IMAGE_URL_WITH_CLASS = /(\\w+)(\\s+)((https?:\\/\\/|\\/)(\\S+))/i IMAGE_URL = /((https?:\\/\\/|\\/)(\\S+))/i def initialize(tag_name, markup, tokens) super if markup =~ IMAGE_URL_WITH_CLASS_AND_CAPTION_AND_LINK @class = $1 @url = $3 @caption = $7 @link = $9 elsif markup =~ IMAGE_URL_WITH_CLASS_AND_CAPTION @class = $1 @url = $3 @caption = $7 elsif markup =~ IMAGE_URL_WITH_CAPTION @url = $1 @caption = $5 elsif markup =~ IMAGE_URL_WITH_CLASS @class = $1 @url = $3 elsif markup =~ IMAGE_URL @url = $1 end end def render(context) if @class source = \u0026quot;\u0026lt;figure class='#{@class}'\u0026gt;\u0026quot; else source = \u0026quot;\u0026lt;figure\u0026gt;\u0026quot; end if @link source += \u0026quot;\u0026lt;a href=\\\u0026quot;#{@link}\\\u0026quot;\u0026gt;\u0026quot; end source += \u0026quot;\u0026lt;img src=\\\u0026quot;#{@url}\\\u0026quot;\u0026gt;\u0026quot; if @link source += \u0026quot;\u0026lt;/a\u0026gt;\u0026quot; end source += \u0026quot;\u0026lt;figcaption\u0026gt;#{@caption}\u0026lt;/figcaption\u0026gt;\u0026quot; if @caption source += \u0026quot;\u0026lt;/figure\u0026gt;\u0026quot; source end end end Liquid::Template.register_tag('image', Jekyll::ImageTag)  is written as this Hugo shortcode:\n\u0026lt;!-- image --\u0026gt; \u0026lt;figure {{ with .Get \u0026quot;class\u0026quot; }}class=\u0026quot;{{.}}\u0026quot;{{ end }}\u0026gt; {{ with .Get \u0026quot;link\u0026quot;}}\u0026lt;a href=\u0026quot;{{.}}\u0026quot;\u0026gt;{{ end }} \u0026lt;img src=\u0026quot;{{ .Get \u0026quot;src\u0026quot; }}\u0026quot; {{ if or (.Get \u0026quot;alt\u0026quot;) (.Get \u0026quot;caption\u0026quot;) }}alt=\u0026quot;{{ with .Get \u0026quot;alt\u0026quot;}}{{.}}{{else}}{{ .Get \u0026quot;caption\u0026quot; }}{{ end }}\u0026quot;{{ end }} /\u0026gt; {{ if .Get \u0026quot;link\u0026quot;}}\u0026lt;/a\u0026gt;{{ end }} {{ if or (or (.Get \u0026quot;title\u0026quot;) (.Get \u0026quot;caption\u0026quot;)) (.Get \u0026quot;attr\u0026quot;)}} \u0026lt;figcaption\u0026gt;{{ if isset .Params \u0026quot;title\u0026quot; }} {{ .Get \u0026quot;title\u0026quot; }}{{ end }} {{ if or (.Get \u0026quot;caption\u0026quot;) (.Get \u0026quot;attr\u0026quot;)}}\u0026lt;p\u0026gt; {{ .Get \u0026quot;caption\u0026quot; }} {{ with .Get \u0026quot;attrlink\u0026quot;}}\u0026lt;a href=\u0026quot;{{.}}\u0026quot;\u0026gt; {{ end }} {{ .Get \u0026quot;attr\u0026quot; }} {{ if .Get \u0026quot;attrlink\u0026quot;}}\u0026lt;/a\u0026gt; {{ end }} \u0026lt;/p\u0026gt; {{ end }} \u0026lt;/figcaption\u0026gt; {{ end }} \u0026lt;/figure\u0026gt; \u0026lt;!-- image --\u0026gt;  Usage I simply changed:\n{% image full http://farm5.staticflickr.com/4136/4829260124_57712e570a_o_d.jpg \u0026quot;One of my favorite touristy-type photos. I secretly waited for the good light while we were \u0026quot;having fun\u0026quot; and took this. Only regret: a stupid pole in the top-left corner of the frame I had to clumsily get rid of at post-processing.\u0026quot; -\u0026gt;http://www.flickr.com/photos/alexnormand/4829260124/in/set-72157624547713078/ %}  to this (this example uses a slightly extended version named fig, different than the built-in figure):\n{{% fig class=\u0026quot;full\u0026quot; src=\u0026quot;http://farm5.staticflickr.com/4136/4829260124_57712e570a_o_d.jpg\u0026quot; title=\u0026quot;One of my favorite touristy-type photos. I secretly waited for the good light while we were having fun and took this. Only regret: a stupid pole in the top-left corner of the frame I had to clumsily get rid of at post-processing.\u0026quot; link=\u0026quot;http://www.flickr.com/photos/alexnormand/4829260124/in/set-72157624547713078/\u0026quot; %}}  As a bonus, the shortcode named parameters are, arguably, more readable.\nFinishing touches Fix content Depending on the amount of customization that was done with each post with Jekyll, this step will require more or less effort. There are no hard and fast rules here except that hugo server --watch is your friend. Test your changes and fix errors as needed.\nClean up You\u0026rsquo;ll want to remove the Jekyll configuration at this point. If you have anything else that isn\u0026rsquo;t used, delete it.\nA practical example in a diff Hey, it\u0026rsquo;s Alex was migrated in less than a father-with-kids day from Jekyll to Hugo. You can see all the changes (and screw-ups) by looking at this diff.\n"});index.add({'id':4,'href':'/posts/','title':"henry",'content':""});index.add({'id':5,'href':'/','title':"Introduction",'content':"Acerbo datus maxime Astris ipse furtiva Est in vagis et Pittheus tu arge accipiter regia iram vocatur nurus. Omnes ut olivae sensit arma sorori deducit, inesset crudus, ego vetuere aliis, modo arsit? Utinam rapta fiducia valuere litora adicit cursu, ad facies  Suis quot vota Ea furtique risere fratres edidit terrae magis. Colla tam mihi tenebat: miseram excita suadent es pecudes iam. Concilio quam velatus posset ait quod nunc! Fragosis suae dextra geruntur functus vulgata.   Tempora nisi nunc Lorem markdownum emicat gestu. Cannis sol pressit ducta. Est Idaei, tremens ausim se tutaeque, illi ulnis hausit, sed, lumina cutem. Quae avis sequens!\nvar panel = ram_design; if (backup + system) { file.readPoint = network_native; sidebar_engine_device(cell_tftp_raster, dual_login_paper.adf_vci.application_reader_design( graphicsNvramCdma, lpi_footer_snmp, integer_model)); }  Locis suis novi cum suoque decidit eadem Idmoniae ripis, at aves, ali missa adest, ut et autem, et ab?\n"});index.add({'id':6,'href':'/posts/basic/browser/','title':"브라우저?",'content':"브라우저 브라우저 역시 소프트웨어. 가장 많이 사용하는 소트웨어.\n주요기능 사용자가 선택한 자원을 서버에 요청하고 브라우저에 표시하는것 자원은 보통 HTML이지만 PDF, 또는 이미지 등 다른 형태일 수 있다. 자원의 주소는 URI에 의해 정해진다.\n구성요소  사용자 인터페이스 : 주소표시줄, 이전/다음 버튼 등 요청한 페이지를 보여주는 창을 제외한 나머지 모든 부분 브라우저 엔진 - 사용자 인터페이스와 렌더릴 엔진 사이의 동작 제어 렌더링 엔진 - 요청한 콘텐츠를 표시. 통신 - 네트워크 호출에 사용 - 플랫폼 독자적인 인터페이스이고 각 플랫폼 하부에서 실행 UI 백엔드 - 콤보 박스와 창 같은 기본적인 장치를 그림. 플랫폼에서 명시하지 않은 일반적인 인터페이스로서 OS 사용자 인터페이스 체계를 사용. 자바스크립트 해석기 - 자바스크립트 코드를 해석하고 실행. 자료 저장소 - 이 부분은 자료를 저장하는 캡슐. 쿠키를 저장하는 것과 같이 모든 종류의 자원을 하드 디스크에 저장할 필요가 있음.   크롬은 대부분의 브라우저와 달리 각 탭마다 별도의 렌더링 엔진 인스턴스를 유지함, 독립적인 프로세스로 처리.  렌더링 엔진 애플 사파리, 크롬 - 웹킷 파이어폭스 - 게코\nhttps://d2.naver.com/helloworld/59361\n"});index.add({'id':7,'href':'/posts/basic/internet/','title':"인터넷이란?",'content':"인터넷이란?? 흔히 말하는 인터넷이란?\n인터넷이란 단어에서 그 의미를 찾을 수 있다.\nInternet = Inter + net\nInter는 \u0026lsquo;상호간의'라는 뜻이고, net은 network을 의미한다.\n즉, 인터넷이란 네트워크간의 상호 연결되어있는 상태를 말한다.\n그렇다면 인터넷은 어떻게 동작할까\u0026hellip;\n인터넷의 동작 원리 "});index.add({'id':8,'href':'/tags/framework/','title':"Framework",'content':""});index.add({'id':9,'href':'/tags/front/','title':"Front",'content':""});index.add({'id':10,'href':'/tags/javascript/','title':"JavaScript",'content':""});index.add({'id':11,'href':'/posts/framework/svelte/sveltejs/','title':"SvelteJS",'content':"기초시작\n컴포넌트 포멧 템플릿 Attributes and props Text expressions 명령어 Element directives 컴포넌트 이벤트 Run time Compile time "});index.add({'id':12,'href':'/tags/','title':"Tags",'content':""});index.add({'id':13,'href':'/docs/categories/','title':"Categories",'content':"카테고리\n"});index.add({'id':14,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/','title':"프로그래밍",'content':"프로그래밍\n"});index.add({'id':15,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/javascript/','title':"Java Script",'content':"자 스\n"});index.add({'id':16,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/springboot/','title':"Spring Boot",'content':"쉘\n"});index.add({'id':17,'href':'/posts/cloud/aws/applications/apigateway/','title':"API Gateway",'content':"API Gateway  It is a fully managed service that makes it easy for developers to publish, maintain, monitor, and secure APIs at any scale.  What can api gateway do?  Expose HTTPS endpoints to define RESTful API Serverless-ly connect to service like lamda \u0026amp; DynamoDB Send each API endpoint to a different target Run efficiently with low cost Scale effortlessly Track and control usage by API key Throttle requests to prevent attacks Connect to CloudWatch to log all requests for monitorinng Maintain multiple versions of your API  Tips  Remeber what api gatway is at a high level API gateway has caching capabilities to increase performance APi gateway is log cost and scales automatically You can throttle API Gateway to prevent attacks You can log results to CloudWatch If you are using Javascript/AJAX that uses multiple domains with API Gateway, ensure that you have enabled CORS on API Gateway  "});index.add({'id':18,'href':'/posts/cloud/aws/applications/summary/','title':"Application Summary",'content':"SQS  SQS is a way to decouple hour infrastructure SQS is pull based, not pushed based. Messages are 256 KB in size. Messages can be kept in the queue from 1 minute to 14 days; the default retention period is 4 days. Standard SQS and FIFO SQS Standard order is not quaranteed and messages can be delivered more than once. FIFO order is strictly maintained and messages are delivered only once. SQS guarantees that your messages will be processed at least once.  SWF vs SQS  SQS has retention period of up to 14 days; with SWF, workflow executions can last up to 1 year. Amazon SWF presents a task-oriented APi, whereas Amazon SQS offers a message-oriented API. Amazon SWF ensures that a task is assigned only once and is never duplicated. With Amazon SQS, you need to handle duplicated messages and may also need to ensure that a message is processed only once. Amazon SWF keeps track of all the tasks and events in an application. With Amazon SQS, need to implement your own application-level tracking, especially if your application uses multiple queues.  SWF actors  Workflow starters Deciders Activity workers  SNS Benefits  Instantaneous, push-based delivery (no polling) Simple APIs and easy integration with applications Flexble message delivery over multiple transport protocols Inexpensive, pay-as-you-go model with no up-front costs Web-based AWS Management Console offers the simplicithy of a point-and-click interface  SNS vs SQS  Both Messaging service SNS - push SQS - polls(Pulls)  Elastic Transcoder  Just rememver that elastic transcoder is a media transcoder in the cloud. It converts media files from their original source format in to different formats that will play on smartphones, tablets, PCs etc  API Gateway  Remeber what api gatway is at a high level API gateway has caching capabilities to increase performance APi gateway is log cost and scales automatically You can throttle API Gateway to prevent attacks You can log results to CloudWatch If you are using Javascript/AJAX that uses multiple domains with API Gateway, ensure that you have enabled CORS on API Gateway  Kinesis  Know the difference between kinesis streams and kinesis firehose. you will be geiven scenario quesions and you must choose the most relevant service. Understand what kineis Analytic is.  Cognito  Federation allows users to authenticate with a Web Identity Provider (Google, Facebook, Amazon)  "});index.add({'id':19,'href':'/posts/cloud/aws/applications/cognito/','title':"Cognito \u0026 Web Identity Federation)",'content':"Web Identity Federation  Web Identity Federation lets you give your users access to AWS resources after they have successfully authenticated with a web-based identify provider like Amazon, Facebook, or Google. Following successful authentication, ther user receives an authentication code from the Web ID provider, which they can trade for temporary AWS security credentials.  Amazon Gognito  Amazon Gognito providers Web Identify Federation  Sign-up and sign-in to your apps Access for guest users Acts as an Identify Broker between your application and Web ID providers, so you don\u0026rsquo;t need to write any additional code. Syncronizes user data for multiple devices Recommanded for all mobile applications AWS services.    User pool \u0026amp; Identify pool Tips    "});index.add({'id':20,'href':'/posts/cloud/aws/applications/elastictranscoder/','title':"ElasticTranscoder",'content':"ElasticTranscoder  Media Transcoder in the cloud Convert media files from their original source format in to different formats that will play on smartphones, tablets, PCs, stc Provides transcoding presets for popular output formats, which means that you don\u0026rsquo;t need to guess about which settings work best on particular devices Pay based on the minutes that you transcode and the resolution at which you transcode.  How we use Elastic Transcoder  S3 bucket -\u0026gt; Lamda -\u0026gt; Elastic Tanscoder -\u0026gt; S3 bucket  Tips Just remember Elastic Transcoder is a media transcoder in the cloud. It convert media files from their original source format in to different formats that will play on multi device\n"});index.add({'id':21,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/javascript/javascript_es6/','title':"ES6 연습환경",'content':"연습환경 만들기 원하는 폴더에서 아래 명령어 입력\n\u0026gt;npm init\n기본 정보들을 입력하고 package.json 이 생성된다.\nBabel CLI 설치\n\u0026gt; npm install --save-dev babel-cli\n위와 같이 package.json 파일에서 설정이 된걸 확인 할 수 있다.\n그리고 \u0026lsquo;start\u0026rsquo;, \u0026lsquo;test\u0026rsquo; 등등 npm 명령어를 등록하면 터미널에서 간단하게 코드를 실행할 수 있다.\n"});index.add({'id':22,'href':'/posts/language/javascript/javascript_es6/','title':"ES6 연습환경",'content':"연습환경 만들기 원하는 폴더에서 아래 명령어 입력\n\u0026gt;npm init\n기본 정보들을 입력하고 package.json 이 생성된다.\nBabel CLI 설치\n\u0026gt; npm install --save-dev babel-cli\n위와 같이 package.json 파일에서 설정이 된걸 확인 할 수 있다.\n그리고 \u0026lsquo;start\u0026rsquo;, \u0026lsquo;test\u0026rsquo; 등등 npm 명령어를 등록하면 터미널에서 간단하게 코드를 실행할 수 있다.\n"});index.add({'id':23,'href':'/posts/cloud/aws/applications/kinesis101/','title':"Kinesis 101",'content':"Streaming data  Puchases from online stores Stock prices Game data Social network data Geospatial data (uber) IOT sensor data  Kinesis  Kinesis is a platform on aws to send your streaming data to. Kinesis makes it easy to load and analze streaming data, and also providing the abilirty for you to build your own custom applications for you business needs.  3 different types  Kinesis Streams Kinesis Firehose Kinesis Analytics  shard  5 transactions per second for reads, up to a maxium total data read rate of 2MB per second and up to 1000 records per second for writes, up to a maximum total data write rate of 1 MB per second (including partition keys)  Tips  Kinesis Streams Kinesis Firehose Kinesis Analytics shard  "});index.add({'id':24,'href':'/tags/react/','title':"React",'content':""});index.add({'id':25,'href':'/posts/cloud/aws/applications/sns/','title':"Simple Notification Service",'content':"SNS SNS is web service that makes easy to set up, operate, and send notification from the cloud. It provides developers with a highly scaleable, flexible, and cost-effective capability to publish message from an application and immediately deliver them to subscribers or other applications.\nSNS Benefits  Instantaneous, push-based delivery (no polling) Simple APIs and easy integration with applications Flexible message delivery over multiple transport protocols Inexpensive, pay-as-you-go model with no up-front costs Web-based AWS management Console offers the simplicity of a point-and-click-interface  SNS vs SQS  Both Messaging Service in AWS SNS - Push SQS - Polls(Pulls)  "});index.add({'id':26,'href':'/posts/cloud/aws/applications/swf/','title':"Simple Work Flow Service",'content':"SWF SWF is a web service that makes it easy to coordinate work across distributed application components. SWF enables applications for a range of use cases, including media processing, web application back-ends, business process workflows, and analytics pipeliens, to be designed as a coordination of tasks.\nSWF vs SQS  SQS has a retention period of up to 14days, with SWF, workflow executions can last up to 1 year. Amozon SWF ensures that a task is assigned only once and is never duplicated. With amazon SQS, you need to handle duplicated message and may also need to ensure that a message is processed only once. Amozon SWF keeps track of all the tasks and events in an application. With amazon SQS, you need to implement your own application-level tracking, especially if your application uses multiple queues.  SWF Actors  Workflow Starters Deciders : control the flow of activity tasks in a workflow execution. Acitivity Workers - Carry out the activity tasks.  "});index.add({'id':27,'href':'/posts/cloud/aws/applications/sqs/','title':"SQS",'content':"SQS SQS is web service that gices you access to a message queue that can be used to store message while waiting for a computer to process them.2\nTwo type queue  Standard Queues (default) Fifo Queues (Complemet Standard queue)  Tips\n  SQS is pull baed, not pushed baed.\n  Messages are 256 kb in size.\n  Message can be kept in the queue from 1 minute to 14 days; the default retnetion period is 4 days.\n  Visibility Time out is the amount of time that the message is invisible in the SQS queue after a reader picks up that message. Provided the job is processed before the visibility time out expires, the message wil then be deleted from the queue.\n  SQS guarantees that your message will be processed at least once.\n  "});index.add({'id':28,'href':'/tags/typsscript/','title':"TypsScript",'content':""});index.add({'id':29,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/javascript/react_hook/','title':"리액트 훅(hook)!",'content':"Hooks 리액트 훅은 함수형 컴포넌트에서도 상태관리를 할 수 있는 useState, 렌더링 직후 작업을 설정하는 useEffect 등의 기능을 제공하여 기존의 함수형 컴포넌트에서 할 수 없었던 다양한 작업을 할 수 있게 한다.\nuseState  함수형 컴포넌트가 가변적인 상태를 갖게 한다.    useState를 Import 하여 사용한다. 이러한 문법을 배열 비구조화 할당 문법이라고 하나보다.. ㅎㅎ  useEffect  리액트 컴포넌트가 렌더링 될 떄마다 특정 작업을 수해하도록 설정할 수 있는 Hook이다.   가장 처음 렌더링 됬을때만 실행하고 업데이트 할때는 필요없을 때  useEffect(() =\u0026gt; { console.log({ value, }); }, []);  특정 값이 업데이트 됬을 때만 수행. [] 안에 검사할 값을 넣어준다.  useEffect(() =\u0026gt; { console.log({ value, }); }, [value]);  컴포넌트가 언마운트 되기 직전 어떤 동작을 수행하고자 할떄  useEffect(() =\u0026gt; { console.log({ value, }); return () =\u0026gt; { console.log('cleanup'); console.log(value ); }; }); useContext  함수형 컴포넌트에서 Context를 더 쉽게 사용.  useReducer  useState 보다 컴포넌트에서 더 다양한 상황에 따라 다양한 상태를 다른 값으로 업데이트해주고 싶을 때 사용하는 Hook  useMemo  useMemo 를 사용하면 함수형 컴포넌트 내부에서 발생하는 연산을 최적화  "});index.add({'id':30,'href':'/posts/language/javascript/react_hook/','title':"리액트 훅(hook)!",'content':"Hooks 리액트 훅은 함수형 컴포넌트에서도 상태관리를 할 수 있는 useState, 렌더링 직후 작업을 설정하는 useEffect 등의 기능을 제공하여 기존의 함수형 컴포넌트에서 할 수 없었던 다양한 작업을 할 수 있게 한다.\nuseState  함수형 컴포넌트가 가변적인 상태를 갖게 한다.    useState를 Import 하여 사용한다. 이러한 문법을 배열 비구조화 할당 문법이라고 하나보다.. ㅎㅎ  useEffect  리액트 컴포넌트가 렌더링 될 떄마다 특정 작업을 수해하도록 설정할 수 있는 Hook이다.   가장 처음 렌더링 됬을때만 실행하고 업데이트 할때는 필요없을 때  useEffect(() =\u0026gt; { console.log({ value, }); }, []);  특정 값이 업데이트 됬을 때만 수행. [] 안에 검사할 값을 넣어준다.  useEffect(() =\u0026gt; { console.log({ value, }); }, [value]);  컴포넌트가 언마운트 되기 직전 어떤 동작을 수행하고자 할떄  useEffect(() =\u0026gt; { console.log({ value, }); return () =\u0026gt; { console.log('cleanup'); console.log(value ); }; }); useContext  함수형 컴포넌트에서 Context를 더 쉽게 사용.  useReducer  useState 보다 컴포넌트에서 더 다양한 상황에 따라 다양한 상태를 다른 값으로 업데이트해주고 싶을 때 사용하는 Hook  useMemo  useMemo 를 사용하면 함수형 컴포넌트 내부에서 발생하는 연산을 최적화  "});index.add({'id':31,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/springboot/batch_init/','title':"스프링 부트배치 디비 설정",'content':" 기본적으로 H2 DB를 사용할 경우엔 해당 테이블을 Boot가 실행될때 자동으로 생성해주지만, MySQL이나 Oracle과 같은 DB를 사용할때는 개발자가 직접 생성  스프링 부트에서는 해당 테이블의 쿼리를 같이 배포하고 있다.\n schema- 검색!! "});index.add({'id':32,'href':'/posts/framework/springboot/batch_init/','title':"스프링 부트배치 디비 설정",'content':" 기본적으로 H2 DB를 사용할 경우엔 해당 테이블을 Boot가 실행될때 자동으로 생성해주지만, MySQL이나 Oracle과 같은 DB를 사용할때는 개발자가 직접 생성  스프링 부트에서는 해당 테이블의 쿼리를 같이 배포하고 있다.\n schema- 검색!! "});index.add({'id':33,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/javascript/typescript_01/','title':"타입스크립트로 리액트 사용하기",'content':""});index.add({'id':34,'href':'/posts/language/javascript/typescript_01/','title':"타입스크립트로 리액트 사용하기",'content':""});index.add({'id':35,'href':'/posts/cloud/aws/vpcs/chaper02/','title':"ACL",'content':"ACL   Your VPC automatically comes with a default network ACL, and by default it allows all outbound and inbound traffic.\n  You can create custom network ACLs. By default, each custom network ACL denies all inbound and outbound traffic untill you add rules\n  Each subnet in your VPC must be associated with a network ACL. If you don\u0026rsquo;t explicitly associate a subnet with a network ACL, the subnet is automatically associated with the default network ACL.\n  Block IP Addresses using network ACLs not Security Groups\n  You can associate a network ACL with multiple subnets; however, a subnet can be associated with only one network ACL at a time. When you associate a network ACL with a subnet, the previous association is removed.\n  Network ACLs contain a numbered list of rules that is evaluated in order, starting with the lowest numbered rule.\n  Network ACLs have separate inbound and outbound rules, and each rule can either allow or deny traffic.\n  Network ACLs are stateless; reponses to allowed inbound traffic are subject to the rules for outbound traffic(and vice versa)\n  "});index.add({'id':36,'href':'/posts/cloud/aws/ha-architecture/chapter02/','title':"Advanced Load Balancers Theory",'content':" Sticky Sessions   Classic Load Balancer routes each request independently to the registered EC2 instance with the smallest load. Sticky sessions allow you to bind a user\u0026rsquo;s session to a specific EC2 instance. This ensures that all requests from the user during the session are sent to the same instance. You can enable Sticky Sessions for application load balancers as well, but the traffic will be sent at the target group level.    Cross Zone Load Balancing\n  Path Patterns\n   You can create a listener with rules to forward requests based on the URL path. This is known as path-based routing. IF you are running microservices, you can route traffic to multiple back-end services using path-based routing. For example, you can route general requests to one target group and requests to render images to another target group.   Tips   Sticky Sessions enable your users to stick to the same EC2 instance. Can be useful if you are storing information locally to that instance. Cross Zone Load Balancing enables you to load balance across multiple availibility zones. Path patterns allow you to direct traffic to different EC2 instances based on the URL contained in the request  "});index.add({'id':37,'href':'/posts/cloud/aws/ha-architecture/chapter03/','title':"Auto Scaling Groups",'content':"   "});index.add({'id':38,'href':'/posts/cloud/aws/vpcs/chaper04/','title':"Bastions",'content':"Bastion host   A bastion host is a special purpose computer on a network specifically designed and configured to withstand attacks.\n  A NAT Gateway or NAT instance is used to provide internet traffic to EC2 instances in a private subnets.\n  A Bastion is used to securely adminster EC2 instances(Using SSH or RDP). Bastions are called Jump Boxes in Australia.\n  You cannot use a NAT Gateway as a Bastion host.\n  "});index.add({'id':39,'href':'/posts/cloud/aws/vpcs/chaper05/','title':"Direct Connect",'content':"Direct Connect  Direct Connect directly connects your data center to AWS Useful for high throughput workloads (a lots of network traffic) Or if you need a stable reliable secure connection.  "});index.add({'id':40,'href':'/posts/cloud/aws/ha-architecture/chapter04/','title':"HA Architecture",'content':" HA Sample question.    You have a website that requires a minumum of 6 instances and it must be highly available. You must also be able to tolerate the failure of 1 Availablity Zone.\n  Always Design for failure\n  Use Multiple AZ\u0026rsquo;s and Multiple Regions where ever you can.\n  Know the difference between Multi-AZ and Read Replicas for RDS.\n  Know the difference scailing out and scailing up.\n  Read the question carefully and always consider the code element.\n  Know the different S3 storage classes.\n  "});index.add({'id':41,'href':'/posts/cloud/aws/ha-architecture/chapter01/','title':"Load Balancers Theory",'content':" Elastic Load Balancer    Typs\n Application  HTTP and HTTPS   Network  TCP traffic Use for extreme performance   Classic  HTTP/HTTPS/TCP      504 Error means the gateway has timed out. This means that the application not responding within the idle timeout period.\n  Application Load Balancer\n designed to handle streaming, real-time, and WebSocket workloads in an optimized fashion. Instead of buffering requests and responses, it handles them in streaming fashion.    "});index.add({'id':42,'href':'/posts/cloud/aws/route53/summary/','title':"Route53 summary",'content':"DNS Summary  ELBs do not have pre-defined IPv4 addresses; you resolve to them using a DNS name. Understand the difference between an Alias Record and a CNAME Given the choice, always choose an Alias Record over a CNAME  Common DNS Types  SOA Records NS Records A Records CNAMES MX Records PTR Records  Routing Rolicies that available with Route53  Simple Routing Weighted Routing Latency-based Routing Failover Routing Geolocation Routing Geoproximity Routing (Traffic Flow Only) Multivalue Answer Routing  Health Checks  You can set health checks on individual record sets. If a record set fails a health check it will be removed from Route53 until it passes the health check. You can set SNS notifications to alert you if a health check is failed.  Simple Routing Policy  If you choose the simple routing policy you can only have one record with multiple IP address. If you specify muliple values in a record, Route 53 returns all values to the user in random order.  Weighted Routing Policy Latency Routing Policy Failover Routing Policy Geolocation Routing Policy Geoproximity Routing (Traffic Flow Only)  To use geoproximity routing, you must use Route 53 traffic flow.  Multivalue Answer Policy  Essentially the same as with Simple based routing, except you get Health Checks.  "});index.add({'id':43,'href':'/posts/cloud/aws/vpcs/chaper06/','title':"VPC Endpoints",'content':"VPC Endpoints   A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by PrivateLink without requiring an internet gateway. NAT device, VPN connection, or AWS Direct Connect connection. Instances in your VPC do not require public IP addresses to communicate with reesource in the service. Traffic between your VPC and the other service does not leave the Amazon network.\n  Endpoints are virtual devices. They are horizontally scaled, redundant, and highly available VPC components that allow communication between instances in your VPC and services without imposing availability risks or bandwidth constraints on your network traffic\n  "});index.add({'id':44,'href':'/posts/cloud/aws/vpcs/chaper03/','title':"VPC Flow logs",'content':"Custom VPCs and ELBs VPC Flow logs levels  VPC Subnet Network Interface Level  Not all IP Traffic is monitored.  Traffic generated by instances when they contact the Amazon DNS server. If you use your own DNS server, then all traffic to that DNS server is logged. Traffic generated by a Windows instance for Amazon Windows license activation. DHCP traffic. Traffic to the reserved IP address for the default VPC router.  "});index.add({'id':45,'href':'/posts/cloud/aws/vpcs/chaper01/','title':"VPC overview",'content':"What can we do with a VPC  Launch instances into a subnet of your choosing Assign custom IP address ranges in each subnet Configure route tables between subnets Create insternet gateway and attach it to our VPC Much better security control over your AWS resources Instance security groups Subnet network access control lists (ACLS)  Default VPC vs Custom VPC  Default VPC is user friendly, allowing you to immediately deploy instances. All Subnets in default VPC have a route out to the internet Each EC2 instance has both a public and private IP address.  VPC Peering  Allows you to connect one VPC with another via a direct network route using private IP Addresses. Instances behave as if they were on the same private network You can peer VPC\u0026rsquo;s with other AWS accouhnts as well as with other VPCs in the same account. Peering is in a star configuration : ie 1 central VPC peers with 4 others. NO TRANSITIVE PEERING  NAT instance  When creating a NAT instance, Disable Source/Destination Check on the instance. NAT instances must be in a public subnet. There must be a route out of the private subnet to the NAT instance, in order for this to work. The amount of traffic that NAT instances can suppprot depends on the instance size. If you are bottlenecking, increase the instance size. You can create high availability using Autoscaling Groups, multiple subnets in different AZs, and a script to automate failover. Behind a security Group.  NAT Gatways  Redundant inside the Availability Zone Preferred by the enterprise Starts at 5Gbps and scale currently to 45Gbps No need to patch Not associated with security groups Automatically assigned a public ip address Remeber to update your route tables. No need to disable Source/Destination Checks  "});index.add({'id':46,'href':'/tags/bean/','title':"bean",'content':""});index.add({'id':47,'href':'/tags/ioc/','title':"IoC",'content':""});index.add({'id':48,'href':'/tags/spring/','title':"spring",'content':""});index.add({'id':49,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/springboot/spring_bean_understanding/','title':"Spring bean life cycle",'content':"스프링에서는 빈의 생명주기 관리를 위한 방법을 몇가지를 제공하고 있다. 본 문서에서는 스프링 빈의 생명주기를 알아보고 관련 인터페이스 몇가지를 알아보자.\nSpring bean life cycle overview  Part 1 - 빈 생성이후 사용전까지 각 단계, 전 처리 단계, 각 생성자 호출하여 생성. Part 2 - 빈 삭제 단계  Aware Interfaces 많이 사용되는 인터페이스.\n BeanFactoryAware : setBeanFactory() 제공 BeanNameAware : ThesetVeanName() 빈의 이름을 생성하는 인터페이스 제공 ApplicationContextAware : ThesetApplicationContext() 해당 빈의 ApplicationContext 객체 제공.  exmaple 1 Bean Post Processor BeanPostProcessor 인터페이스는 개발자가 원하는 로직 의존성 처리로직 등을 구현 할 수 있는 콜백 메소드를 정의\n BeanPostProcessor  postProcessBeforeInitialization: 빈의 초기화 전 수행  InitializingBean’s afterPropertiesSet or a custom init-method.\n  postProcessAfterInitialization: 빈 초기화 후 수행  Spring calls this method after any bean initialization callbacks.\n     InitializingBean and DisposableBean Callback Interfaces  InitializingBean  afterPropertiesSet 메소드 선언 , 초기화 로직 작성 가능.   DisposableBean  destroy 메서드 선언, 빈의 삭제와 관련 코드 클린업    "});index.add({'id':50,'href':'/posts/framework/springboot/spring_bean_understanding/','title':"Spring bean life cycle",'content':"스프링에서는 빈의 생명주기 관리를 위한 방법을 몇가지를 제공하고 있다. 본 문서에서는 스프링 빈의 생명주기를 알아보고 관련 인터페이스 몇가지를 알아보자.\nSpring bean life cycle overview  Part 1 - 빈 생성이후 사용전까지 각 단계, 전 처리 단계, 각 생성자 호출하여 생성. Part 2 - 빈 삭제 단계  Aware Interfaces 많이 사용되는 인터페이스.\n BeanFactoryAware : setBeanFactory() 제공 BeanNameAware : ThesetVeanName() 빈의 이름을 생성하는 인터페이스 제공 ApplicationContextAware : ThesetApplicationContext() 해당 빈의 ApplicationContext 객체 제공.  exmaple 1 Bean Post Processor BeanPostProcessor 인터페이스는 개발자가 원하는 로직 의존성 처리로직 등을 구현 할 수 있는 콜백 메소드를 정의\n BeanPostProcessor  postProcessBeforeInitialization: 빈의 초기화 전 수행  InitializingBean’s afterPropertiesSet or a custom init-method.\n  postProcessAfterInitialization: 빈 초기화 후 수행  Spring calls this method after any bean initialization callbacks.\n     InitializingBean and DisposableBean Callback Interfaces  InitializingBean  afterPropertiesSet 메소드 선언 , 초기화 로직 작성 가능.   DisposableBean  destroy 메서드 선언, 빈의 삭제와 관련 코드 클린업    "});index.add({'id':51,'href':'/posts/os/common/posix/','title':"POSIX",'content':" POSIX(포직스)  포직스는 유닉스 운영체계에 기반을 두고 있는 이식 가능 운영 체제 인터페이스이다.\n  stdin\n  stdout\n  stderr\n  pipes\n  "});index.add({'id':52,'href':'/posts/os/linux/tip/','title':"Useful command",'content':"특정 포트를 사용하는 프로세스 검사\n lsof -i :[port]  파일의 전체 내용출력\n awk \u0026lsquo;{print}\u0026rsquo; [File]  지정된 문자열을 포함하는 레코드만 출력\n awk \u0026lsquo;/STR/\u0026rsquo; [File]  특정 포트를 사용하는 프로세스 정보보기\n lsof -i TCP:22  특정 명령어가 사용하는 포트 보기\n lsof -c httpd  "});index.add({'id':53,'href':'/posts/database/common/acid/','title':"ACID",'content':""});index.add({'id':54,'href':'/posts/database/mysql/sql-20191208/','title':"sql_20191208",'content':"AUTO_INCREMENT 초기화\nALTER TABLE '테이블이름' AUTO_INCREMENT = 1; 캐리지 리턴 제거 (개행제거)\nUPDATE '테이블이름' SET '컬럼명' = replace('컬럼명', char(13), '') UPDATE '테이블이름' SET '컬럼명' = replace('컬럼명', '\\r\\n', '') "});index.add({'id':55,'href':'/posts/database/mysql/sql_tunning/','title':"sql_20191208",'content':"SQL 튜닝\n튜닝 기초\n 성능 높일시 비중이 높은부분을 높이는것이 중요  EXPLAIN 사용  EXPLAIN을 사용하여 쿼리 플랜 분석 ![스크린샷 2019-12-05 오전 11.13.11](‎⁨Macintosh HD⁩ ▸ ⁨사용자⁩ ▸ ⁨hoonoh⁩ ▸ ⁨데스크탑⁩/스크린샷 2019-12-05 오전 11.13.11.png)  "});index.add({'id':56,'href':'/posts/database/mysql/sql_basic/','title':"기본",'content':"1. INSERT INTO 테이블이름(필드이름1, 필드이름2, 필드이름3, ...) VALUES (데이터값1, 데이터값2, 데이터값3, ...) 2. INSERT INTO 테이블이름 VALUES (데이터값1, 데이터값2, 데이터값3, ...) "});index.add({'id':57,'href':'/posts/test/','title':"test",'content':""});index.add({'id':58,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/springboot/spring-20191205/','title':"Spring_20191205",'content':"스프링 제어 WebMvcConfigurer\n 포멧, 메시지 컨버트 관련하여 스프링 MVC를 제어 한다.  "});index.add({'id':59,'href':'/posts/framework/springboot/spring-20191205/','title':"Spring_20191205",'content':"스프링 제어 WebMvcConfigurer\n 포멧, 메시지 컨버트 관련하여 스프링 MVC를 제어 한다.  "});index.add({'id':60,'href':'/tags/aws/','title':"AWS",'content':""});index.add({'id':61,'href':'/posts/cloud/aws/exam/practice/','title':"AWS 설정 연습",'content':"ECS 컨테이너 서비스 구축 "});index.add({'id':62,'href':'/posts/cloud/aws/exam/summary_all/','title':"AWS 시험 정리",'content':"IAM  IAM role can be attached to the Amazon EC2 instance.  S3  S3에서는 특정 파일(Object)에 제한된 시간 동안 접근할 수 있도록 임시 permission을 부여하는 S3 pre-signed url 기능을 제공  S3 Glacier  장기 백업을 위한 안전하고 내구성이 뛰어나고 매우 저렴한 Amazon S3 클라우드 스토리지 클래스 고객은 월별 테라바이트당 1 USD의 저렴한 요금으로 데이터를 저장할 수 있으므로 온프레미스 솔루션과 비교하면 상당한 비용 절감을 기대할 수 있습니다 비용을 낮게 유지하면서 동시에 다양한 검색 요구를 지원하기 위해 Amazon S3 Glacier에서는 아카이브에 액세스하는 3가지 옵션(몇 분에서 몇 시간까지 소요)을 제공하며 S3 Glacier Deep Archive는 2가지 액세스 옵션(12~48시간 소요)을 제공합니다.    S3 - S3 Standard-IA  수명이 길지만 자주 액세스하지 않는 데이터 자주 액세스하지 않지만 필요할 때 빠르게 액세스해야 하는 데이터에 적합    S3 - Athena  표준 SQL을 사용해 Amazon S3에 저장된 데이터를 간편하게 분석할 수 있는 대화식 쿼리 서비스 Athena는 서버리스 서비스이므로 관리할 인프라가 없으며 실행한 쿼리에 대해서만 비용을 지불하면 됩니다.    S3 - encryption  서버측암호화  Amazon S3에서는 데이터 센터의 디스크에 데이터를 쓸 때 객체 레벨에서 데이터를 암호화하고 해당 데이터에 액세스할 때 자동으로 암호 해독 Amazon S3 관리형 키를 사용한 서버 측 암호화(SSE-S3)  각 객체는 고유한 키로 암호화 또한 추가 보안 조치로 주기적으로 바뀌는 마스터 키를 사용하여 키 자체를 암호화 가장 강력한 블록 암호 중 하나인 256비트 고급 암호화 표준(AES-256)을 사용하여 데이터를 암호화   고객 제공 키를 사용한 서버 측 암호화(SSE-C)  사용자는 암호화 키를 관리하고 Amazon S3는 암호화(디스크에 쓸 때) 및 해독(객체에 액세스할 때)을 관리   AWS Key Management Service에 저장된 고객 마스터 키(CMK)를 사용한 서버 측 암호화(SSE-KMS)  SSE-S3와 유사하지만 이 서비스 사용 시 몇 가지 추가적인 이점이 있고 비용이 발생 SSE-KMS도 CMK가 사용된 때와 사용 주체를 표시하는 감사 추적 기능을 제공 고객 관리형 CMK를 생성하고 관리하거나 사용자, 서비스 및 리전에 고유한 AWS 관리형 CMK를 사용할 수 있습니다      S3- pre-signed url  S3에서는 특정 파일(Object)에 제한된 시간 동안 접근할 수 있도록 임시 permission을 부여하는 S3 pre-signed url 기능    Aurora  Amazon Aurora는 고성능 상용 데이터베이스의 성능과 가용성에 오픈 소스 데이터베이스의 간편성과 비용 효율성을 결합하였으며 클라우드를 위해 구축된 MySQL 및 PostgreSQL 호환 관계형 데이터베이스입니다 Amazon RDS에서 모든것을 관리한다. 내결함성을 갖춘 자가 복구 분산 스토리지 시스템으로, 데이터베이스 인스턴스당 최대 64TB까지 자동으로 확장 지연 시간이 짧은 읽기 전용 복제본 최대 15개, 특정 시점으로 복구, Amazon S3로 지속적 백업, 3개의 가용 영역(AZ)에 걸친 복제 를 통해 뛰어난 성능과 가용성을 제공  Amazon Redshift  Amazon Redshift는 클라우드에서 완벽하게 관리되는 페타바이트급 데이터 웨어하우스 서비스 작게는 수백 기가바이트부터 시작하여 페타바이트 이상까지 데이터를 확장  Read Replica  Amazon RDS 읽기 전용 복제본은 데이터베이스(DB) 인스턴스의 성능과 내구성을 높여줍니다 특정 소스 DB 인스턴스의 복제본을 여러 개 만들어 여러 데이터 사본이 요청하는 높은 애플리케이션 읽기 트래픽도 처리할 수 있습니다. 덕분에 전체 읽기 처리량이 향상됩니다. 읽기 전용 복제본은 Amazon RDS for MySQL, MariaDB, PostgreSQL 및 Oracle뿐만 아니라 Amazon Aurora에서도 사용할 수 있습니다.  SES ( Simple Email Service)  디지털 마케터 및 애플리케이션 개발자가 마케팅, 알림 및 트랜잭션 이메일을 발송하는 데 도움이 되도록 설계된 클라우드 기반 이메일 발송 서비스  Beanstalk  Elastic Beanstalk를 사용하면, 애플리케이션을 실행하는 인프라에 대한 염려 없이 AWS 클라우드에서 애플리케이션을 신속하게 배포 및 관리할 수 있다. workflow   VPC 구성요소 VPC Endpoint  VPC 네트워크 내에서 VPC 외부에 위치한 Public한 서비스를 IGW를 거치지 않고 VPC내부에서 직접 접근하도록 지원 VPC 엔드포인트를 통해 인터넷 게이트웨이, NAT 디바이스, VPN 연결 또는 AWS Direct Connect 연결을 필요로 하지 않고 AWS PrivateLink 구동 지원 AWS 서비스 및 VPC 엔드포인트 서비스에 비공개로 연결할 수 있습니다. VPC의 인스턴스는 서비스의 리소스와 통신하는 데 퍼블릭 IP 주소를 필요로 하지 않습니다. VPC와 기타 서비스 간의 트래픽은 Amazon 네트워크를 벗어나지 않습니다.  인터페이스 엔드포인트  인터페이스 엔드포인트는 프라이빗 IP 주소 를 가진 탄력적 네트워크 인터페이스이며, 지원되는 서비스로 전달되는 트래픽에 대한 진입점 역할을 하는 서브넷의 IP 주소 범위   게이트웨이 엔드포인트  게이트웨이 엔드포인트는 지원되는 AWS 서비스로 전달되는 트래픽에 대한 라우팅 테이블에서 경로의 대상으로 지정하는 게이트웨이      Gateway Endpoint  Endpoint가 Gateway 타입으로 지원하여 AWS 서비스 접근 시, 라우팅으로 접근 라우팅 테이블에서 S3나 DynamoDB의 목적지 네트워크에 대한 Target(Next Hop)으로 Gateway Endpoint를 지정 S3와 DynamoDB 접근을 지원  Interface Endpoint  생성 시에는 어느 VPC의 어떤 AZ의 어떤 Subnet을 사용할지 선택, 생성 시에 지정한 각 서브넷의 IP를 각각 할당 받음 Interface Endpoint 를 이용해서 서비스를 호출하는 경우에는, AWS에서 기본으로 사용하는 도메인을 사용하거나, 별도의 서비스 도메인을 지정하여 VPC 내에서 서비스 도메인 Lookup 시에 Interface Endpoint 의 IP로 응답하여 접근하도록 할 수 있음.  VPC Peering  VPC 간의 인터넷을 통하지 않고 직접 통신 할 수 있도록 연결하는 기술 VPC Peering으로 연결 시에 VPC 간의 네트워크 대역이 겹치지 않도록 설계해야 함. VPC Peering은 단일 계정으로도 가능하며, 서로 다른 계정 간의 VPC Peering 구성도 가능  VPC Peering 제한  멀티 Region 간의 VPC Peering 시에는 security group 참조 지원 안 함. 멀티 Region 간의 VPC Peering 시에는 DNS resolution 지원 안 함. IPv6와 Jumbo 프레임 지원 안 함. VPC Peering을 통해서 외부 혹은 다른 VPC에서 VPC를 통해서 또 다른 VPC로 접근하는 Transit 기능은 지원하지 않음.  Transit Gateway  VPC 간의 Transit이 가능하도록 해주는 게이트웨이 서비스   AWS Direct Connect  온프레미스에서 AWS로 전용 네트워크 연결을 쉽게 설정할 수 있는 클라우드 서비스 솔루션 AWS Direct Connect를 사용하면 AWS와 사용자의 데이터 센터, 사무실, 또는 코로케이션 환경 사이에 프라이빗 연결을 설정할 수 있습니다. 따라서 많은 경우 네트워크 비용을 줄이고, 대역폭 처리량을 늘리며, 인터넷 기반 연결보다 일관된 네트워크 경험을 제공할 수 있습니다.  CloudFront  CloudFront는 개발자 친화적 환경에서 짧은 지연 시간과 빠른 전송 속도로 데이터, 동영상, 애플리케이션 및 API를 전 세계 고객에게 안전하게 전송하는 고속 콘텐츠 전송 네트워크(CDN) 서비스 CloudFront는 AWS Shield와 연동되어 DDoS 완화를 수행하고, 애플리케이션 오리진으로서 Amazon S3, Elastic Load Balancing 또는 Amazon EC2를 사용하고, Lambda@Edge와 연동되어 사용자지정 코드를 고객의 사용자에서 가까운 위치에서 실행하고 맞춤화된 사용자 경험을 제공 Amazon S3, Amazon EC2 또는 Elastic Load Balancing과 같은 AWS 오리진을 사용하는 경우, 이러한 서비스와 CloudFront 간에 전송된 데이터에 대해서는 비용을 지불하지 않습니다. Q1 : A Solutions Architect has been asked to deliver video content stored on Amazon S3 to specific users from Amazon CloudFront while restricting access by unauthorized users. How can the Architect implement a solution to meet these requirements? Answer :CloudFront 배포를 통해서만 Amazon S3 버킷에 대한 액세스를 허용하려면 먼저 배포에 OAI(오리진 액세스 ID)를 추가합니다. 그런 다음, 버킷 정책 및 Amazon S3 ACL(액세스 제어 목록)을 검토  Multi-AZ  다중 AZ DB 인스턴스를 프로비저닝하면 Amazon RDS는 기본 DB 인스턴스를 자동 생성하고 다른 가용 영역(AZ)에 있는 예비 인스턴스에 데이터를 동기적으로 복제 각 AZ는 물리적으로 분리된 자체 독립 인프라에서 실행되며 높은 안정성을 제공하도록 설계  ELB(Elastic Load Balancer)  Application Load Balancer  Application Load Balancer는 HTTP 및 HTTPS 트래픽의 로드 밸런싱에 가장 적합 마이크로서비스와 컨테이너 등 최신 애플리케이션 아키텍처 전달을 위한 고급 요청 라우팅 기능을 제공합니다 개별 요청 수준(계층 7)에서 작동하는 Application Load Balancer는 요청의 콘텐츠를 기반으로 Amazon VPC(Amazon Virtual Private Cloud) 내의 대상으로 트래픽을 라우팅합니다.   Network Load Balancer  Network Load Balancer는 극한의 성능이 요구되는 TCP(Transmission Control Protocol), UDP(User Datagram Protocol) 및 TLS(전송 계층 보안) 트래픽의 로드 밸런싱에 가장 적합 연결 수준(계층 4)에서 작동하는 Network Load Balancer는 Amazon VPC(Amazon Virtual Private Cloud) 내의 대상으로 트래픽을 라우팅하며, 초당 수백만 개의 요청을 처리하면서 지연 시간을 매우 낮게 유지 Network Load Balancer는 갑작스러운 일시적 트래픽 패턴 처리에도 최적화   Classic Load Balancer  여러 Amazon EC2 인스턴스에서 기본적인 로드 밸런싱을 제공 Classic Load Balancer는 EC2-Classic 네트워크 내에 구축된 애플리케이션을 대상으로 합니다.    EC2 price model type  T-series instances scheduled Reserved Instances. Spot instances.  스팟 인스턴스는 Auto Scaling, EMR, ECS, CloudFormation, Data Pipeline 및 AWS Batch와 같은 AWS 서비스와 긴밀하게 통합 AWS 클라우드에서 미사용 EC2 용량을 활용할 수 있습니다.    EBS 볼륨  Instance Store Volume are somethimes called Ephemeral Storage Instance store volume cannot be stopped If the underlying host fails, you will lose your data. EBS backed instances can be stopped. You will not lose the data on this instance if it is stopped. You can reboot both, you will not lose your data. By default, both ROOT volumes will be deleted on termination. However, with EBS volumes, you can tell aws to keep the root device volume    EBS 데이터를 잃는 경우  Failure of an underlying drive Stopping an Amazon EBS-backed instance Terminating an instance    EBS 볼륨 유형   SSD 지원 볼륨 : 작은 I/O 크기의 읽기/쓰기 작업을 자주 처리하는 트랜잭션 워크로드에 최적화되어 있으며, 기준 성능 속성은 IOPS\n 범용 SSD (gp2) : 다양한 워크로드에 사용할 수 있으며 가격 대비 성능이 우수한 범용 SSD 볼륨 프로비저닝된 IOPS SSD (io1) : 지연 시간이 짧거나 처리량이 많은 미션 크리티컬 워크로드에 적합한 고성능 SSD 볼륨    HDD 지원 볼륨 : 대용량 스트리밍 워크로드 에 최적화되어 있으며, IOPS보다는 처리량(MiB/s로 측정)이 더 정확한 성능 측정 기준\n  처리량에 최적화된 HDD (st1) : - 자주 액세스하는 처리량 집약적 워크로드에 적합한 저비용\n 빅 데이터, 저비용으로 일관되고 높은 처리량을 요구하는 스트리밍    Cold HDD (sc1) : - 자주 액세스하지 않는 워크로드에 적합한 최저 비용 HDD 볼륨\n 자주 액세스하지 않는 대용량 데이터를 위한 처리량 중심의 스토리지        EBS Snapshots  Snapshots with AWS Marketplace product codes can\u0026rsquo;t be made public.    S3 vs EBS vs EFS  https://sarc.io/index.php/aws/1789-s3-vs-ebs-vs-efs  EBS 지연 발생시 확인 사항  If your I/O latency is higher than you require, check your average queue length to make sure that your application is not trying to drive more IOPS than you have provisioned. You can maintain high IOPS while keeping latency down by maintaining a low average queue length (which is achieved by provisioning more IOPS for your volume).  Route 53  Route 53는 높은 가용성과 확장성이 뛰어난 클라우드 Domain Name System (DNS) 웹 서비스 사용자를 AWS 외부의 인프라로 라우팅하는 데도 Route 53를 사용할 수 있습니다.   라우팅 정책  단순 라우팅 정책 장애 조치 라우팅 정책 지리 위치 라우팅 정책 지리 근접 라우팅 정책 지연 시간 라우팅 정책 다중 응답 라우팅 정책 가중치 기반 라우팅 정책     Route 53 health check  Route 53 natively supports ELB with an internal health check. Turn \u0026ldquo;Evaluate target health\u0026rdquo; on and \u0026ldquo;Associate with Health Check\u0026rdquo; off and R53 will use the ELB\u0026rsquo;s internal health check.   액티브-액티브 및 액티브-패시브 장애 조치  액티브 - 액티브 장애조치 모든 리소스를 대부분의 시간 동안 사용 가능하도록 하려면 이 장애 조치 구성을 사용 액티브-패시브 장애 조치 기본 리소스 또는 리소스 그룹이 대부분의 시간 동안 사용 가능하도록 하고 보조 리소스 또는 리소스 그룹은 기본 리소스가 사용 불가능할 경우를 대비해 대기 중에 있도록 하고 싶다면 이 장애 조치 구성    Cognito  웹 및 모바일 앱에 대한 인증, 권한 부여 및 사용자 관리  사용자 풀  사용자 풀은 Amazon Cognito의 사용자 디렉터리 Amazon Cognito를 통해, 또는 타사 자격 증명 공급자(IdP)를 통해 연동하여 웹 또는 모바일 앱에 로그인   자격 증명 풀  임시 AWS 자격 증명을 얻어 Amazon S3 및 DynamoDB 등과 같은 다른 AWS 서비스에 액세스      DynamoDB  DynamoDB는 어떤 규모에서도 10밀리초 미만의 성능을 제공하는 키-값 및 문서 데이터베이스 내구성이 뛰어난 다중 리전, 다중 마스터 데이터베이스로서, 인터넷 규모 애플리케이션을 위한 보안, 백업 및 복원, 인 메모리 캐싱 기능을 기본적으로 제공 Amazon DynamoDB supports increment and decrement atomic operations. DynamoDB supports in-place atomic updates DynamoDB allows for the storage of large text and binary objects, but there is a limit of 400 KB.  Data Pipeline  데이터의 이동과 변환을 자동화하는 데 사용할 수 있는 웹 서비스  Kinesis Data Firehouse  스트리밍 데이터를 데이터 레이크, 데이터 스토어 및 분석 도구에 쉽고 안정적으로 로드하는 방법. 스트리밍 데이터를 캡처하고 변환한 후 Amazon S3, Amazon Redshift, Amazon Elasticsearch Service 및 Splunk로 로드하여 이미 사용하고 있는 기존 비즈니스 인텔리전스 도구 및 대시보드를 통해 거의 실시간으로 분석 데이터를 로드하기 전에 배치 처리, 압축, 변환 및 암호화하여 대상 스토리지의 사용량을 최소화하고 보안을 강화할 수 있습니다.  AWS Import/Export  AWS Import/Export does not currently support export from Amazon EBS or Amazon Glacier.  SNS  애플리케이션, 최종 사용자 및 디바이스에서 즉시 알림을 전송하고 클라우드의 알림을 수신하도록 하는 웹 서비스입니다.  Gateway-cached  AWS Storage Gateway는 온프레미스 소프트웨어 어플라이언스를 클라우드 기반 스토리지에 연결하여 데이터 보안 기능으로 온프레미스 IT 환경과 AWS 스토리지 인프라 사이에 원활한 통합이 이루어지도록 지원  AWS CloudFormation  클라우드 환경에서 AWS 및 타사 애플리케이션 리소스를 모델링하고 프로비저닝할 수 있도록 공용 언어를 제공합니다 CloudFormation을 사용하면 프로그래밍 언어 또는 간단한 텍스트 파일을 사용하여 자동화되고 안전한 방식으로 모든 지역과 계정에 걸쳐 애플리케이션에 필요한 모든 리소스를 모델링 및 프로비저닝할 수 있습니다.  EIP (Elastic IP)  탄력적 IP 주소는 동적 클라우드 컴퓨팅을 위해 고안된 정적 IPv4 주소입니다 탄력적 IP 주소는 AWS 계정과 연결됩니다. 탄력적 IP 주소를 사용하면 주소를 계정의 다른 인스턴스에 신속하게 다시 매핑하여 인스턴스나 소프트웨어의 오류를 마스킹할 수 있습니다. 탄력적 IP 주소는 인터넷에서 연결 가능한 퍼블릭 IPv4 주소입니다 인스턴스에 퍼블릭 IPv4 주소가 없는 경우 탄력적 IP 주소를 인스턴스와 연결하여 인터넷과 통신을 활성화하고 예를 들어 로컬 컴퓨터에서 인스턴스에 연결할 수 있습니다. 현재는 IPv6에 대한 탄력적 IP 주소를 지원하지 않습니다. 모든 AWS 계정은 리전당 5개의 탄력적 IP 주소 로 제한됩니다.  Amazon ElastiCache  AWS 클라우드상의 분산 인 메모리 캐시 환경을 손쉽게 설정 및 관리하고 및 확장 환경의 배포 및 관리와 관련된 복잡성을 제거하면서 고성능, 크기 조정 가능 및 비용 효율적인 인 메모리 캐시를 제공 Redis 및 Memcached 엔진과 호환  AWS Key Management Service(KMS)  손쉽게 암호화 키를 생성 및 관리하고 다양한 AWS 서비스와 애플리케이션에서의 사용을 제어 AWS KMS는 AWS CloudTrail과도 통합되어 모든 키 사용에 관한 로그를 제공함으로써 각종 규제 및 규정 준수 요구 사항을 충족할 수 있게 지원  AWS PrivateLink  AWS 네트워크 내에 네트워크 트래픽을 유지하여 AWS에 호스팅된 서비스에 쉽고 안전하게 액세스 퍼블릭 인터넷에 데이터가 노출되지 않도록 하여 클라우드 기반 애플리케이션과 공유된 데이터 보안을 간소화합니다 AWS PrivateLink는 Amazon 네트워크를 통해 VPC, AWS 서비스 및 온프레미스 애플리케이션 간에 안전하게 비공개 연결을 제공 PrivateLink를 사용하면 여러 계정과 VPC에 걸쳐 손쉽게 서비스에 연결하여 네트워크 아키텍처를 상당히 간소화  Application load balancers support dynamic host port mapping  동적 포트 매핑을 사용하면 Amazon ECS 클러스터의 동일한 Amazon EC2 서비스에서 여러 작업을 더욱 쉽게 실행할 수 있습니다. Classic Load Balancer에서는 컨테이너 인스턴스의 포트 번호를 정적으로 매핑해야 합니다. Classic Load Balancer에서는 포트가 충돌하게 되므로 동일한 인스턴스에서 여러 개의 작업 사본을 실행할 수 없습니다 Application Load Balancer는 동적 포트 매핑을 사용하므로 동일한 컨테이너 인스턴스의 단일 서비스에서 여러 작업을 실행할 수 있습니다.  Amazon EC2 Auto Scaling  대상 추적 조정 정책  CloudWatch 경보를 생성 및 관리하면서 지표와 목표 값을 기준으로 조정 조절값을 계산합니다 조정 정책은 필요에 따라 용량을 Spot Instances 추가하거나 제거하여 측정치를 지정한 목표 값으로, 혹은 목표 값에 가깝게 유지   단순 단계 조정 정책  일련의 조정 조절을 기반으로 Auto Scaling 그룹의 용량을 늘리거나 줄입니다. 단순 및 단계 조정 정책을 사용할 경우, 조정 프로세스를 트리거하는 CloudWatch 경보에 대한 조정 지표와 임계값을 선택하고, 지정된 평가 기간 동안 임계값을 위반했을 때 Auto Scaling 그룹을 어떻게 조정할지 정의해야 합니다.    AWS WAF(웹 애플리케이션 방화벽)  가용성에 영향을 주거나, 보안을 위협하거나, 리소스를 과도하게 사용하는 일반적인 웹 공격으로부터 웹 애플리케이션이나 API를 보호하는 데 도움이 되는 웹 애플리케이션 방화벽입니다. AWS WAF에서는 SQL 주입 또는 사이트 간 스크립팅과 같은 일반적인 공격 패턴을 차단하는 보안 규칙 및 사용자가 정의한 특정 트래픽 패턴을 필터링하는 규칙을 생성하도록 지원하여 애플리케이션에 트래픽이 도달하는 방법을 제어할 수 있습니다  Amazon API Gateway  모든 규모의 API를 생성, 유지 관리 및 보호 API는 애플리케이션이 백엔드 서비스의 데이터, 비즈니스 로직 또는 기능에 액세스할 수 있는 \u0026ldquo;정문\u0026rdquo; 역할을 합니다. API Gateway를 사용하면 실시간 양방향 통신 애플리케이션이 가능하도록 하는 RESTful API 및 WebSocket API를 작성할 수 있습니다. API Gateway는 컨테이너식 서버리스 워크로드 및 웹 애플리케이션을 지원합니다.  storage type 정리  - 자주 액세스하는 객체를 위한 스토리지 클래스 - 성능에 민감한 사용 사례(밀리초 액세스 시간을 필요로 하는 사례)와 자주 액세스되는 데이터를 위해 Amazon S3는 다음과 같은 스토리지 클래스를 제공 - STANDARD —기본 스토리지 클래스. 객체를 업로드할 때 스토리지 클래스를 지정하지 않으면 Amazon S3가 STANDARD 스토리지 클래스를 할당합니다. - REDUCED_REDUNDANCY—Reduced Redundancy Storage(RRS) 스토리지 클래스는 STANDARD 스토리지 클래스보다 더 적은 중복성으로 저장될 수 있는 중요하지 않고 재현 가능한 데이터용으로 설계되었습니다. - 자주 액세스하는 객체와 자주 액세스하지 않는 객체를 자동으로 최적화하는 스토리지 클래스 - INTELLIGENT_TIERING 스토리지 클래스는 성능 영향 또는 운영 오버헤드 없이 가장 비용 효율적인 스토리지 액세스 계층으로 데이터를 자동으로 이동하여 스토리지 비용을 최적화하도록 설계 - 세스 패턴이 바뀔 때 자주 액세스하는 티어와 저렴한 요금의 자주 액세스하지 않는 티어 사이에 세분화된 객체 수준에서 데이터를 이동함으로써 자동 비용 절감 효과 - 자주 액세스하지 않는 객체를 위한 스토리지 클래스 - STANDARD_IA 및 ONEZONE_IA 스토리지 클래스는 수명이 길고 자주 액세스하지 않는 데이터용으로 설계되었습니다. - STANDARD_IA 및 ONEZONE_IA 객체는 밀리초 액세스에 사용 가능합니다(STANDARD 스토리지 클래스와 유사함) - Amazon S3는 이들 객체에 대해 검색 요금을 부과하므로 이들 객체는 자주 액세스되지 않는 데이터에 가장 적합합니다 - 다음의 경우에 STANDARD_IA 및 ONEZONE_IA 스토리지 클래스를 선택할 수 있을 것입니다. - 백업 - 밀리초 액세스가 필요한 오래된 데이터의 경우 - STANDARD_IA—Amazon S3가 객체 데이터를 지리적으로 분리된 여러 개의 가용 영역에 중복되게 저장합니다 - ONEZONE_IA–Amazon S3가 객체 데이터를 하나의 가용 영역에만 저장하므로 STANDARD_IA보다 더 저렴합니다 ![](../../../image/2020-02-03-21-55-15.png)   객체 아카이빙을 위한 스토리지 클래스  GLACIER 및 DEEP_ARCHIVE 스토리지 클래스는 저비용 데이터 아카이빙용으로 설계  GLACIER—분 단위로 데이터의 일부를 검색해야 하는 아카이브에 사용합니다 LACIER 스토리지 클래스에 저장된 데이터는 최소 스토리지 기간이 90일이며 신속 검색을 사용하여 최소 1~5분 이내에 액세스할 수 있습니다. 90일 최소 기간 이전에 삭제했거나 덮어썼거나 다른 스토리지 클래스로 이전한 경우, 90일 요금이 부과됩니다 DEEP_ARCHIVE—거의 액세스할 필요가 없는 데이터를 아카이빙할 때 사용합니다. 최소 스토리지 기간은 180일이고 기본 검색 시간은 12시간입니다.      VPC Flow Logs  VPC의 네트워크 인터페이스에서 전송되고 수신되는 IP 트래픽에 대한 정보를 수집할 수 있는 기능 플로우 로그 데이터를 Amazon CloudWatch Logs 및 Amazon S3로 게시할 수 있습니다.  Amazon S3 multipart upload    AWS CloudTrail "});index.add({'id':63,'href':'/posts/cloud/aws/exam/faq/','title':"AWS 용어 정리",'content':"컴퓨팅  람다(Lambda)  람다에서 실행하는 코드는 람다함수로 업로드됨. 각 함수에는 이름과 설명, 진입점, 리소스 요구 사항등 연관된 구성 정보가 포함되어 있다. 람다함수의 상태가 비저장이어야 하는 이유는 함수를 상태 비저장으로 유지하면 AWS Lambda에서 필요한 만큼 함수 사본을 빠르게 시작하여 수신 이벤트 비율에 따라 조정 람다의 프로그래밍 모델은 상태 비저장이지만 코드에서 S3, DynamoDB 등 다른 웹 서비스를 호출하면 상태 저장 데이터에 액세스 할 수 있다. 함다함수 코드 제한  인바운드 네트워크 연결 아웃바운드 TCP/IP 및 UDP/IP 소켓만 지원 TCP 포트 25 트래픽도 스팸 방지 조치로 차단.   모니터링  사용자 대신 함수를 모니터링하여 총 요청수, 계정 수준 및 함수 수준 동시성 사요, 지연시간, 오류 비율, 제한된 요청 등을 비롯한 실시간 지표를 Amazon CloudWatch를 통해 보고한다.   CloudWatch 경보 응답  먼저 Amazon SNS 알림에 전송할 경보를 구성. 그런 다음 AWS lambda 콘솔에서 lambda함수를 ㅅ건택하여 Amazon SNS 주제와 연결.   어플리케이션에서 직접 람다를 트리거 하려면 AWS lambda invoke API를 통해 커스텀 이벤트로 Lambda 함수를 호출 HTTPS 통해 Lambda 호출  Api Gateway를 사용해 커스텀 RESTFull API를 정의해 HTTPS통해 Lambda함수 호출   데드레터큐  SQS 대기열 또는 SNS 주제를 데드레터큐로 구성 할 수 있다.      스토리지 온프레미스 환경과 AWS 클라우드간 서비스   S3\n 객체 스토리지로서 가용성이 높으며 무제한 확장 가능한 데이터 스토리지 서비스 성능  저장할 수 있는 데이터의 전체 볼륨과 객체수에는 제한이 없다. 객체의 크기는 최소 0바이트 부터 최대 5테라바이트까지 지원. 단일 PUT업로드 가능 객체 최대 크기는 5기가바이트 객체의 크기가 100메가바이트 이상인 경우 멀티파트 업로드 기능 사용가능.   가용성  Standard : 99.99 One zone-IA : 99.5 Glacier, Deep Archive : 99.99   저장  Standard,Standard-IA,Glacier는 AWS 리전 내에 각기 지리적으로 분리된 최소 3개의 가용영역에 걸쳐 여러 디바이스에 자동 저장. One zone-IA는 사용자가 선택한 AWS리전의 단일 가용 영역에 중복 저장   비용  같은 리전에 있는 EC2와 S3간에 데이터를 전송한경우 데이터 전송 요금이 청구되지 않는다. S3에서 데이터 수신요금은 버킷에 전송된 데이터의 양을 나타냄 송신 시 요금은 특정 S3지역 이외의 지역에 있는 버킷에서 데이터를 읽어올때 요금부과. 특정 지역에서 인터넷으로 송신된 EC2, S3, RDS, simpleDB, SQS, SNS, VPC 전체 데이터 송신량을 합산한 것. 다른 AWS 계정에서 내 S3버킷에 액세스 하는 경우 일반 요금이 나오고 요청자 지불 버킷으로 구성하여 요청자가 비용을 내게 할 수 있다.   보안  버킷정책, 엑세스제어목록, IAM, 쿼리문자열 인증 같은 제어 메커니즘 제공 추가 보안은 서버측 암호화 옵션을 사용하여 저장데이터 암호화 SSE-S3 : 키 관리 및 키보호를 처리하는 통합 솔루션. 아마존에서 키관리 SSE-C : 자체 암호화키를 유지 관리하고 싶지만 클라이언트 측 암호화 라이브러리를 구현하거나 활용하고 싶지 않은 경우에 사용 SSEーKMS : S3와 비슷하지만, 감사추적을 제공 Amazon S3 Encryption Client : 암호화 클라이언트 라이브러리를 사용하여 키에대한 제어 권한을 유지할 수 있으며 워하는 암호화 라이브러리를 사용하여 클라이언트측 객체 암호화 및 암호 해독을 완료.   Macie  S3에 저장된 민감한 데이터를 자동 검색 분류 및 보호하는 AI기반 보안 서비스   액세스 포인트  수백개의 버킷정책의 복잡성으로 인해 생김. 특정 ARN 리소스에서만 버킷에 접근이 가능하도록 만든다. S3 콘솔 및 CLI를 통해 액세스 포인트 정책을 편집할 뿐 아니라 액세스 포인트를 추가하고 보고 삭제할 수 있습니다. CloudFormation 템플릿을 사용하여 액세스 포인트를 시작할 수도 있습니다. AWS CloudTrail 로그를 통해 \u0026ldquo;액세스 포인트 생성\u0026rdquo; 및 \u0026ldquo;액세스 포인트 삭제\u0026quot;와 같은 액세스 포인트 작업을 모니터링하고 감사할 수 있다.      S3 Intelligent Tiering\n 알수없는 패턴 또는 알아보기 어려운 변화하는 액세스 패턴이 있는 데이터를 위한 클래스 저장  30일 연속으로 액세스 되지 않은 객체를, 자주 액세스하지 않는 계층으로 이동하는 방식으로 작동한다. 이후에 다시 액세스하면 빈번한 액세스 계층으로 이동. 최소 객체 크기는 없지만, 128키로바이트보다 작은 객체는 자동 계층화에 접합하지 않으며 항상 빈번한 액세스 계층 요금으로 저장 한번에 다양한 객체를 여러가지 클래스에 저장할 수 있다.      S3 IA\n 액세스 빈도가 낮지만 빠르게 액세스 해야하는 데이터를위한 스토리지 클래스 용도  백업용, 장기 스토리지, 재해 복구용, 이전 동기화 공유 스토리지   성능  스탠다드, One zone-IA 동일한 성능   저장  x-amz-storage-class 에 STANDARD_IA지정 또는 S3에서 IA로 변경   비용  저장된지 30일이내의 데이터를 삭제를 하면 한달만큼의 요금이 결제 된다.      S3 One zone-IA\n  S3 Glacier\n  S3 Glacier Deep archive\n  Amazon S3 Transfer Acceleration\n  S3 CloudWatch 지표\n  EBS\n EC2 인스턴스 종료 시 데이터  로컬 인스턴스 스토어에 저장된 데이터는 인스턴스가 활성화되어 있는 동안만 지속되는 것과 달리, EBS볼륨에 저장된 데이터는 인스턴스 수명과 별도로 지속될 수 있다. 따라서 로컬 인스턴스 스토어는 임시 데이터만 사용하는 것이 좋다. 더 높은 내구성을 원한다면 EBS 볼륨을 사용하거나 S3에 백업.   성능  EBS 프로비저닝 IOPS(SSD) 기대 성능 지연시간 : 10 밀리쵸 미만 I/O 크기에따라 IOPS 속도에 영향이 있다. I/O 크기가 증가 할 떄마다동일한 IOPS 속도를 달성하는데 필요한 리소스는 선형적으로 증가한다. 성능일관성을 가지려면 EBS 대기열에도 충분한 요청수가 있어야 한다. 보통 1000iops당 1수준으로 유지되어야 적당한편이라고 함. I/O 크기가 HDD 지원 볼륨에서 제공하는 처리량 속도에 영향을 주는데 HDD지원 볼륨은 1메가바이트의 I/O크기로 읽기 쓰기를 처리한다. 순차적 I/O는 1MB단위로 병합되어 처리하는 반면 비순차적 I/O는 실제 I/O크기가 1MB 작더라도 1MB로 처리한다. 따라서 HDD 성능 일관성에 영향을 줄수있는 요인  순차적I/O 와 비순차적 I/O 작업간 균형 인스턴스 종류 스냅샷 생성 (스냅샷이 완료될때까지 기대 쓰기 성능을 기준 속도까지 낮춤 -\u0026gt; st1, sc1 에 한함) 충분치 않은 대기열 HDD의 경우 기준 대기열이 4이상이여야함     스냅샷  스냅샷은 볼륨이 연결되어 사용되고 있는 중에도 실시간으로 실행 할 수 있다. 단 스냅샷은 EBS 볼륨에 기록된 데이터만 갭처 할 수 있으므로 사용자의 어플리케이션 또는 OS를 사용해 로컬로 캐싱한 데이터는 제외 될 수 있다. (루트 디바이스로 사용되는 볼륨은 시스템을 종료하고 하는것이 좋다.)   암호화  EBS 데이터 볼륨 , 부팅 볼륨 및 스냅샷에 대한 원할한 암호화를 제공하므로, 보안키 관리 인프라를 구축할 필요가 없다. 아마존 관리키 또는 KMS를 사용하여 생성 및 관리하는 키로 데이터를 암호화하여 저장 데이터 보안을 활성화한다. 인스턴스 시작시 알호화된 데이터 볼륨을 생성하려면 CMK(고객마스터키)를 사용하면 된다. 암호화 되지 않은 AMI에서 암호화된 EBS 인스턴스를 시작가능함      EFS\n 파일 스토리지를 간편하게 설정하고 확장하고 비용을 최적화 할수 있도록 지원하는 완전관리형 서비스 스토리지를 프로비저닝할 필요 없이 자동으로 기가바이트를 페타바이트 규모의 데이터로 확장 될 수 있다. 수백, 수천개의 인스턴스에서 도시에 EFS로 액세스 가능, 일관된 성능을 제공. 사용  빅데이터 및 분석, 미디어 처리 워크플로, 콘텐츠 관리, 웹 지원 및 홈 디렉터리 블록 스토리지 단일 EC2인스턴스에서 가장 짧은 지연 시간으로 데이터 액세스해야 할때 사용   종류  Standard 및 Infrequent Access 스토리지 클래스를 제공   연결  외부 VPC에서 액세스 하려면 VPC내 EC2인스턴스에서는 파일시스템에 접근이 가능하므로, VPC피어링 연결, VPC 게이트웨이를 통해 VPC내의 인스턴스에 액세스하여 EFS 접그니, 온프레미스 서버는 VPC에 대한 Direct Connect 또는 AWS VPN 연결을 통해 파일 시스템을 탑재   성능  페타바이트 급 규모. EBS의 경우 지연시간이 조금 더 빠르지만 처리량 규모는 초당 여러 GB로 초당 단일 GB인 EBS 보다 좋다.   마이그레이션  온프레미스의 대용량 데이터를 EFS로 옮길떄 Direct Connect를 사용      Storage Gateway\n 스토리지 게이트웨이 서비스를 이용하면 온프레미스 환경과 AWS 클라우드 간에 하이브리드 스토리지를 지원 할 수 있다. 서비스 내용  AWS 클라우드 스토리지 서비스에 데이터를 안전하고 안정적으로 저장하면서 자주 액세스하는 데이터는 온프레미스에 캐싱하여 지연 시간이 짧은 성능을 제공한다. 불안정한 네트워크를 허용하고 전송되는 데이터 양을 최소화하는 최적화된 데이터 전송 메커니즘과 대역폭 관리를 제공   종류  파일 게이트웨이 : NFS와 같은 파일 프로토콜을 사용하여 Amazone S3에서 객체를 저장하고 검색. 파일 게이트웨이를 통해 작성된 객체는 S3에서 직접 액세스 할 수 있다. 테이프 게이트웨이 : 가상 미디어 체인저, 가상 테이프 드라이브 및 가상 테이프로 구성된 iSCSI 가상 테이프 라이브러리(VTL) 인터페이스를 백업 애플리케이션에 제공, 가상 데이프 데이터는 S3, Glacier에 아카이브 될 수 있다. 볼륨 게이트웨이 : iSCSI 프로토콜을 사용하여 애플리케이션에 블록 스토리지를 제공. 볼륨의 데이터는 S3에 저장. AWS에서 iSCSI 볼륨에 액세스하려면 EBS 볼륨을 생성하는데 사용될 EBS 스냅샷 만듬. (백업용으로도 사용 가능)   이점  게이트웨이는 로컬 캐시를 통해 자주 사용하는 데이터에 지연 시간이 짧은 액세스를 제공   암호화  SSL 을 이용해 데이터 전송 S3에 저장되는 모든 데이터는 S3관리형 SSE-S3로 서버측에서 함호화 (KMS는 선택사항)   FAQ(파일게이트웨이)  Storage Gateway는 라이팅이 불가능한 Private 네트워크에 배포가능 단 이경우에는 DX, VPN 을 통해 VPC에 연결되어 있어야 한다. Storage gateway트래픽은 AWS private link를 통해 구동되는 VPC 종단점을 통해 라우팅된다. 파일 게이트웨이가 S3 버킷에 액세스하는 방법: IAM 역할을 사용하여 S3에 접근. IAM 역할을 자체적으로 설정하거나 AWS storage gateway관리 콘솔에서 자동으로 설정하도록 할 수 있다. 먼저 IAM 역할을 생성, S3버킷에 액세스할수 있도록 IAM 액세스 정책과 연결. 버킷당 파일공유 수는 제한이 없음 버킷은 단일 라이터가 있는것이 좋다. 게이트웨이당 최대 10개 파일공유를 생성할 수 있다. 개별 파일은 최대 5TB 개별 객체의 최대 크기와 같다.   FAQ(볼륨게이트웨이)  게이트웨이당 최대 32개의 볼륨지원. 각 볼륨 크기는 32TB 게이트웨이당 데이터 크기는 최대 1PB. S3에서 내 볼륨 데이터를 볼수없는 이유는 Storage gateway를 통해 I/O 작업을 위해 볼륨에 액세스 할수 있다.   PrivateLink  PrivateLink를 파일 게이트웨이와 함께 사용하려면 온프레미스 파일 게이트웨이를 PrivateLink 및 프라이빗 가상 인터페이스와 함께 사용하여 S3 버킷에 액세스하려면 EC2기반 프록시 서버를 설정. 그리고 프라이빗 네트워크를 통해 S3에 액세스하려면 S3의 게이트웨이 엔드포인트를 사용. 엔드포인트는 온프레미스 환경에서 직접 액세스 할 수 없고, 프록시 서버가 온프레미스 파일 게이트웨이에 액세스 할 수 있도록 도와줌.   성능 및 모니터링  Storage Gateway를 Direct Connect와 함계 사용 가능. 온프레미스 게이트웨이와 AWS간 전용 네트워크 연결을 설정함으로써 처리량을 높이고, 네트워크 비용을 줄임.      네트워킹 및 콘텐츠 전송  VPC  AWS에서 논리적으로 격리된 공간을 만들고 가상 네트워크에서 AWS리소스를 시작할 수 있다. 구성  VPC : AWS 내 논리적으로 격리된 가상 네트워크, 선택한 범위에서 VPC의 IP 주소 공간을 정의 서브넷 : 격리된 리소스 그룹을 배치할 수 있는 VPC 한 세그먼트 인터넷 게이트 웨이 : 인터넷에 연결되는 Amazon VPC 측 게이트웨이 NAT 게이트웨이 : 프라이빗 서브넷에 있는 리소스가 인터넷에 액세스 할 수 있게 해주는 고가용성 관리형 네트워크 주소 변환 서비스. 가상 프라이빗 게이트웨이 : VPN에 연결되는 Amazon VPC측 게이트웨이 피어링 연결: 피어링 연결을 사용하여 프라이빗 Ip 주소를 통해 피어링 되는 두 VPC간 트래픽을 라우팅 할 수 있다. VPC 엔드포인트: 인터넷 게이트웨이 VPN, NAT, 디바이스 또는 방화벽 프록시를 사용하지 않고 AWS에서 호스팅되는 서비스에 VPC 내에서부터 비공개로 연결가능 송신 전용 인터넷 게이트웨이: VPC에서 인터넷으로 IPv6 트래픽에 대하여 송신 전용 액세스를 제공하는 상태 저장 게이트웨이   VPC 연결 대상  인터넷(인터넷 게이트웨이) Site to Site VPN 연결을 사용하여 회사 데이터 센터(가상 프라이빗 게이트웨이) 인터넷과 사용자의 회사 데이터 센터 모두(인터넷, 가상 프라이빗 게이트웨이) 다른 AWS 서비스(인터넷게이트웨이, NAT, 가상 프라이빗 게이트웨이 또는 VPC엔드포인트) 다른 VPC(VPC 피어링)   퍼블릭 IP가 없는 인스턴스가 인터넷에 액세스 하는방법  NAT 게이트웨이, NAT 인스턴스를 통해 트래픽을 라우팅하여 인터넷에 액세스, 즉 인터넷을 통과하기위에 위 게이트웨이의 IP 주소를 쓰는것임. VPN연결이 , 직접연결이 지원되는 VPC라면 가상프라이빗게이트웨이의 인터넷 트래픽을 사용자의 기존 데이터센터로 라우팅   site-to-site VPN 연결  사용자의 VPC를 데이터 센터에 연결. IPsec으로 연결. 데이터센터간 전송은 암호화하여 VPN연결을 통해 전송. 두 연결 사이 인터넷게이트웨이는 필요 하지 않다.   VPC 보안  보안그룹, 각 서브넷에 출입하는 네트워크 트래픽은 네트워크 ACL를 통해 허용하거나 거부할 수있다. 보안그룹 : 인스턴스 사이 어떤 트래픽을 허용할지 지정, 상태 저장(소스,목적지저장) ACL : 서브넷 수준에서 작동, 서브넷에 출입하는 트래픽을 평가. 허용 및 거부 규칙 설정 가능, 동일한 서브넷에 있는 인스턴스 간 트래픽은 필터링 하지 않는다. 상태 비저장(목적지만 검사)   트래픽미러링 vs 흐름로그  흐름 로그를 이용하여 네트워크 흐름 로그 수집, 저장 및 분석 가능. 흐름 로그에 캡처되는 정보에는 허용 및 거부되는 트래픽 원본 및 대상 IP 주소, 포트, 프로토콜 번호, 패킷 및 바이트 수, 작업에 대한 정보 포함 트래픽미러링은 페이로드 같은 실제 트래픽 콘텐츠를 분석하여 네트워크 트래픽을 좀 더 깊이 있게 파악할수 있다. 실제 성능 문제의 근본원인을 파악하거나, 정교한 네트워크 공격을 리버스 엔지니어링 하거나 내부자 침해 또는 손상된 워크로드를 감지 및 차단.   DescribeInstances()  위 명령을 실하면 모든 실행 중인 EC2 인스턴스를 반환. 서브넷 필드에 있는 항목으로 EC2-VPC 인스턴스와 EC2-Classic 인스턴스를 구별 할 수 있다. 모든 EBS 볼륨 정보 반환   VPC 인스턴스 갯수  인스턴스의 갯수는 제한이 없지만, 기본 20개이며 이 이상 필요할시 요청   PrivateLink  PrivateLink를 사용하려면 사용자는 PrivateLink로 구동되는 서비스를 위해 인터페이스 유형 VPC 엔드포인트를 생성. 이러한 서비스 엔드포인트는 VPC 내 프라이빗 IP가 연결된 ENI로 표시. 이러한 엔드포인트가 생성되면, 이 IP로 향하는 모든 트래픽이 비공개로 해당 AWS 서비스로 라우팅 됨. 서비스 사용자는 서비스 앞단에 Network Load Balancer를 설정하여 AWS privatelink에 서비스를 탑재할수 있으며 NLB Privatelink서비스를 생성하여 NLB에 등록 할 수 있다. 그리고 IAM역할 허용후 VPC내에 엔드포인트를 설정하여 서비스에 연결   생성가능 리소스  리전별로 AWS계정당 5개의 VPC VPC당 200개의 서브넷 리전별로 AWS계정당 5개의 EIP 주소 VPC당 하나의 인터넷 게이트웨이      데이터베이스  Aurora  고성능 상용 데이터베이스의 속도와 안정성에 오픈 소스 데이터베이스의 간편성과 비용 효율성이 결합된 관계형 데이터베이스 엔진 데이터 베이스 워크로드 최적화 방법은 mysql 또는 postgresql 역시 동시에 처리하는 워크로드가 많다는 것이기 떄문에 Aurora에서 워크로드 처리량을 극대화 하기위해서는 다수의 동시 쿼리와 트랜잭션을 수행하도록 구성해야한다. 하드웨어  최소 스토리지는 10G 최대 64G가지 10G 단위로 자동으로 늘어난다. 프로비저닝 할 필요 없음. 데이터 복구는 자동으로 Aurora는 3개의 가용영역에 6개의 데이터 사본을 유지 관리하기 때문에 자동으로 복구한다. 스냅샷은 최대 20개의 AWS계정과 공유할수 있고, 그 이상은 스냅샷을 퍼블릭으로 설정 하거 한도 증가를 요청. 스냅샷은 이를 공유하는 계정과 같은 리전에 있는 계정에서만 액세스 할 수 있다. 암호화된 스냅샷을 공유 할 수 있다.   서버리스  Aurora 서버리스는 Aurora의 Mysql, Postgresql 호환 에디션에 대한 온디맨드 Auto Scaling 구성이다. 기존 Aurora와 상호 마이그레이션 가능   병렬 쿼리  스토리지 계층에 있는 수천개의 CPU 전체로 푸시다운하여 분산 할 수 있는 기능. 병렬 쿼리가 없다면 Aurora데이터베이스에 대해 실행된 쿼리가 데이터베이스 클러스터 인스턴스 1개에서 모두 실행 된다. 현재 R*인스턴스 패밀리의 인스턴스에서만 병렬 쿼리를 사용할 수 있다.     RDS  클라우드에서 관계형 데이터베이스를 쉽게 설치, 운영 및 확장할 수 있는 관리형 서비스. MySQL, MariaDB, Oracle, SQL Server 또는 PostgreSQL 데이터베이스 기능에 액세스 옵션 다중 AZ배포를 사용하면 RDS에서 자동 장애 조치를 통해 가용 영역 전체에서 동기식 데이터 복제를 관리 데이터베이스 인스턴스  컴퓨팅 및 스토리지 리소스를 제공하는 클라우드의 데이터 베이스 환경 최대 40개의 RDS DB 인스턴스를 보유할 수 있다. 이중 최대 10개는 \u0026ldquo;라이선스 포함 모델에 따른 Oracle, SQL Server DB 인스턴스가 될수 있다. RDS for SQL Server는 단일 DB 인스턴스에서 데이터베이스가 최대 100개로 제한 제한  Amazon Aurora용 RDS: 소프트웨어에서 지정한 제한 없음 MySQL용 RDS: 소프트웨어에서 지정한 제한 없음 MariaDB용 RDS: 소프트웨어에서 지정한 제한 없음 Oracle용 RDS: 인스턴스당 데이터베이스 1개, 데이터베이스당 스키마 수에는 소프트웨어에서 지정한 제한 없음 RDS for SQL Server: 인스턴스당 데이터베이스 최대 100개 참조 항목: Amazon RDS SQL Server 사용 설명서 PostgreSQL용 RDS: 소프트웨어에서 지정한 제한 없음   유지관리 기간은 디폴트 30분이며 DB인스턴스를 다중 AZ배포로 실행하면 유지 관리 이벤트의 영향을 더 줄일 수 있다. 쿼리 튜닝  CPU 사용량이 높을때 성능이 저하 될 수 있다. 이러한 경우 인스턴스 클래스를 상향   예약 인스턴스  RDS 예약 인스턴스는 1년 또는 3년 약정으로 DB인스턴스를 예약 할 수 있는 옵션을 제공하므로 온디맨드 인스턴스 요금보다 DB인스턴스의 시간당 요금을 대폭 할인 받을수 있습니다. 예약 디비 인스턴스는 최대 40개 까지 구매 할 수 있다.   하드웨어  DB 인스턴스 가용성을 유지하면서 DB 인스턴스에 할당된 스토리지 용량을 늘릴 수 있다.   백업  기본 백업 기간은 DB 인스턴스를 백업하기 위해 사용자가 지정하는 기안. 백업기간 중에 백업 프로세스가 시작될 때 스토리지 I/O가 일시적으로 중단 될 수 있으며, 일시적으로 지연시간이 증가하는 것을 경험 할 수 있다.   다중 배포  데이터베이스 내구성 및 가용성 향상 백업 및 복구 그리고 관리 자동화   프록시  데이터베이스 연결을 풀링, 공유하여 애플리케이션의 확장성을 개선 할 수 있다. 데이터베이스 장애조치 시간을 66% 줄인다. 데이터 베이스 AWS IAM인증을 필요에 따라 적용하고, AWS Secret Manager에 자격증명을 안전하게 저장하여 애플리케이션 보안을 개선 할 수 있다.       DynamoDB  모든 규모에서 빠르고 유연한 비관계형 데이터베이스 지원  사용자가 정의한 기본 키를 사용하여 GET/PUT 작업을 지원한다. DynamoDB는 복합 파티션-정렬 키를 파티션 키 요소 및 정렬 키 요소로 인덱싱한다.      분석  Amazon Athena  표준 SQL을 이용해 S3에 저장된 데이터를 간편하게 분석 할 수 있는 대화식 쿼리 서비스. 서버리스 서비스이므로 설정하거나 관리할 인프라가 없으며 데이터 분석을 즉시 시작할 수 있다. Athena로 데이터를 로드할 필요없이 S3에 저장된 데이터를 직접 사용하면 된다. 활용  QuickSight와 통합하여 쉽게 시각화 할 수 있다. 보고서를 생성하거나 ODBC, JDBC 드라이버를 통해 연결된 비즈니스 인텔리전스 도구나 SQL 클라이언트로 데이터를 탐색 할 수도 있다. Redshift vs Athena  Redshift같은 데이터 웨어하우스는 인벤토리 시스템, 금융 시스템, 소매 판매 시스템 등 다양한 소스의 데이터를 하나의 공통 형식으로 취합하여 장기간 보관하고 과거 데이터에서 정교한 비즈니스 보고서를 작성할 필요가 있을떄 사용하는 것이 가장 좋다. 따라서 매우 방대한 양의 테이블에서 수많은 조인을 사용하여 고도의 정형 데이터에 대한 쿼리를 실행해야 할 때는 Redshift를 사용.        AWS Lambda@Edge  Cloud Front용 Lambda를 Lambda@Edge라고 한다.  AWS STS  AWS STS(AWS Security Token Service)를 사용하여 AWS 서비스에 액세스하는 데 사용할 수 있는 권한이 제한된 임시 자격 증명을 가져올 수 있습니다.  AWS OpsWorks  AWS OpsWorks는 Puppet 또는 Chef를 사용하여 클라우드 엔터프라이즈에서 애플리케이션을 구성하고 운영하도록 지원하는 구성 관리 서비스  VPC tenancy  VPC에서 실행하는 각 인스턴스는 테넌시 속성으로 실행  default 인스턴스가 공유된 하드웨어에서 실행됩니다. dedicated 인스턴스가 단일 테넌트 하드웨어에서 실행됩니다. host 인스턴스는 구성을 제어할 수 있는 격리된 서버인 전용 호스트에서 실행됩니다.    Amazon DynamoDB Accelerator(DAX)  DynamoDB용 완전관리형 인 메모리 캐시. DynamoDB 응답 시간을 밀리초에서 마이크로초로 단축.  AWS CloudHSM  AWS CloudHSM은 AWS 클라우드에서 자체 암호화 키를 손쉽게 생성 및 사용할 수 있도록 지원하는 클라우드 기반 하드웨어 보안 모듈(HSM)입니  EBS 볼륨 암호화 방법  데이터 저장전 어플리케이션에서 암호화 서드파티 볼륨 암호화 툴 이용 native 암호화 툴 이용 (OS) 참고 SSL은 데이터를 전송할때 암호화 하는 것.  SQS timeout ?  12 hour  SQS 큐에서 메시지를 받을 수 있는 시간  14days  내구성 99.999999999% 인 S3 유형?  Reduced Redundancy Storage 만 유일하게 아니다.  SQS FIFO  SQS는 무조건 한번은 메기지를 실행한다. FIFO는 디폴트로 제공되지 않는다.  DynomoDB HTTP header 필요한 정보  x-amz-date content-type x-amz-target host  Amazone Athena 지원 파일 형식  JSON, Parquet, ORC  Placement Group  Placement Group 은 AZ당 오직 7개의 인스턴스만 가질수 있다.  EC2 Key Pairs, Security Groups, ELB 는 Region별로 유일하다. 암호화된 EBS 스냅샷  암호화되어있지 않은 EBS 볼륨에서 암호화된 볼륨을 snapshot하거나 암호화된 볼륨을 unencruption할수 없다.  장애허용 Storage gateway  EFS is a mountable file storage for EC2 Storage gateway is primarily used for attaching infrastructure located in a Data center or office to the AWS Storage infastructure  Custom VPC 생성시 자동 생성되는 것  default Security Group Access contol list Route table  Elasticache 제공 서비스  pub/sub, sorted sets, in memory data store. 하지만 Elasticahe는 key value 저장소이므로 관계형 데이터를 저장할 순 없다.  네트워크 트래픽을 고려할 때  저장 트래픽과 일반적인 네트워크 트래픽을 분리하여 생각.  CloudFormation 템플릿 형식  JSON, YAML  Proactive Cyclic Scaling -a utomatically start up and shutdown vms during peak periods, e.g. 9am-5pm mon-fri.\nAMI copy를 했을때 새로운 인스턴스에 복사해야하는 것  Launch permissions, User-defined tag, S3 bucket permissions User data는 AMI에 포함되어있어 따로 복사 안해도 된다.  VPN 커넥션을 AWS와 할때 필요한 것  Customer Gateway , Virtual Private Gateway  Spread Placement Groups  작은 수의 중요 인스턴스가 여러 AZ에 분산되어 관리가 되어야 할때 Spread Placement Groups은 여러 가지 정보를 관리 보호함.  stateless, stateful Lambda 빌링 시스템  MB or RAM , execution duration in 100 ms  VPC Flow logs 생성 타겟 계층  VPC, subnet, network interface levels  Docker가 실행 될 수 있는 AWS 서비스  EC2, Elastic Beanstalk, Fargate  인스턴스의 정보 / 추가되거나 auto scailing 된것 들을 확인하고 싶을떄  Using a Curl or get command to get the latest meta-data from http://111.111.111.111/latest/meta-data  site-to-site VPN 연결을 위한 서비스  A private subnet in your VPC A VPC with hardware VPN access An on premis customer gateway A virtual private gateway  Route53 alase, cname 차이 Lambda 다이렉트 서비스  API gateway Elastic load balancer Kinesis data firehouse  Gateway-Cached, File Gateway  Cached 볼륨은 중요 저장소에 들어가는 비용을 줄이고, 저장소의 사이즈를 최소화한다.  Cloudwatch 로그 디폴트 옵션값  매 5분, 수정하면 1분까지  "});index.add({'id':64,'href':'/posts/cloud/aws/exam/summary_word/','title':"AWS 용어 정리",'content':"Basic service architecture Auto Scaling group   애플리케이션의 로드를 처리할 수 있는 정확한 수의 Amazon EC2 인스턴스를 보유하도록 보장\n  Auto Scaling 그룹이라는 EC2 인스턴스 모음을 생성하며, 최소값과 최대값을 지정하며 이 범위를 넘어서지 않는다.\n  bastion host  보루, 요새라는 뜻으로 중세 시대에 영주나 왕이 살고 있는 중요한 기지인 성을 둘러싸고 있는 방어막 컴퓨터 보안에서도 이런 의미를 가져와서 보호된 네트워크에 접근하기 위해 유일하게 외부에 노출되는 호스트를 Bastion 호스트라고 정의  Oracle Data Pump  import complex databases or databases that are several hundred megabytes or several terabytes in size.  인터넷 게이트 웨이  수평 확장되고, 가용성이 높은 중복 VPC 구성 요소로, VPC의 인스턴스와 인터넷 간에 통신할 수 있게 해줍니다 인터넷 라우팅 기능 트래픽에 대한 VPC 라우팅 테이블에 대상을 제공, IPv4 주소가 할당된 인스턴스에 대해 NAT를 수행하는 두가지 목적이 있다.  NAT 게이트 웨이  NAT 게이트웨이를 사용하여 프라이빗 서브네스이 인스턴스를 인터넷 또는 기타 AWS서비스에 연결하는 한편, 인터넷에서 해당 인스턴스와의 연결을 시작하지 못하게 할수 있다.  NAT 게이트웨이 기본사항  NAT 게이트웨이가 속할 퍼블릭 서브넷을 지정 탄력적 IP 주소 지정 인터넷 바운드 트래픽이 NAT 게이트웨이를 가리키도록 하나 이상의 프라이빗 서브넷과 연결된 라우팅 테이블을 업데이트      Cross-region key pairs   Key pairs consist of a public and private key, where you use the private key to create a digital 44 IT Certification Guaranteed, The Easy Way! signature, and then AWS uses the corresponding public key to validate the signature.\n  Key pairs are used only for Amazon EC2 and Amazon CloudFront.\n  Amazon Resource Name  Amazon 리소스 이름(ARN)은 AWS 리소스를 고유하게 식별 AM 정책, Amazon Relational Database Service(Amazon RDS) 태그 및 API 호출과 같은 모든 AWS에서 리소스를 명료하게 지정해야 하는 경우 ARN이 필요합니다.  Amazon EBS 볼륨 유형 RAID  Redundant Array of Independent Disk (독립된 디스크의 복수 배열) Redundant Array of Inexpensive Disk (저렴한 디스크의 복수 배열) RAID는 여러개의 디스크를 묶어 하나의 디스크 처럼 사용하는 기술  기대효과  대용량의 단일 볼륨을 사용하는 효과 디스크 I/O 병렬화로 인한 성능 향상 (RAID 0, RAID 5, RAID 6 등) 데이터 복제로 인한 안정성 향상 (RAID 1 등)      egress-only - 외부 전용 인터넷 게이트웨이 - 외부 전용 인터넷 게이트웨이는 수평 확장되고 가용성이 높은 중복 VPC 구성 요소로서, VPC의 인스턴스에서 인터넷으로 IPv6를 통한 아웃바운드 통신을 가능케 하되 인터넷에서 해당 인스턴스와의 IPv6 연결을 시작하지 못하게 할 수 있습니다. - IPv4를 통한 아웃바운드 전용 인터넷 통신을 사용하려면 NAT 게이트웨이를 사용  "});index.add({'id':65,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/springboot/springsecurity_#1/','title':"스프링 시큐리티 이해하기",'content':"![스크린샷 2019-12-05 오전 11.13.11](/Users/hoonoh/Desktop/스크린샷 2019-12-05 오전 11.13.11.png)\n스프링시큐리티 시나리오\n 인증 권한체크  Authentication 객체  이름 권한 인증여부  AuthenticatioFilter 에서 사용자 정보를 꺼내 Authentication 객체를 만들고,\nAuthenticationProvider에 전달한다.\nAuthenticationProvider에서는 실제 인증이 이루어 지고, 인증 결과를 Authentication에 담아 SecurityContextHolder에 저장 성공 여부에 따라 handler를 실행한다.\n"});index.add({'id':66,'href':'/posts/framework/springboot/springsecurity_#1/','title':"스프링 시큐리티 이해하기",'content':"![스크린샷 2019-12-05 오전 11.13.11](/Users/hoonoh/Desktop/스크린샷 2019-12-05 오전 11.13.11.png)\n스프링시큐리티 시나리오\n 인증 권한체크  Authentication 객체  이름 권한 인증여부  AuthenticatioFilter 에서 사용자 정보를 꺼내 Authentication 객체를 만들고,\nAuthenticationProvider에 전달한다.\nAuthenticationProvider에서는 실제 인증이 이루어 지고, 인증 결과를 Authentication에 담아 SecurityContextHolder에 저장 성공 여부에 따라 handler를 실행한다.\n"});index.add({'id':67,'href':'/posts/opensource/hexo/hexo-command/','title':"hexo command",'content':"$ hexo new [layout] \u0026lt;title\u0026gt; layout : 기본 레이아웃은 3가지 종류가 있고 각기 다른 경로에 보관됩니다.\n post(Default) page draft title : 파일 제목  "});index.add({'id':68,'href':'/tags/hexo-command/','title':"hexo-command",'content':""});index.add({'id':69,'href':'/docs/categories/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0/','title':"빅데이터",'content':"빅데이터\n"});index.add({'id':70,'href':'/docs/categories/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0/%EC%B9%B4%ED%94%84%EC%B9%B4/','title':"카프카",'content':"빅데이터\n"});index.add({'id':71,'href':'/tags/kafka/','title':"Kafka",'content':""});index.add({'id':72,'href':'/docs/categories/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0/%EC%B9%B4%ED%94%84%EC%B9%B4/how_to_build_kafka_with_intellij/','title':"카프카(Kafka) 실행시키기 - Intellj",'content':"앞선 내용에서 Kafka에서 제공하는 스크립트를 통해 카프카를 실행 시켜 보았다.\n오늘은 카프카를 IDE를 통하여 실행을 시킴으로서 Kafka가 내부적으로 어떻게 동작을 하는지 더 정확히 확인을 해보려고 한다\n오늘의 목표\n Intellij를 이용하여 Kafka 빌드  우선 Kafka 빌드에 앞서 선행적으로 준비가 되어야 할 것이 있다.\n git Java 8 IntelliJ  위 환경이 준비가 되었다는 가정하에 문서를 보면 된다.\n 인텔리제이의 경우 Scala, Gradle을 플러그인 형태로 아주 쉽게 다운로드 받을 수 있다.\n만약 이클립스를 사용한다면 위 두가지를 다운로드 받거나 플러그인이 있다면 추가해서 사용하자.\n카프카는 Scala 로 작성된 어플리케이션 이다.\n 카프카(Kafka) 실행시키기 with Intellij Step-1. Git clone git clone https://github.com/apache/kafka.git 위 명령어를 통해 Kafka 소스를 내려 받는다.\nStep-2. Build 카프카의 실행에 앞서 실행에 필요한 서드 파티 파일들을 받아야 한다.\n./gradlew clean ./gradlew jar Step-3. Run Kafka VM Options -Dkafka.logs.dir=/tmp/kafka -Dlog4j.configuration=file:config/log4j.properties Program arguments config/server.properties VM Options은 server.properties 에 설정해둔 로그파일 저장 위치와 log4j 설정 정보를 입력한다.\nError-#1 SLF4J: Failed to load class \u0026quot;org.slf4j.impl.StaticLoggerBinder\u0026quot;. SLF4J: Defaulting to no-operation (NOP) logger implementation SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. SLF4J: Failed to load class \u0026quot;org.slf4j.impl.StaticMDCBinder\u0026quot;. SLF4J: Defaulting to no-operation MDCAdapter implementation. SLF4J: See http://www.slf4j.org/codes.html#no_static_mdc_binder for further details. 실행했을때 위와 같은 에러로그가 발생한다면\nkafka/build.gradle project(':core') { dependencies { compile project(':clients') compile libs.slf4jlog4j12 .... } } kafka/gradle/dependencies.gradle versions += [ .... zstd: \u0026quot;1.4.3-1\u0026quot;, slf4jlog4j12: \u0026quot;2.0.0-alpha1\u0026quot; ] libs += [ ..... httpclient: \u0026quot;org.apache.httpcomponents:httpclient:$versions.httpclient\u0026quot;, slf4jlog4j12: \u0026quot;org.slf4j:slf4j-log4j12:$versions.slf4jlog4j12\u0026quot; ] 위와 같이 \u0026lsquo;slf4jlog4j12'를 추가.\nRef. https://medium.com/@chandreshpancholi007/how-to-setup-apache-kafka-source-code-on-intellij-b204966d7c2\n"});index.add({'id':73,'href':'/posts/opensource/bigdata/kafka/how_to_build_kafka_with_intellij/','title':"카프카(Kafka) 실행시키기 - Intellj",'content':"앞선 내용에서 Kafka에서 제공하는 스크립트를 통해 카프카를 실행 시켜 보았다.\n오늘은 카프카를 IDE를 통하여 실행을 시킴으로서 Kafka가 내부적으로 어떻게 동작을 하는지 더 정확히 확인을 해보려고 한다\n오늘의 목표\n Intellij를 이용하여 Kafka 빌드  우선 Kafka 빌드에 앞서 선행적으로 준비가 되어야 할 것이 있다.\n git Java 8 IntelliJ  위 환경이 준비가 되었다는 가정하에 문서를 보면 된다.\n 인텔리제이의 경우 Scala, Gradle을 플러그인 형태로 아주 쉽게 다운로드 받을 수 있다.\n만약 이클립스를 사용한다면 위 두가지를 다운로드 받거나 플러그인이 있다면 추가해서 사용하자.\n카프카는 Scala 로 작성된 어플리케이션 이다.\n 카프카(Kafka) 실행시키기 with Intellij Step-1. Git clone git clone https://github.com/apache/kafka.git 위 명령어를 통해 Kafka 소스를 내려 받는다.\nStep-2. Build 카프카의 실행에 앞서 실행에 필요한 서드 파티 파일들을 받아야 한다.\n./gradlew clean ./gradlew jar Step-3. Run Kafka VM Options -Dkafka.logs.dir=/tmp/kafka -Dlog4j.configuration=file:config/log4j.properties Program arguments config/server.properties VM Options은 server.properties 에 설정해둔 로그파일 저장 위치와 log4j 설정 정보를 입력한다.\nError-#1 SLF4J: Failed to load class \u0026quot;org.slf4j.impl.StaticLoggerBinder\u0026quot;. SLF4J: Defaulting to no-operation (NOP) logger implementation SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. SLF4J: Failed to load class \u0026quot;org.slf4j.impl.StaticMDCBinder\u0026quot;. SLF4J: Defaulting to no-operation MDCAdapter implementation. SLF4J: See http://www.slf4j.org/codes.html#no_static_mdc_binder for further details. 실행했을때 위와 같은 에러로그가 발생한다면\nkafka/build.gradle project(':core') { dependencies { compile project(':clients') compile libs.slf4jlog4j12 .... } } kafka/gradle/dependencies.gradle versions += [ .... zstd: \u0026quot;1.4.3-1\u0026quot;, slf4jlog4j12: \u0026quot;2.0.0-alpha1\u0026quot; ] libs += [ ..... httpclient: \u0026quot;org.apache.httpcomponents:httpclient:$versions.httpclient\u0026quot;, slf4jlog4j12: \u0026quot;org.slf4j:slf4j-log4j12:$versions.slf4jlog4j12\u0026quot; ] 위와 같이 \u0026lsquo;slf4jlog4j12'를 추가.\nRef. https://medium.com/@chandreshpancholi007/how-to-setup-apache-kafka-source-code-on-intellij-b204966d7c2\n"});index.add({'id':74,'href':'/docs/categories/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0/%EC%B9%B4%ED%94%84%EC%B9%B4/how_to_build_kafka_source_intellij/','title':"카프카(Kafka) 실행시키기 - 스크립트",'content':"이제 카프카를 실행 시켜 보자!!\n목표는 아래와 같다.\n 카프카를 설치해서 빌드된 스크립트를 이용하여 카프카의 동작여부를 확인해보자. 최종적으로는 Intellij를 통해 빌드해보며 어떤 식으로 돌아가는지 코드로 확인해 보자.  카프카(Kafka) 실행시키기 - 스크립트 Step.1 DownLoad 카프카 공식 홈페이지에서 다운로드!!\n현재기준 kafka 최신 버전은 2.3.0이다.\n$ tar -zvxf kafka_2.12-2.3.0.tgz $ cd kafka_2.12-2.3.0.tgz 다운로드 받아서 압축을 푹어준다.\nStep.2 실행시키기 카프카를 실행 시켜주면 된다.\n먼저 카프카는 기본적으로 Zookeeper에서 관리가 되고 있기 때문에 Zookeeper가 실행이 되어야만 동작한다.\n따라서 Kafka실행전 Zookeeper를 실행해야 한다.\n먼저 두 어플리케이션을 실행시키기 전에 설정파일을 일부 수정한다.\nzookeeper.properties # the directory where the snapshot is stored. dataDir=/tmp/zookeeper # the port at which the clients will connect clientPort=2181 # disable the per-ip limit on the number of connections since this is a non-production config maxClientCnxns=0 server.1 = 127.0.0.1\u0026quot;2888:3888 //.[number] 는 아이디 값. server.properties . . . ############################# Server Basics ############################# # The id of the broker. This must be set to a unique integer for each broker. broker.id=1 ############################# Socket Server Settings ############################# listeners=PLAINTEXT://:9092 advertised.listeners=PLAINTEXT://127.0.0.1:9092 ############################# Zookeeper ############################# # Zookeeper connection string (see zookeeper docs for details). # This is a comma separated host:port pairs, each corresponding to a zk # server. e.g. \u0026quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\u0026quot;. # You can also append an optional chroot string to the urls to specify the # root directory for all kafka znodes. zookeeper.connect=127.0.0.1:2181 # Timeout in ms for connecting to zookeeper zookeeper.connection.timeout.ms=6000 위 와 같이 zookeeper에 서버정보를 추가하고 (복수개 설정가능)\nKafka의 server 프로퍼티에도 해당 zookeeper의 정보를 입력해주면 된다.\n$ zookeeper-server-start.sh config/zookeeper.properties $ kafka-server-start.sh config/server.properties 그리고 두 어플리케이션을 실행한다.\n이제 Topic을 생성 후 Producer 인풋 메시지를 저장하고 Consumer로 받아보자.\nkafka-topics.sh --create --zookeeper 127.0.0.1:2181 --replication-factor 1 --partitions 1 --topic test Created topic test. 다운받은 소스에서 토픽을 생성하는 스크립트를 이용하여 Test 라는 토픽을 생성하였다.\n Topic은 추가로 생성, 삭제가 가능하다\n 이제 Topic과 마찬가지로 생산자와 소비자 스크립트를 이용해서 메시지를 교환하여 보자\nkafka-console-producer.sh --ber-list 127.0.0.1:9092 --topic test \u0026gt;Test \u0026gt;Hi \u0026gt; 위와 같이 생산자가 메시지를 입력한다.\nkafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic test --from-beginning Test Hi \u0026ndash;from-beginning 은 처음부터 메시지를 읽겠다는 뜻이고 입력한 메시지를 읽어온것을 확인 할 수 있다.\n"});index.add({'id':75,'href':'/posts/opensource/bigdata/kafka/how_to_build_kafka_source_intellij/','title':"카프카(Kafka) 실행시키기 - 스크립트",'content':"이제 카프카를 실행 시켜 보자!!\n목표는 아래와 같다.\n 카프카를 설치해서 빌드된 스크립트를 이용하여 카프카의 동작여부를 확인해보자. 최종적으로는 Intellij를 통해 빌드해보며 어떤 식으로 돌아가는지 코드로 확인해 보자.  카프카(Kafka) 실행시키기 - 스크립트 Step.1 DownLoad 카프카 공식 홈페이지에서 다운로드!!\n현재기준 kafka 최신 버전은 2.3.0이다.\n$ tar -zvxf kafka_2.12-2.3.0.tgz $ cd kafka_2.12-2.3.0.tgz 다운로드 받아서 압축을 푹어준다.\nStep.2 실행시키기 카프카를 실행 시켜주면 된다.\n먼저 카프카는 기본적으로 Zookeeper에서 관리가 되고 있기 때문에 Zookeeper가 실행이 되어야만 동작한다.\n따라서 Kafka실행전 Zookeeper를 실행해야 한다.\n먼저 두 어플리케이션을 실행시키기 전에 설정파일을 일부 수정한다.\nzookeeper.properties # the directory where the snapshot is stored. dataDir=/tmp/zookeeper # the port at which the clients will connect clientPort=2181 # disable the per-ip limit on the number of connections since this is a non-production config maxClientCnxns=0 server.1 = 127.0.0.1\u0026quot;2888:3888 //.[number] 는 아이디 값. server.properties . . . ############################# Server Basics ############################# # The id of the broker. This must be set to a unique integer for each broker. broker.id=1 ############################# Socket Server Settings ############################# listeners=PLAINTEXT://:9092 advertised.listeners=PLAINTEXT://127.0.0.1:9092 ############################# Zookeeper ############################# # Zookeeper connection string (see zookeeper docs for details). # This is a comma separated host:port pairs, each corresponding to a zk # server. e.g. \u0026quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002\u0026quot;. # You can also append an optional chroot string to the urls to specify the # root directory for all kafka znodes. zookeeper.connect=127.0.0.1:2181 # Timeout in ms for connecting to zookeeper zookeeper.connection.timeout.ms=6000 위 와 같이 zookeeper에 서버정보를 추가하고 (복수개 설정가능)\nKafka의 server 프로퍼티에도 해당 zookeeper의 정보를 입력해주면 된다.\n$ zookeeper-server-start.sh config/zookeeper.properties $ kafka-server-start.sh config/server.properties 그리고 두 어플리케이션을 실행한다.\n이제 Topic을 생성 후 Producer 인풋 메시지를 저장하고 Consumer로 받아보자.\nkafka-topics.sh --create --zookeeper 127.0.0.1:2181 --replication-factor 1 --partitions 1 --topic test Created topic test. 다운받은 소스에서 토픽을 생성하는 스크립트를 이용하여 Test 라는 토픽을 생성하였다.\n Topic은 추가로 생성, 삭제가 가능하다\n 이제 Topic과 마찬가지로 생산자와 소비자 스크립트를 이용해서 메시지를 교환하여 보자\nkafka-console-producer.sh --ber-list 127.0.0.1:9092 --topic test \u0026gt;Test \u0026gt;Hi \u0026gt; 위와 같이 생산자가 메시지를 입력한다.\nkafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic test --from-beginning Test Hi \u0026ndash;from-beginning 은 처음부터 메시지를 읽겠다는 뜻이고 입력한 메시지를 읽어온것을 확인 할 수 있다.\n"});index.add({'id':76,'href':'/docs/categories/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0/%EC%B9%B4%ED%94%84%EC%B9%B4/what_is_kafka/','title':"카프카(Kafka) 이해하기",'content':"카프카(Kafka) 이해하기 오늘은 카프카에 대해서 간략하게 알아보며 간단하게 실행을 시켜보는 시간을 가져보자.\n그냥 궁금해서.. :)\n​\tLet\u0026rsquo;s get it!\n메시징 서비스 먼저 카프카는 메시지 퍼블리싱 어플리케이션으로서 메시지를 서로 전달할 수 있도록 연결하는 오픈소스입니다.\n카프카는 특히 실시간 대량 정보를 다루는데에 유용하게 사용될 수 있는데, 여러 정보를 소비자에게 빠르게 전달하는 과정에서 생기는 문제점을 해결하기 위한 솔루션입니다.\n 카프카는 활동 스트림 데이터를 처리하는 데 유용하다는 점에서 스크라이브 또는 플럼 과 유사해 보이지만 아키텍처 관점에서는 액티브엠큐, 래빗엠큐 같은 메시징 시스템에 더 가깝다.\n 카프카 특징 카프가는 아래와 같은 특징을 가집니다.\n 비휘발성메시징 : 빅데이터로 부터 실제 가치를 끌어내기 위해선 어떠한 정보유실도 있어선 안되는데, 카프카는 O(1)의 디스크 구조로 디자인 되어서 많은 데이터의 저장 메시지라도 상수 시간의 성능을 제공 높은 처리량 : 초당 수백건 (정확하지 않음) 분산 : 카프카 서버들을 대상으로 메시지 파티셔닝을 지원. 또한 소비자 장비들이 속한 클러스터 단위 분산 소비를 지원하는데 파티션 단위로만 순서를 가짐 다양한 클라이언트 지원 : 자바, 루비, 닷넷, PHP등등 실시간  카프카 목적 카프카의 목적은 하둡시스템으로의 병렬 로드와 클러스터의 장비들에 의한 실시간 분할 소비를 지원해서 오프라인\n과 온라인 처리를 통합하는것을 목적으로 합니다.\n카프카 사용 예  링크드인, 데이터시프트, 트위터 , 포스퀘어, 스퀘어  카프카 메시징 처리 과정 카프카 디자인의 핵심\n 생산자는 카프카 브로커에 생성된 카프카 토픽으로 메시지를 보낸다. 카프카 브로커는 카프카 서버로 동작 소비자는 메시지를 얻기 위해 카프카 토픽을 구독한다.  카프카 주요 설계 요소  카프카의 핵심은 메시지를 파일 시스템에 저장하고 캐싱하는 것이다. 데이터는 즉시 OS커널 페이지에 쓴다. 데이터를 디스크에 캐시하고 플러시하는 것은 설정할 수 있다. 카프카는 필요에 따라 메시지 소비후 다시 메시지를 소비 할 수 있게 메시지의 장기 보관을 지원 카프카는 네트워크 부하를 줄이기 위해 메시지를 그룹으로 묶는 메시지 집합을 사용 메시지 소비에 대한 메타정보가 서버에 저장되는 대부분의 메시지 시스템과 다르게 카프카는 소비자 레벨에서 소비된 메시지의 상태를 가지고 있다.  실패에 따른 메시지 유실 해결 단일 메시지의 복수 전달   소비자는 상태를 주키퍼에 저장(기본설정), 온라인 트랜잭션 처리 애플리케이션으로 사용가능 카프카는 생산자 소비자 Push and Pull 모델 방식. 카프카에서 마스터 개념은 없고 모든 브로커를 피어로 다룸으로, 브로커의 메타 데이터는 주키퍼에 보관하고 생산자 소비자에 공유하므로, 브로커의 추가,제거가 쉽다. 생산자는 메시지를 브로커에 보내는데 , 비동기, 동기 모드를 선택할 수 있다.  카프카 메시지 압축  Gzip, Snappy 지원 네트워크단의 부하를 줄이기 위해 압축지원, 소비자단은 부하가 증가.  카프카의 클러스터 미러링 카프카 미러링 기능은 기존 클러스터의 복사본을 만드는데 사용한다.\nex \u0026gt; 활성 데이터 센터로부터 비활성 데이터 센터로 복제하는 경우\n카프카에서 원본 클러스터로부터 대상 클러스터로 미러링을 만드는 도구를 제공 ( 살펴보장!)\n카프카 리플리케이션(이해 필요) 메시지 파티셔닝\n어떻게 파티션될 것인지 메시지 생산자에 의해 결정, 브로커는 메시지가 들어온 순서대로 저장.\n파티션의 개수는 브로커 내의 각 토픽에 설정할 수 있다.\nKafka 생산자 생산자 어플리케이션은 메시지를 만들고 나중의 소비를 위해 카프카 브로커에 배포한다.\n생산자는 다양한 성격일 수 있다.\n 애플리케이션 프론트엔드 서비스의 백엔드 프록시 애플리케이션 하둡 생산자 etc  메시지 생산자를 위한 카프카 API 자바 생산자 API 카프카는 단일 또는 다중 토픽에 메시지들을 생성하는 Producer\u0026lt;K,V\u0026gt; 클래스를 제공\n파티션은 선택사항이다.\n생산자는 스칼로 작성된 자바의 제네릭 타입이기 때문에 매개변수의 타입을 기술해야함.\nKafka 소비자 소비자 어플리케이션은 메시지들을 소비하고 메시지들로부터 데이터를 추출하는 어플리케이션이다.\n소비자 역시 다양한 성격일 수 있다.\n 실시간 분석 어플리케이션 NoSQL관련 어플리케이션 데이터 웨어하우스 솔루션 백엔드 서비스 하둡 소비자 구독 서비스 etc  메시지 소비자를 위한 카프카 API 카프카는 자바 기반 Consumer로 두가지 타입의 API를 제공\n 상위 레벨 소비자 단순 소비자  상위 레벨 소비자 API는 소비자 API의 하위 레벨의 구현을 추상화해 제공\n반변 단순 소비자 API는 기본 하위 레벨의 구현을 오버라이드할 수 있어 더 많은 제어를 할 수 있다.\n상위 레벨 소비자 API  상위 레벨의 소비자 API는 메시지 오프셋을 다룰 필요 없이 데이터를 쓸 때 사용\n메시지 소비시 일어나는 대부분 하위 레벨의 기능을 추상화하였다.\n특징으로는 주키퍼의 특정 영역에 최근 읽은 오프셋을 저장하고 오프셋은 프로세스가 시작할 때 카프카에 제공된 소비자 그룹 이름에 기반을 둬서 저장한다.\n소비자 그룹 소비자 그룹의 이름은 클러스터에서 유일하고 전역적이다.\n이미 사용중인 소비자 그룹 이름을 가진 새로운 소비자는 시스템에 예기치 못한 행동을 발생 시킬 수 있다.\n새로운 프로세스가 기존 소비자 그룹 이름을 가지고 시작하면 스레드 간 리발란스를 작동시키는데\n리발란스 후 새로운 프로세스로 가야하는 몇몇 메시지들이 이전 프로세스로 갈 수 있고 오작동을 초래할 수도 있다\n(현재 버전 2.13 에서는 확인해봐야 할 것 같다.)\n해결방법은 기존 소비자 그룹의 이름을 가지는 새로운 소비자를 시작 하려면 기존의 모든 소비자를 중단\u0026hellip;\n"});index.add({'id':77,'href':'/posts/opensource/bigdata/kafka/what_is_kafka/','title':"카프카(Kafka) 이해하기",'content':"카프카(Kafka) 이해하기 오늘은 카프카에 대해서 간략하게 알아보며 간단하게 실행을 시켜보는 시간을 가져보자.\n그냥 궁금해서.. :)\n​\tLet\u0026rsquo;s get it!\n메시징 서비스 먼저 카프카는 메시지 퍼블리싱 어플리케이션으로서 메시지를 서로 전달할 수 있도록 연결하는 오픈소스입니다.\n카프카는 특히 실시간 대량 정보를 다루는데에 유용하게 사용될 수 있는데, 여러 정보를 소비자에게 빠르게 전달하는 과정에서 생기는 문제점을 해결하기 위한 솔루션입니다.\n 카프카는 활동 스트림 데이터를 처리하는 데 유용하다는 점에서 스크라이브 또는 플럼 과 유사해 보이지만 아키텍처 관점에서는 액티브엠큐, 래빗엠큐 같은 메시징 시스템에 더 가깝다.\n 카프카 특징 카프가는 아래와 같은 특징을 가집니다.\n 비휘발성메시징 : 빅데이터로 부터 실제 가치를 끌어내기 위해선 어떠한 정보유실도 있어선 안되는데, 카프카는 O(1)의 디스크 구조로 디자인 되어서 많은 데이터의 저장 메시지라도 상수 시간의 성능을 제공 높은 처리량 : 초당 수백건 (정확하지 않음) 분산 : 카프카 서버들을 대상으로 메시지 파티셔닝을 지원. 또한 소비자 장비들이 속한 클러스터 단위 분산 소비를 지원하는데 파티션 단위로만 순서를 가짐 다양한 클라이언트 지원 : 자바, 루비, 닷넷, PHP등등 실시간  카프카 목적 카프카의 목적은 하둡시스템으로의 병렬 로드와 클러스터의 장비들에 의한 실시간 분할 소비를 지원해서 오프라인\n과 온라인 처리를 통합하는것을 목적으로 합니다.\n카프카 사용 예  링크드인, 데이터시프트, 트위터 , 포스퀘어, 스퀘어  카프카 메시징 처리 과정 카프카 디자인의 핵심\n 생산자는 카프카 브로커에 생성된 카프카 토픽으로 메시지를 보낸다. 카프카 브로커는 카프카 서버로 동작 소비자는 메시지를 얻기 위해 카프카 토픽을 구독한다.  카프카 주요 설계 요소  카프카의 핵심은 메시지를 파일 시스템에 저장하고 캐싱하는 것이다. 데이터는 즉시 OS커널 페이지에 쓴다. 데이터를 디스크에 캐시하고 플러시하는 것은 설정할 수 있다. 카프카는 필요에 따라 메시지 소비후 다시 메시지를 소비 할 수 있게 메시지의 장기 보관을 지원 카프카는 네트워크 부하를 줄이기 위해 메시지를 그룹으로 묶는 메시지 집합을 사용 메시지 소비에 대한 메타정보가 서버에 저장되는 대부분의 메시지 시스템과 다르게 카프카는 소비자 레벨에서 소비된 메시지의 상태를 가지고 있다.  실패에 따른 메시지 유실 해결 단일 메시지의 복수 전달   소비자는 상태를 주키퍼에 저장(기본설정), 온라인 트랜잭션 처리 애플리케이션으로 사용가능 카프카는 생산자 소비자 Push and Pull 모델 방식. 카프카에서 마스터 개념은 없고 모든 브로커를 피어로 다룸으로, 브로커의 메타 데이터는 주키퍼에 보관하고 생산자 소비자에 공유하므로, 브로커의 추가,제거가 쉽다. 생산자는 메시지를 브로커에 보내는데 , 비동기, 동기 모드를 선택할 수 있다.  카프카 메시지 압축  Gzip, Snappy 지원 네트워크단의 부하를 줄이기 위해 압축지원, 소비자단은 부하가 증가.  카프카의 클러스터 미러링 카프카 미러링 기능은 기존 클러스터의 복사본을 만드는데 사용한다.\nex \u0026gt; 활성 데이터 센터로부터 비활성 데이터 센터로 복제하는 경우\n카프카에서 원본 클러스터로부터 대상 클러스터로 미러링을 만드는 도구를 제공 ( 살펴보장!)\n카프카 리플리케이션(이해 필요) 메시지 파티셔닝\n어떻게 파티션될 것인지 메시지 생산자에 의해 결정, 브로커는 메시지가 들어온 순서대로 저장.\n파티션의 개수는 브로커 내의 각 토픽에 설정할 수 있다.\nKafka 생산자 생산자 어플리케이션은 메시지를 만들고 나중의 소비를 위해 카프카 브로커에 배포한다.\n생산자는 다양한 성격일 수 있다.\n 애플리케이션 프론트엔드 서비스의 백엔드 프록시 애플리케이션 하둡 생산자 etc  메시지 생산자를 위한 카프카 API 자바 생산자 API 카프카는 단일 또는 다중 토픽에 메시지들을 생성하는 Producer\u0026lt;K,V\u0026gt; 클래스를 제공\n파티션은 선택사항이다.\n생산자는 스칼로 작성된 자바의 제네릭 타입이기 때문에 매개변수의 타입을 기술해야함.\nKafka 소비자 소비자 어플리케이션은 메시지들을 소비하고 메시지들로부터 데이터를 추출하는 어플리케이션이다.\n소비자 역시 다양한 성격일 수 있다.\n 실시간 분석 어플리케이션 NoSQL관련 어플리케이션 데이터 웨어하우스 솔루션 백엔드 서비스 하둡 소비자 구독 서비스 etc  메시지 소비자를 위한 카프카 API 카프카는 자바 기반 Consumer로 두가지 타입의 API를 제공\n 상위 레벨 소비자 단순 소비자  상위 레벨 소비자 API는 소비자 API의 하위 레벨의 구현을 추상화해 제공\n반변 단순 소비자 API는 기본 하위 레벨의 구현을 오버라이드할 수 있어 더 많은 제어를 할 수 있다.\n상위 레벨 소비자 API  상위 레벨의 소비자 API는 메시지 오프셋을 다룰 필요 없이 데이터를 쓸 때 사용\n메시지 소비시 일어나는 대부분 하위 레벨의 기능을 추상화하였다.\n특징으로는 주키퍼의 특정 영역에 최근 읽은 오프셋을 저장하고 오프셋은 프로세스가 시작할 때 카프카에 제공된 소비자 그룹 이름에 기반을 둬서 저장한다.\n소비자 그룹 소비자 그룹의 이름은 클러스터에서 유일하고 전역적이다.\n이미 사용중인 소비자 그룹 이름을 가진 새로운 소비자는 시스템에 예기치 못한 행동을 발생 시킬 수 있다.\n새로운 프로세스가 기존 소비자 그룹 이름을 가지고 시작하면 스레드 간 리발란스를 작동시키는데\n리발란스 후 새로운 프로세스로 가야하는 몇몇 메시지들이 이전 프로세스로 갈 수 있고 오작동을 초래할 수도 있다\n(현재 버전 2.13 에서는 확인해봐야 할 것 같다.)\n해결방법은 기존 소비자 그룹의 이름을 가지는 새로운 소비자를 시작 하려면 기존의 모든 소비자를 중단\u0026hellip;\n"});index.add({'id':78,'href':'/tags/agile/','title':"Agile",'content':""});index.add({'id':79,'href':'/posts/seminar/agile/agile_daily_scrum/','title':"Agile daily scrum",'content':"#스크럼 마스터 역할\n###진행\n 이슈 유도  ###개발속도 확인 및 고융\n 번다운차트 활용 필요한 경우 우선순위  ###장애요소 수집 및 해소\n###커뮤니케이션\n"});index.add({'id':80,'href':'/tags/crud/','title':"CRUD",'content':""});index.add({'id':81,'href':'/tags/database/','title':"database",'content':""});index.add({'id':82,'href':'/tags/h2/','title':"H2",'content':""});index.add({'id':83,'href':'/tags/migration/','title':"migration",'content':""});index.add({'id':84,'href':'/posts/project/backup-program/','title':"Migration_java_program",'content':"Autor : 오 훈\nTitle : Backup-program\nBackup-program (GitHub Link) 1. 시스템 구성 1.1 역할 Master  0.1초 주기로 Random 하게 생성되는 정수 값을 TimeStamp와 함께 DB에 저장. 소켓 연결 시 1초 단위로 꺼내서 데이터 전달.  Slave  소켓 통신을 이용하여 DataSource로부터 데이터를 가져옴. 설정한 back up DB에 데이터 저장.  1.2 개발 방법  다중 Slave 접속을 위한 멀티 쓰레드 활용 ScheduledExecutorService를 이용한 Thread trigger Slave 세션별 Offset맵핑을 통한 데이터 유실 보안  2. Master 상세 설명 Master는 위와 같은 데이터 플로우를 가지고 있습니다.\n코드의 실행은 다음과 같습니다.\n  Generator 실행\nMaster 프로그램은 데이터를 생성하는 중요한 프로그램입니다. 따라서 멀티 유저와의 소켓 연결시 예측할수 없는 에러로 부터 최대한 분리하여야 하기때문에 별도의 Thread로 실행합니다. 즉, 유저의 연결과 상관없이 Master가 실행이 되면 데이터 생성 및 적재를 시작합니다.\n  SocketService 실행 SocketService는 다중 연결 접속을 지원합니다. 먼저 SocketService는 소켓서버를 생성합니다. 이후 Client(Slave)가 연결이 되면, WorkerPool(쓰레드풀)에서 Thread를 생성하여 해당 소켓 연결을 별도의 Thread로 동작 시킵니다. Thread실행 후, 다른 소켓 연결을 대기합니다. ​\n  2.1 코드 설명  2.1.1 ServerStarter public class ServerStarter { private final static Logger logger = LogManager.getLogger(ServerStarter.class); private static void Start(AppProperties props) { // 데이터 제너레이터 실행 \tGenerator generator = new Generator(props); generator.start(); //소켓 서비스 실행 \tSocketService service = new SocketService(); service.initialize(props); service.start(); } public static void main(String[] args) { String propFile = \u0026#34;\u0026#34;; for(String l_arg : args) { /* =/Users/hoon/pjt/project/backup-program/p1/slave/src/main/resources/config/app.properties */ if(l_arg.indexOf(\u0026#34;\u0026#34;) \u0026gt; -1) { propFile = l_arg.split(\u0026#34;=\u0026#34;)[1]; AppProperties props = new AppProperties(); props.initialize(); props.loadConfig(propFile); Start(props); } else { logger.info(\u0026#34;Put properties location\u0026#34;); } } logger.info(\u0026#34;There are no properties info\u0026#34;); } 프로그램의 실행을 위해 설정 파일의 Path를 읽어와야 합니다.\n만일 Path가 없거나 args 인자가 없다면 실행하지 않습니다.\n2.1.2. Generator.class public class Generator{ private final static Logger logger = LogManager.getLogger(Generator.class); private AbstractRepositoryManager repositoryManager = null; private String target_data_table = \u0026#34;myData\u0026#34;; public Generator(AppProperties props) { this.repositoryManager = new PostgresqlRepositoryManager(props); if(props.getPropsMap().get(Constant.DB_TARGET_TABLE_NAME) != null){ target_data_table = props.getPropsMap().get(Constant.DB_TARGET_TABLE_NAME); } } . . . } Generator는 생성자로 부터 설정정보 객체를 전달 받아 DB커넥션 정보를 얻기 위한 RepositoryManager, 데이터 적재를 위한 테이블 네이밍 값을 초기화 합니다.\npublic void start() { try{ final Connection con = repositoryManager.getConnection(); logger.info(\u0026#34;DataGenerator DB connection set\u0026#34;); if (!repositoryManager.isExist(con, target_data_table)){ //테이블이 존재하지 않는다면 생성. \trepositoryManager.createTargetDataTable(con, target_data_table); } Runnable runnable = new Runnable() { String query = \u0026#34;INSERT INTO \u0026#34;+target_data_table+\u0026#34;(value, created) VALUES(?, ?)\u0026#34;; public void run() { try { Random rf = new Random(); PreparedStatement pst = con.prepareStatement(query); pst.setInt(1,rf.nextInt()); pst.setTimestamp(2, new Timestamp(System.currentTimeMillis())); pst.executeUpdate(); } catch (Exception e) { e.printStackTrace(); } } }; ScheduledExecutorService service = Executors.newScheduledThreadPool(1); service.scheduleAtFixedRate(runnable, 0, 100, TimeUnit.MILLISECONDS); }catch (Exception e) { logger.error(e.getMessage()); }finally { } } Generator의 수행 로직입니다.\n Connection 생성. 테이블 생성. 주기적으로 Insert를 실행시켜 데이터를 생성.  주기적인 Thread 로직 수행을 위해 ScheduledExecutorService 클래스를 사용하였습니다. 자세한 이유는 뒤에서 설명하겠습니다.\n2.1.3. SocketService.class public class SocketService { private final static Logger logger = LogManager.getLogger(SocketService.class); private WorkerPool workerPool; private AbstractRepositoryManager repositoryManager = null; private int DEFAULT_PORT_NUM = 20000; private int port; private String sync_table = \u0026#34;sync_info\u0026#34;; private ServerSocket _serverSocket; public SocketService() {} public void initialize(AppProperties props) { workerPool = new WorkerPool(props); this.repositoryManager = new PostgresqlRepositoryManager(props); if(props.getPropsMap().get(\u0026#34;PORT\u0026#34;) != null){ port = Integer.valueOf(props.getPropsMap().get(\u0026#34;PORT\u0026#34;)); }else{ port = DEFAULT_PORT_NUM; } if(props.getPropsMap().get(Constant.DB_SYNC_TABLE_NAME) != null){ sync_table = props.getPropsMap().get(Constant.DB_SYNC_TABLE_NAME); } try { repositoryManager.createSyncDataTable(sync_table); } catch (SQLException e) { e.printStackTrace(); }; } public void start() { try { _serverSocket = new ServerSocket(port); Socket l_socket = null; while(true) { l_socket = _serverSocket.accept(); Sender l_worker = (Sender) workerPool.getWorker(); l_worker.setSocket(l_socket); ScheduledExecutorService service = Executors.newSingleThreadScheduledExecutor(); service.scheduleAtFixedRate(l_worker, 0, 1000, TimeUnit.MILLISECONDS); } } catch (Exception e) { logger.error(e.getMessage()); } } } SocketService는 slave와의 소켓 통신을 위한 소켓서버 역할을 합니다.\nSocketService 초기화시 Port번호와 Sync_table이 생성됩니다.\n먼저 설정된 Port 가 있다면 해당 Port로 초기화 하고, 이후 Start() 메소드에서 해당 Port 번호로 소켓서버를 생성합니다.\nsync_table은 데이터 유실을 막기위한 Client별 데이터 Offset정보를 가지는 테이블의 이름입니다.\n소켓연결 방법은 아래와 같습니다.\n 소켓서버 연결대기 상태 WorkerPool에서 Thread(Worker)생성 소켓 연결 Thread(Worker) 실행 다시 1번 부터 반복  Slave(Client)로 주기적인 데이터 전송을 위해 ScheduledExecutorService를 사용하였습니다.\n2.1.4 WorkerPool.class public class WorkerPool { private final static Logger logger = LogManager.getLogger(WorkerPool.class); private List\u0026lt;AbstractWorker\u0026gt; senderList = null; private final Object lockObject = new Object(); private int activeThreadCount = 0; private AppProperties props; private AbstractRepositoryManager repositoryManager = null; public WorkerPool(AppProperties props) { this.senderList = new ArrayList\u0026lt;AbstractWorker\u0026gt;(); this.props = props; this.repositoryManager = new PostgresqlRepositoryManager(props); logger.debug(\u0026#34;WorkerPool is created.\u0026#34;); } public List\u0026lt;AbstractWorker\u0026gt; getSenderList() { return senderList; } public void setSenderList(List\u0026lt;AbstractWorker\u0026gt; senderList) { this.senderList = senderList; } public int getActiveThreadCount() { return activeThreadCount; } public void setActiveThreadCount(int activeThreadCount) { this.activeThreadCount = activeThreadCount; } } WorkerPool은 현재 생성된 Thread의 상태 또는 갯수를 관리 합니다.\npublic AbstractWorker getWorker() { AbstractWorker l_worker = null; synchronized (lockObject) { try { l_worker = (AbstractWorker)Class.forName(\u0026#34;org.opensource.master.socket.Sender\u0026#34;) .getConstructor(AppProperties.class, AbstractRepositoryManager.class) .newInstance(props, repositoryManager); l_worker.setId(\u0026#34;Test\u0026#34;); this.senderList.add(l_worker); this.activeThreadCount = this.senderList.size(); } catch(Exception e) { e.printStackTrace(); } } return l_worker; } Master의 소켓서비스는 다중 연결을 지원하기때문에, Thread 생성시 데드락 방지를 위해 synchronized를 사용합니다.\nThread객체인 Sender를 생성하며, 생성된 Thread를 리스트에 담고, 사용 Thread 갯수를 최신화 합니다.\n위 정보는 소켓 연결이 끊어지거나 Thread에 문제가 있을경우, Thread 컨드롤에 사용하기 위해 추가 하였습니다.\n하지만 현재 기능을 개발은 못하였습니다.\n2.1.4 Sender.class public class Sender extends AbstractWorker{ private final static Logger logger = LogManager.getLogger(Sender.class); private AbstractRepositoryManager repositoryManager = null; private int LIMIT = 100; private Socket _socket; private String target_data_table = \u0026#34;myData\u0026#34;; private String sync_table = \u0026#34;sync_info\u0026#34;; String slaveID = \u0026#34;\u0026#34;; ObjectInputStream ois = null; ObjectOutputStream oos = null; Connection con = null; public Sender(AppProperties props, AbstractRepositoryManager repositoryManager) { this.repositoryManager = repositoryManager; if(props.getPropsMap().get(Constant.DB_SYNC_TABLE_NAME) != null){ sync_table = props.getPropsMap().get(Constant.DB_SYNC_TABLE_NAME); } if(props.getPropsMap().get(Constant.DB_TARGET_TABLE_NAME) != null){ target_data_table = props.getPropsMap().get(Constant.DB_TARGET_TABLE_NAME); } if(props.getPropsMap().get(Constant.DB_DATA_LIMIT) != null){ LIMIT = Integer.parseInt(props.getPropsMap().get(Constant.DB_DATA_LIMIT)); } } Sender는 Slave와 연결된 소켓으로 데이터를 전송하는 실질적인 로직이 수행되는 역할을 하고 있습니다.\ntarget_data_table은 데이터를 적제할 테이블이고, Limit값은 데이터 전송을 위해 DB에서 Select시 한번에 얼마만큼 가져올지를 나타내는 설정입니다.\npublic void setSocket(Socket p_socket) { _socket = p_socket; try { ois = new ObjectInputStream(_socket.getInputStream()); slaveID = (String) ois.readObject(); logger.info(\u0026#34;Connected client ID : \u0026#34; + slaveID); oos = new ObjectOutputStream(_socket.getOutputStream()); con = repositoryManager.getConnection(); logger.info(\u0026#34;Client connection set\u0026#34;); } catch (Exception e) { e.printStackTrace(); logger.error(e); }finally { } } setSocket 메소드는 소켓 연결과 stream연결과 DB 커넥션을 연결하는 메소드입니다.\n이때, 소켓이 연결 되면 Slave는 자신의 ID를 서버에 전송합니다.\n해당 ID는 클래스변수로 관리되며 해당 세션에서 Offset과 함께 사용이 됩니다.\n@Override public void run() { // 데이터 전송에 사용할 DataContainer 객체를 생성 \tDataContainer dataContainer = new DataContainer(); dataContainer.setSlaveID(slaveID); // 현재 연결된 Slave의 ID값을 헤더정보로 세팅.  String sql = buildSyncInfoSQL(slaveID); // Sync_table에 현재 Slave에 전송된 데이터 Offset값을 가져쿼리 생성.  int offset = 0; //Default값은 0  try { Statement st = con.createStatement(); ResultSet rs = st.executeQuery(sql); if (rs.next()) { //만약 Offset 값이 있다면 해당 값으로 Offset값을 변경  offset = rs.getInt(2); } sql = buildSelectDataSQL(String.valueOf(offset)); //target_data_table에 Offset 값 만큼 데이터를 가져온다.  rs = st.executeQuery(sql); int count = 0; while(rs.next()){ //해당 데이터들을 객체로 변환  dataContainer.add( new ArrayList\u0026lt;\u0026gt;( Arrays.asList( String.valueOf(rs.getInt(1)), rs.getTimestamp(2).toString() ) ) ); count++; } // 객체 전송  oos.writeObject(dataContainer); // 객체 전송이 완료가 되면, 현재의 Offset값을 최신화 시킨다.  sql = buildUpdateOffsetSQL(slaveID, offset+count); int var = st.executeUpdate(sql); } catch (Exception e) { setWorkerState(WorkerState.NON_ACTIVE); try { ois.close(); oos.close(); } catch (Exception e1) { e1.printStackTrace(); } try { this.wait(); } catch (InterruptedException e1) { e1.printStackTrace(); } } } Sender의 수행 로직입니다.\n 데이터 전송에 사용할 DataContainer 객체를 생성 해당 DataContainer의 헤더 정보로 현재 연결된 Slave의 ID값을 세팅 Sync_table에 현재 Slave에 전송된 데이터 Offset값을 가져쿼리 생성 만약 Offset 값이 있다면 해당 값으로 Offset값을 변경 target_data_table에 Offset 값 만큼 데이터 로드 DataContainer에 데이터 추가 데이터 전송 객체 전송이 완료가 되면, 현재의 Offset값을 최신화 ​  2.1.4 Master Sequence flow chart 3. Slave 상세 설명 3.1 코드 설명 3.1.1 ClientStarter.class public class ClientStarter { private final static Logger logger = LogManager.getLogger(ClientStarter.class); private static void Start(AppProperties props) { SocketService service = new SocketService(); service.initialize(props); service.socketClientStart(); } public static void main(String[] args) { String propFile = \u0026#34;\u0026#34;; for(String l_arg : args) { if(l_arg.indexOf(\u0026#34;\u0026#34;) \u0026gt; -1) { propFile = l_arg.split(\u0026#34;=\u0026#34;)[1]; AppProperties props = new AppProperties(); props.initialize(); props.loadConfig(propFile); Start(props); } else { logger.info(\u0026#34;Put properties location\u0026#34;); } } logger.info(\u0026#34;There are no properties info\u0026#34;); } } Slave(Client)역시 프로그램의 실행을 위해 설정 파일의 Path를 읽어와야 합니다.\n만일 Path가 없거나 args 인자가 없다면 실행하지 않습니다.\n3.1.2 SocketService.class public class SocketService { private final static Logger logger = LogManager.getLogger(SocketService.class); private AbstractRepositoryManager repositoryManager = null; private AppProperties props; private String back_data_table = \u0026#34;myData\u0026#34;; public SocketService() { } public void initialize(AppProperties props) { repositoryManager = new PostgresqlRepositoryManager(props); this.props = props; if(props.getPropsMap().get(Constant.DB_BACKUP_TABLE_NAME) != null){ back_data_table = props.getPropsMap().get(Constant.DB_BACKUP_TABLE_NAME); } try { repositoryManager.createTargetDataTable(back_data_table); } catch (SQLException e) { e.printStackTrace(); } } public void socketClientStart() { Reciever reciever = new Reciever(props, repositoryManager); reciever.startReciving(); logger.info(\u0026#34;client start\u0026#34;); } } SocketService 초기화시 벡업 테이블이 생성됩니다.\n먼저 설정된 벡업 테이블 네임이없다면 default네임은 myData입니다.\n3.1.1 Reciever.class public class Reciever { private final static Logger logger = LogManager.getLogger(Reciever.class); private int PORT = 20000; private String IP = \u0026#34;127.0.0.1\u0026#34;; private String ID = \u0026#34;TEST\u0026#34;; AbstractRepositoryManager repositoryManager; private String back_data_table = \u0026#34;myData\u0026#34;; public Reciever(AppProperties props, AbstractRepositoryManager repositoryManager) { this.repositoryManager = repositoryManager; if(props.getPropsMap().get(Constant.MASTERPORT) != null){ PORT = Integer.valueOf(props.getPropsMap().get(Constant.MASTERPORT)); }else{ PORT = 20000; } if(props.getPropsMap().get(Constant.MASTERIP) != null){ IP = props.getPropsMap().get(Constant.MASTERIP); }else{ IP = \u0026#34;127.0.0.1\u0026#34;; } if(props.getPropsMap().get(Constant.SLAVEID) != null){ ID = props.getPropsMap().get(Constant.SLAVEID); }else{ ID = \u0026#34;Slave\u0026#34;; } if(props.getPropsMap().get(Constant.DB_BACKUP_TABLE_NAME) != null){ back_data_table = props.getPropsMap().get(Constant.DB_BACKUP_TABLE_NAME); } } . . Reciever는 Slave에서 데이터의 수신과 저장을 하는 역할을 합니다.\n생성자를 통해 접속할 서버의 IP, PORT 정보를 설정값으로 초기화 하고, 현재 Slave의 ID값도 초기화 합니다.\n각 변수의 Default값은 각각 \u0026ldquo;127.0.0.1\u0026rdquo;, \u0026ldquo;20000\u0026rdquo;, \u0026ldquo;Slave\u0026rdquo; 입니다.\npublic void startReciving(){ Socket socket = null; ObjectOutputStream oos =null; ObjectInputStream ois = null; try { socket = new Socket(IP,PORT); oos = new ObjectOutputStream(socket.getOutputStream()); // 현재 실행된 Slave의 ID를 전송. \toos.writeObject(ID); logger.info(\u0026#34;Sending request to Socket Server\u0026#34;); ois = new ObjectInputStream(socket.getInputStream()); while(true){ if(!socket.isConnected()) break; // 소켓이 끊겼다면 서비스 로직 종료. \tDataContainer dataContainer = (DataContainer) ois.readObject(); if(dataContainer.getSlaveID().equals(ID)){ // 현재 연결된 Slave의 ID가 아니라면 데이터를 적재하지 않는다. \tlogger.info(\u0026#34;Reciever Data Count: \u0026#34; + dataContainer.getRowCount()); backUpData(dataContainer); // 수신한 데이터 백업테이블에 적재. \t} } } catch (Exception e) { e.printStackTrace(); logger.error(e.getMessage()); }finally{ try { ois.close(); oos.close(); } catch (IOException e) { e.printStackTrace(); } } } 소켓 연결시 현재 Slave의 ID를 Master에 전송합니다.\n이후, DataContainer객체로 데이터를 수신하여 backUpData(dataContainer)에서 데이터를 백업 테이블에 저장합니다.\n하지만 만일 전달 받은 DataContainer가 현재 연결된 Slave의 ID가 아니라면 데이터를 저장하지 않습니다.\nprivate void backUpData(DataContainer dataContainer) { SimpleDateFormat format = new SimpleDateFormat(\u0026#34;yyyy-MM-dd hh:mm:ss.SSS\u0026#34;); Connection con = null; try { con = repositoryManager.getConnection(); Statement stmt = con.createStatement(); con.setAutoCommit(false); PreparedStatement pstmt = con.prepareStatement( \u0026#34;INSERT INTO \u0026#34;+back_data_table+\u0026#34;(value, created) VALUES(?,?)\u0026#34;); for (List\u0026lt;String\u0026gt; row : dataContainer.getRowList()) { // Add each parameter to the row.  pstmt.setInt(1, Integer.parseInt(row.get(0))); Date d = format.parse(row.get(1)); pstmt.setTimestamp(2, new Timestamp(d.getTime())); pstmt.addBatch(); } try { pstmt.executeBatch(); } catch (Exception e) { System.out.println(\u0026#34;Error message: \u0026#34; + e.getMessage()); return; } con.commit(); } catch(Exception e) { logger.error(e); } finally { try { con.close(); } catch (SQLException e) { e.printStackTrace(); } } } backUpData 메소드에서는 다중 PreparedStatement을 생성하여 batch로 데이터 Insert를 수행 합니다.\n5. 테스트방법 Case 1   JDK 8\n  eclipse 설치\n  Postgresql 9.4 of higher 설치\n  Postgresql 설치 주의 사항   데이터베이스 변경   DB_URL의 jdbc:postgresql://localhost:5432/{DB_Name} postgres는 postgres설치시 디폴트 DB 입니다. 다른것을 이용하고자 한다면 DB 생성후 해당 DB이름으로 변경\nex\u0026gt; jdbc:postgresql://localhost:5432/opensource\n  소문자로 생성 하는 것을 권장합니다.\n    DB_USER, DB_PASSWORD DB_USER, DB_PASSWORD 역시 postgres 설치 시 설정한 유저명과 비밀번호 입니다. 새로운 유저로 사용하고자 한다면 해당 DB 접속 후 USER, PASSWORD 생성 후 properties에 변경 (소문자로 생성 하는 것을 권장합니다.)\nex\u0026gt; ![](/image/backup_program/스크린샷 2019-08-28 오전 6.17.07.png)\n  5.1.1 git clone https://github.com/guriOH/backup-program.git 5.1.2 eclipse maven import 5.1.3 Maven build 5.1.4 Run Master \u0026amp; Slave  Program arguments : \u0026lsquo;={app.properties 파일 위치}\u0026rsquo;\nVM arguments : \u0026lsquo;-Dlog4j.configurationFile=file:////{log4j2.xml 파일 위치}\u0026rsquo;\n6. 테스트방법 case 2 6.1 5.1.1~3 까지 동일 6.2 Runnable JAR file 각각 export 6.3 Terminal command java -Dlog4j.configurationFile=file:////{log4j2.xml 파일 위치} -jar master.jar {=app.properties 파일 위치} java -Dlog4j.configurationFile=file:////{log4j2.xml 파일 위치} -jar slave.jar {=app.properties 파일 위치} "});index.add({'id':85,'href':'/tags/scrum/','title':"Scrum",'content':""});index.add({'id':86,'href':'/tags/socket/','title':"socket",'content':""});index.add({'id':87,'href':'/posts/project/addressbook/','title':"Spring_CRUD_practice",'content':"Autor : 오 훈\nTitle : AddressBook\nAddressBook (GitHub Link) 1. 목적  GET, PUT, POST, DELETE 를 이용한 주소록 CRUD 구현  2. 어플리케이션 디자인  구현에 앞서 기본적인 어플리케이션 디자인을 설명 드리겠습니다.\n어플리케이션은 크게 데이터 클래스 (Request, Response, Model), 비즈니스 로직을 포함한 데이터 처리 클래스로 나뉩니다.\n3. 프로젝트 구성  프로젝트는 SpringBoot 어플리케이션을 사용하여 작성하였습니다.\nRepository 컨트롤로는 JPA api를 사용하였고, DataBase로는 인메모리디비 H2를 사용하였습니다.\n3.1 데이터 구성 AddressInfo.class\n@Entity @ToString @Getter @Setter public class AddressInfo implements Serializable { private static final long serialVersionUID = 1L; @Id @GeneratedValue(strategy= GenerationType.SEQUENCE) private Integer id; private String name; private String phonenumber; private String address; private String email; public AddressInfo() { } public AddressInfo(String name, String phonenumber, String address, String email) { this.name = name; this.phonenumber = phonenumber; this.address = address; this.email = email; } } AddressInfo 클래스는 데이터 테이블에 저장될 데이터의 모델로서 Key값은 Integer형태의 Id를 Auto 생성합니다. 그리고 주소록에 들어갈 내용으로는 이름, 연락처, 주소, 이메일이 있습니다.\nGetter, Setter 어노테이션을 사용하도록 org.projectlombok.lombok 라이브러리를 사용하였습니다.\n4. 상세 설명 4.1 GET @Controller @RequestMapping(path = \u0026#34;/address\u0026#34;) public class AddressController { @Autowired private AddressServiceImpl addressService; @RequestMapping(value = \u0026#34;/{id}\u0026#34;, method = RequestMethod.GET) public @ResponseBody AddressResponse getAddress(@PathVariable(\u0026#34;id\u0026#34;)final Integer id) { List\u0026lt;String\u0026gt; errors = new ArrayList\u0026lt;\u0026gt;(); AddressInfo toDoItem = null; try { toDoItem = addressService.findById(id); } catch (final Exception e) { e.printStackTrace(); errors.add(e.getMessage()); } return AddressAdapter.addressInfoResponse(toDoItem, errors, null); } @RequestMapping(method = RequestMethod.GET) public @ResponseBody List\u0026lt;AddressResponse\u0026gt; getAllMember() { List\u0026lt;String\u0026gt; errors = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;AddressInfo\u0026gt; toDoItems = addressService.findAllMembers(); List\u0026lt;AddressResponse\u0026gt; toDoItemResponses = new ArrayList\u0026lt;\u0026gt;(); toDoItems.stream().forEach(toDoItem -\u0026gt; { toDoItemResponses.add(AddressAdapter.addressInfoResponse(toDoItem, errors, null)); }); return toDoItemResponses; } AddressController는 어노테이션을 이용하여 이 클래스가 RESTFul API임을 명시합니다.\n그리고 @RequestMapping을 사용하여 해당 컨트롤러의 최상위 URL을 정의 합니다.\n@RequestMapping(value = \u0026ldquo;/{id}\u0026quot;, method = RequestMethod.GET)\n  AddressResponse getAddress(@PathVariable(\u0026ldquo;id\u0026rdquo;)final Integer id)\n  getAddress는 GET 방식 사용하여 호출합니다. @PathVariable으로 정의되어 있는 값을 URL에서 선택하여 getAddress의 인자 ID로 넣어 줍니다.\n  addressService.findById(id)에서는 내부적으로 repository서비스 구현 클래스를 호출하여 해당 ID(key value)를 가진 데이터를 가져옵니다.\n@Override public AddressInfo findById(Integer id) { return addressRepository.findById(id).orElse(null); }   AddressAdapter.addressInfoResponse(toDoItem, errors, null) 가져온 결과값을 Adapter에서 Response객체로 변환하여 반환합니다.\n    ListgetAllMember()\n  getAllMember GET 방식 사용하여 호출합니다.\n  addressService.findAllMembers()에서는 addressRepository.findAll()를 호출하여 모든 주소 데이터를 가져옵니다.\n@Override public List\u0026lt;AddressInfo\u0026gt; findAllMembers() { return addressRepository.findAll(); }   AddressAdapter.addressInfoResponse(toDoItem, errors, null) 가져온 결과값을 Adapter에서 Response객체로 변환하여 반환합니다.\n    4.2 POST @RequestMapping(method = RequestMethod.POST) public @ResponseBody AddressResponse create(@RequestBody final AddressRequest addressReqeust) { List\u0026lt;String\u0026gt; errors = new ArrayList\u0026lt;\u0026gt;(); AddressInfo addressInfo = AddressAdapter.addressInfo(addressReqeust); try { addressInfo = addressService.saveMember(addressInfo); } catch (final Exception e) { e.printStackTrace(); errors.add(e.getMessage()); } return AddressAdapter.addressInfoResponse(addressInfo, errors, null); } @RequestBody를 사용하여 HTTP 요청을 AddressRequest로 받고, AddressAdapter에서는 이 Http요청을 AddressInfo객체로 변환한다.\n  AddressResponse create(@RequestBody final AddressRequest addressReqeust)\n  addressService.saveMemver(addressInfo)에서는 addressRepository.save(member)를 호출하여 데이터를 저장한다.\n@Override public AddressInfo saveMember(AddressInfo member) { return addressRepository.save(member); }     @ResponseBody는 create 메소드 결과 객체를 Http 결과를 Json형태로 돌려준다.\n4.3 PUT @RequestMapping(value = \u0026#34;/{id}\u0026#34;, method = RequestMethod.PUT) public @ResponseBody AddressResponse updateAddress(@PathVariable(\u0026#34;id\u0026#34;) Integer id, @RequestBody final AddressRequest addressReqeust) { List\u0026lt;String\u0026gt; errors = new ArrayList\u0026lt;\u0026gt;(); AddressInfo source = AddressAdapter.addressInfo(addressReqeust); AddressInfo updated = addressService.updateMember(id, source); return AddressAdapter.addressInfoResponse(updated, errors, \u0026#34;\u0026#34;); } PUT을 사용하여 데이터를 수정합니다. 먼저 @PathVariable(\u0026ldquo;id\u0026rdquo;)와 같이 URL에서 변환 대상 객체의 Key(Id)와 수정 내용를 전달 받습니다.\n  AddressAdapter.addressInfo(addressReqeust) 먼저 수정할 내용의 객체를 AddressAdapter에서 Model 객체로 변환합니다.\n  addressService.updateMember(id, source)는 내부적으로 모든 주소록을 가져와 해당 ID값을 가지는 Model을 수정할 Model로 업데이트 합니다.\n@Override public AddressInfo updateMember(Integer id, AddressInfo source) { AddressInfo target = addressRepository.findById(id).orElse(null); if(target == null) return null; target.setAddress(source.getAddress()); target.setEmail(source.getEmail()); target.setName(source.getName()); target.setPhonenumber(source.getPhonenumber()); addressRepository.save(target); return target; }   @ResponseBody는 create 메소드 결과 객체를 Http 결과를 Json형태로 돌려준다.\n4.4 DELETE @RequestMapping(value = \u0026#34;/{id}\u0026#34;, method = RequestMethod.DELETE) public @ResponseBody AddressResponse deleteAddress(@PathVariable(value=\u0026#34;id\u0026#34;) Integer id) { List\u0026lt;String\u0026gt; errors = new ArrayList\u0026lt;\u0026gt;(); String info = \u0026#34;Delete fail\u0026#34;; try { if(addressService.deleteMember(id)) { info = \u0026#34;Delete success\u0026#34;; } }catch(Exception e) { e.printStackTrace(); errors.add(e.getMessage()); } return AddressAdapter.addressInfoResponse(null, errors, info); } DELETE를 사용하여 데이터를 삭제합니다. @PathVariable(\u0026ldquo;id\u0026rdquo;)에 명시된 내용을 URL에서 가져옵니다.\n  addressService.deleteMember(id) 에 삭제할 대상 key값을 주어, 해당 객체를 가져와 delete 합니다.\n@Override public Boolean deleteMember(Integer id) { AddressInfo target = addressRepository.findById(id).orElse(null); if( target == null) return false; else addressRepository.delete(target); return true; }   5. 테스트  Postman을 활용한 로직 호출 (DB 로그 확인)  "});index.add({'id':88,'href':'/posts/goisforlovers/','title':"(Hu)go Template Primer",'content':"Hugo uses the excellent Go html/template library for its template engine. It is an extremely lightweight engine that provides a very small amount of logic. In our experience that it is just the right amount of logic to be able to create a good static website. If you have used other template systems from different languages or frameworks you will find a lot of similarities in Go templates.\nThis document is a brief primer on using Go templates. The Go docs provide more details.\nIntroduction to Go Templates Go templates provide an extremely simple template language. It adheres to the belief that only the most basic of logic belongs in the template or view layer. One consequence of this simplicity is that Go templates parse very quickly.\nA unique characteristic of Go templates is they are content aware. Variables and content will be sanitized depending on the context of where they are used. More details can be found in the Go docs.\nBasic Syntax Golang templates are HTML files with the addition of variables and functions.\nGo variables and functions are accessible within {{ }}\nAccessing a predefined variable \u0026ldquo;foo\u0026rdquo;:\n{{ foo }}  Parameters are separated using spaces\nCalling the add function with input of 1, 2:\n{{ add 1 2 }}  Methods and fields are accessed via dot notation\nAccessing the Page Parameter \u0026ldquo;bar\u0026rdquo;\n{{ .Params.bar }}  Parentheses can be used to group items together\n{{ if or (isset .Params \u0026quot;alt\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;) }} Caption {{ end }}  Variables Each Go template has a struct (object) made available to it. In hugo each template is passed either a page or a node struct depending on which type of page you are rendering. More details are available on the variables page.\nA variable is accessed by referencing the variable name.\n\u0026lt;title\u0026gt;{{ .Title }}\u0026lt;/title\u0026gt;  Variables can also be defined and referenced.\n{{ $address := \u0026quot;123 Main St.\u0026quot;}} {{ $address }}  Functions Go template ship with a few functions which provide basic functionality. The Go template system also provides a mechanism for applications to extend the available functions with their own. Hugo template functions provide some additional functionality we believe are useful for building websites. Functions are called by using their name followed by the required parameters separated by spaces. Template functions cannot be added without recompiling hugo.\nExample:\n{{ add 1 2 }}  Includes When including another template you will pass to it the data it will be able to access. To pass along the current context please remember to include a trailing dot. The templates location will always be starting at the /layout/ directory within Hugo.\nExample:\n{{ template \u0026quot;chrome/header.html\u0026quot; . }}  Logic Go templates provide the most basic iteration and conditional logic.\nIteration Just like in Go, the Go templates make heavy use of range to iterate over a map, array or slice. The following are different examples of how to use range.\nExample 1: Using Context\n{{ range array }} {{ . }} {{ end }}  Example 2: Declaring value variable name\n{{range $element := array}} {{ $element }} {{ end }}  Example 2: Declaring key and value variable name\n{{range $index, $element := array}} {{ $index }} {{ $element }} {{ end }}  Conditionals If, else, with, or, \u0026amp; and provide the framework for handling conditional logic in Go Templates. Like range, each statement is closed with end.\nGo Templates treat the following values as false:\n false 0 any array, slice, map, or string of length zero  Example 1: If\n{{ if isset .Params \u0026quot;title\u0026quot; }}\u0026lt;h4\u0026gt;{{ index .Params \u0026quot;title\u0026quot; }}\u0026lt;/h4\u0026gt;{{ end }}  Example 2: If -\u0026gt; Else\n{{ if isset .Params \u0026quot;alt\u0026quot; }} {{ index .Params \u0026quot;alt\u0026quot; }} {{else}} {{ index .Params \u0026quot;caption\u0026quot; }} {{ end }}  Example 3: And \u0026amp; Or\n{{ if and (or (isset .Params \u0026quot;title\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;)) (isset .Params \u0026quot;attr\u0026quot;)}}  Example 4: With\nAn alternative way of writing \u0026ldquo;if\u0026rdquo; and then referencing the same value is to use \u0026ldquo;with\u0026rdquo; instead. With rebinds the context . within its scope, and skips the block if the variable is absent.\nThe first example above could be simplified as:\n{{ with .Params.title }}\u0026lt;h4\u0026gt;{{ . }}\u0026lt;/h4\u0026gt;{{ end }}  Example 5: If -\u0026gt; Else If\n{{ if isset .Params \u0026quot;alt\u0026quot; }} {{ index .Params \u0026quot;alt\u0026quot; }} {{ else if isset .Params \u0026quot;caption\u0026quot; }} {{ index .Params \u0026quot;caption\u0026quot; }} {{ end }}  Pipes One of the most powerful components of Go templates is the ability to stack actions one after another. This is done by using pipes. Borrowed from unix pipes, the concept is simple, each pipeline\u0026rsquo;s output becomes the input of the following pipe.\nBecause of the very simple syntax of Go templates, the pipe is essential to being able to chain together function calls. One limitation of the pipes is that they only can work with a single value and that value becomes the last parameter of the next pipeline.\nA few simple examples should help convey how to use the pipe.\nExample 1 :\n{{ if eq 1 1 }} Same {{ end }}  is the same as\n{{ eq 1 1 | if }} Same {{ end }}  It does look odd to place the if at the end, but it does provide a good illustration of how to use the pipes.\nExample 2 :\n{{ index .Params \u0026quot;disqus_url\u0026quot; | html }}  Access the page parameter called \u0026ldquo;disqus_url\u0026rdquo; and escape the HTML.\nExample 3 :\n{{ if or (or (isset .Params \u0026quot;title\u0026quot;) (isset .Params \u0026quot;caption\u0026quot;)) (isset .Params \u0026quot;attr\u0026quot;)}} Stuff Here {{ end }}  Could be rewritten as\n{{ isset .Params \u0026quot;caption\u0026quot; | or isset .Params \u0026quot;title\u0026quot; | or isset .Params \u0026quot;attr\u0026quot; | if }} Stuff Here {{ end }}  Context (aka. the dot) The most easily overlooked concept to understand about Go templates is that {{ . }} always refers to the current context. In the top level of your template this will be the data set made available to it. Inside of a iteration it will have the value of the current item. When inside of a loop the context has changed. . will no longer refer to the data available to the entire page. If you need to access this from within the loop you will likely want to set it to a variable instead of depending on the context.\nExample:\n {{ $title := .Site.Title }} {{ range .Params.tags }} \u0026lt;li\u0026gt; \u0026lt;a href=\u0026quot;{{ $baseurl }}/tags/{{ . | urlize }}\u0026quot;\u0026gt;{{ . }}\u0026lt;/a\u0026gt; - {{ $title }} \u0026lt;/li\u0026gt; {{ end }}  Notice how once we have entered the loop the value of {{ . }} has changed. We have defined a variable outside of the loop so we have access to it from within the loop.\nHugo Parameters Hugo provides the option of passing values to the template language through the site configuration (for sitewide values), or through the meta data of each specific piece of content. You can define any values of any type (supported by your front matter/config format) and use them however you want to inside of your templates.\nUsing Content (page) Parameters In each piece of content you can provide variables to be used by the templates. This happens in the front matter.\nAn example of this is used in this documentation site. Most of the pages benefit from having the table of contents provided. Sometimes the TOC just doesn\u0026rsquo;t make a lot of sense. We\u0026rsquo;ve defined a variable in our front matter of some pages to turn off the TOC from being displayed.\nHere is the example front matter:\n--- title: \u0026quot;Permalinks\u0026quot; date: \u0026quot;2013-11-18\u0026quot; aliases: - \u0026quot;/doc/permalinks/\u0026quot; groups: [\u0026quot;extras\u0026quot;] groups_weight: 30 notoc: true --- Here is the corresponding code inside of the template:\n {{ if not .Params.notoc }} \u0026lt;div id=\u0026quot;toc\u0026quot; class=\u0026quot;well col-md-4 col-sm-6\u0026quot;\u0026gt; {{ .TableOfContents }} \u0026lt;/div\u0026gt; {{ end }}  Using Site (config) Parameters In your top-level configuration file (eg, config.yaml) you can define site parameters, which are values which will be available to you in chrome.\nFor instance, you might declare:\nparams: CopyrightHTML: \u0026#34;Copyright \u0026amp;#xA9; 2013 John Doe. All Rights Reserved.\u0026#34; TwitterUser: \u0026#34;spf13\u0026#34; SidebarRecentLimit: 5 Within a footer layout, you might then declare a \u0026lt;footer\u0026gt; which is only provided if the CopyrightHTML parameter is provided, and if it is given, you would declare it to be HTML-safe, so that the HTML entity is not escaped again. This would let you easily update just your top-level config file each January 1st, instead of hunting through your templates.\n{{if .Site.Params.CopyrightHTML}}\u0026lt;footer\u0026gt; \u0026lt;div class=\u0026quot;text-center\u0026quot;\u0026gt;{{.Site.Params.CopyrightHTML | safeHtml}}\u0026lt;/div\u0026gt; \u0026lt;/footer\u0026gt;{{end}} An alternative way of writing the \u0026ldquo;if\u0026rdquo; and then referencing the same value is to use \u0026ldquo;with\u0026rdquo; instead. With rebinds the context . within its scope, and skips the block if the variable is absent:\n{{with .Site.Params.TwitterUser}}\u0026lt;span class=\u0026quot;twitter\u0026quot;\u0026gt; \u0026lt;a href=\u0026quot;https://twitter.com/{{.}}\u0026quot; rel=\u0026quot;author\u0026quot;\u0026gt; \u0026lt;img src=\u0026quot;/images/twitter.png\u0026quot; width=\u0026quot;48\u0026quot; height=\u0026quot;48\u0026quot; title=\u0026quot;Twitter: {{.}}\u0026quot; alt=\u0026quot;Twitter\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;/span\u0026gt;{{end}} Finally, if you want to pull \u0026ldquo;magic constants\u0026rdquo; out of your layouts, you can do so, such as in this example:\n\u0026lt;nav class=\u0026quot;recent\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Recent Posts\u0026lt;/h1\u0026gt; \u0026lt;ul\u0026gt;{{range first .Site.Params.SidebarRecentLimit .Site.Recent}} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;{{.RelPermalink}}\u0026quot;\u0026gt;{{.Title}}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {{end}}\u0026lt;/ul\u0026gt; \u0026lt;/nav\u0026gt; "});index.add({'id':89,'href':'/categories/','title':"Categories",'content':""});index.add({'id':90,'href':'/categories/development/','title':"Development",'content':""});index.add({'id':91,'href':'/tags/development/','title':"development",'content':""});index.add({'id':92,'href':'/posts/hugoisforlovers/','title':"Getting Started with Hugo",'content':"Step 1. Install Hugo Go to Hugo releases and download the appropriate version for your OS and architecture.\nSave it somewhere specific as we will be using it in the next step.\nMore complete instructions are available at Install Hugo\nStep 2. Build the Docs Hugo has its own example site which happens to also be the documentation site you are reading right now.\nFollow the following steps:\n Clone the Hugo repository Go into the repo Run hugo in server mode and build the docs Open your browser to http://localhost:1313  Corresponding pseudo commands:\ngit clone https://github.com/spf13/hugo cd hugo /path/to/where/you/installed/hugo server --source=./docs \u0026gt; 29 pages created \u0026gt; 0 tags index created \u0026gt; in 27 ms \u0026gt; Web Server is available at http://localhost:1313 \u0026gt; Press ctrl+c to stop  Once you\u0026rsquo;ve gotten here, follow along the rest of this page on your local build.\nStep 3. Change the docs site Stop the Hugo process by hitting Ctrl+C.\nNow we are going to run hugo again, but this time with hugo in watch mode.\n/path/to/hugo/from/step/1/hugo server --source=./docs --watch \u0026gt; 29 pages created \u0026gt; 0 tags index created \u0026gt; in 27 ms \u0026gt; Web Server is available at http://localhost:1313 \u0026gt; Watching for changes in /Users/spf13/Code/hugo/docs/content \u0026gt; Press ctrl+c to stop  Open your favorite editor and change one of the source content pages. How about changing this very file to fix the typo. How about changing this very file to fix the typo.\nContent files are found in docs/content/. Unless otherwise specified, files are located at the same relative location as the url, in our case docs/content/overview/quickstart.md.\nChange and save this file.. Notice what happened in your terminal.\n\u0026gt; Change detected, rebuilding site \u0026gt; 29 pages created \u0026gt; 0 tags index created \u0026gt; in 26 ms  Refresh the browser and observe that the typo is now fixed.\nNotice how quick that was. Try to refresh the site before it\u0026rsquo;s finished building. I double dare you. Having nearly instant feedback enables you to have your creativity flow without waiting for long builds.\nStep 4. Have fun The best way to learn something is to play with it.\n"});index.add({'id':93,'href':'/tags/go/','title':"go",'content':""});index.add({'id':94,'href':'/tags/golang/','title':"golang",'content':""});index.add({'id':95,'href':'/categories/golang/','title':"golang",'content':""});index.add({'id':96,'href':'/tags/hugo/','title':"hugo",'content':""});index.add({'id':97,'href':'/tags/templates/','title':"templates",'content':""});index.add({'id':98,'href':'/tags/themes/','title':"themes",'content':""});index.add({'id':99,'href':'/docs/categories/%EB%8F%84%EA%B5%AC/','title':"도구",'content':""});index.add({'id':100,'href':'/docs/categories/%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4/','title':"오픈소스",'content':""});index.add({'id':101,'href':'/docs/categories/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C/','title':"클라우드",'content':""});index.add({'id':102,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/java/','title':"Java",'content':"자 바\n"});index.add({'id':103,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/java/environment/','title':"Environment",'content':"Mac JDK 설치 및 환경변수 설정 Default 설치 위치는 /usr/libexec/java_home -V  로 확인 가능하다.\n"});index.add({'id':104,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/javascript/react/','title':"React",'content':"React Context React + Redux flow "});index.add({'id':105,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/shell/','title':"Shell",'content':"쉘\n"});index.add({'id':106,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/shell/configuration_env_with_intellij/','title':"Configuration Env With Intellij",'content':"인텔리제이 쉘스크립트 개발환경 구성 Linux/Mac라면 굳이 쉘스크립트 작성을 위한 개발환경이 필요하지 않아도 되지만,\n제품 빌드 스크립트등을 작성 할 시, 각종 환경변수와 컨피그 파일 로드를 포함하여 복잡한 스크립트를 작성해야 할 수도 있다.\n이 때, 조금이라도 더 편하게 스크립트를 작성 할 수 있을 것 같다\u0026hellip;ㅎㅎ\nEmpty project 생성 단지 쉘스크립트를 위한 환경이니 빈프로젝트를 생성. 개인 취향에 맡게 개발 환경을 만들자. 나는 아래와 같은 폴더구조를 만들었다.\n테스트 프로그램 실행. 아래의 코드를 실행해보자 .\n인텔리제이에서는 아래에서 보이듯이 여러가지 언어 또는 프레임워크를 지원한다. 쉘스크립트 실행 환경을 선택하자.\n그리고 실행할 script path를 입력하고\n아래와 같이 인터프리터를 설정하면 실행 준비 끝.\n일단 기본 Bash쉘로 설정하였다.\nMac 기준 Ctrl + R 로 그때그때 실행하며 편하게 개발시작.\n"});index.add({'id':107,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/shell/shellscript/','title':"Shellscript",'content':"쉘스크립트 문법 정리  쉘스크립트 첫라인 #!/bin/bash 의미?\n  스크립트파일을 bash로 실행시킨다는 의미\n  기재하지 않으면 리눅스 배포판의 경우 디폴트가 bash이므로 무리 없이 작동하지만 다른 쉘간의 오류를 방지를 위함.\n   기본 문법  echo, printf $# : 스크립트에 전달되는 인자들의 수(C언어에서 argc) $0 : 실행하는 스크립트의 파일명으로 실행했을 때 경로를 포함한다면 경로를 포함해서 나옵니다. $1, $2 … : 스크립트로 전달된 인자들(C언어에서 argv[0], argv[1]…)  echo \u0026#34;Echo Test\u0026#34; printf \u0026#34;printf Test\\n\u0026#34; printf \u0026#34;Name of script : %s\\n\u0026#34; $0 printf \u0026#34;%d arguments %s %s\\n\u0026#34; $# $1 $2 exit exit 100 # 스크립트 종료후 echo $? 로 확인. # 관습적으로 'exit 0'은 성공을 의미합니다. # 0이 아닌 값은 에러나 예외상황을 나타냅니다. $?는 스크립트에서 실행시키 명령어의 결과를 확인하는데 특별히 유용\n특수문자 # : 주석\n# 주석 뒤에는 명령어가 올수 없다. \\# 이스케이프된 #은 주석을 나타내지 않는다. ; : 명령어 구분자, 두개 이상의 명령어를 한 줄에서 같이 사용할 수 있다.\n부분쿼우팅[이중쿼우트] \u0026ldquo;content\u0026rdquo; 문자열 대부분 특수문자 해석을 막는다.\n완전쿼우팅[단일쿼우트] \u0026lsquo;content\u0026rsquo; 문자열에 들어 있는 모든 특수 문자를 해석하지 못하도록 막아줍니다\n명령어치환[백틱(backticks)] ``명령어` 라고 하면 명령어의 결과를 변수값으로 설정할 수있다.\n"});index.add({'id':108,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/springboot/java-reflection/','title':"Java Reflection",'content':""});index.add({'id':109,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/springboot/jwt_authenticate_process/','title':"J W T Authenticate Process",'content':"Spring Security 필요개념  접근주체(Principal) : 접근 사용자 인증(Authenticate) : 접근 주체 확인 인가(Authorize) : 접근 주체의 권한 검사  스프링의 구조는 필터와 필터된 Authentication객체를 가지고 실질적인 Validation을 하는 Provider로 나뉜다.\nFilter chain 스프링 시큐리티 역시 Filter가 구성이 되어있다.\n기본적으로 11개의 Filter로 구성이 되어있고, Filter를 커스터마이징 하여 추가 확장 시킬수 있다.\n이때 중요한것은 필터간의 순서가 중요하다.\nProvider 프로바이더는 실질적인 검증을 하는 클래스로 AuthenticationProvider를 구현하고\nAuthenticationManagerBuilder에 커스터마이징하여 등록이 가능하다.\n@Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.authenticationProvider(authenticationProvider); auth.authenticationProvider(jwtAutenticationTokenProvider); } "});index.add({'id':110,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/springboot/spring-aop/','title':"Spring a O P",'content':"스프링 AOP를 구현하는 방법 기술. AOP 개념\nAspect : 공통 기능을 말합니다.\nAdvice : Aspect의 기능 자체를 말합니다.\nJointpoint : Advice를 적용해야 하는 부분입니다. 필드나 메소드이고, 스프링에서는 메소드만\n해당됩니다.\nPointcut : Jointpoint의 부분, 실제로 Advice가 적용된 부분\nWeaving : Advice를 핵심 기능에 적용하는 행위를 말합니다.\n  RTW (Runtime Weaving) 스프링 AOP에서 사용하는 위빙 방식. Proxy를 생성하여 실제 타깃 오브젝트의 변형없이 위빙을 수행. 실제 런타임 시, 메소드 호출과 동시에 위빙이 이루어 지는 방식이다.\n장점 : 소스파일, 클래스파일의 변형이 없다. 단점 : 포인트 컷에 대한 어드바이스 적용 갯수가 늘어 날수록 성능이 떨어진다.\n  CTW (Compile time Weaving) AspectJ에는 AJC (AspectJ Compiler)라는 컴파일러가 있는데 Java Compiler를 확장한 형태의 컴파일러이다. AJC를 통해 java파일을 컴파일 하며, 컴파일 과정에서 바이트 코드 조작을 통해 Advisor 코드를 직접 삽입하여 위빙을 수행\n장점 : 위빙중 가장 빠른 퍼포먼스 (JVM상에 올라 갈때 메소드 내에 이미 advice 코드가 삽입 되어있기 때문에..) 단점 : 컴파일 과정에서 lombok과 같이 컴파일 과정에서 코드를 조작하는 플러그인과 충돌이 발생할 가능성이 아주 높다. (거의 같이 사용 불가)\n  LTW (Load time Weaving) ClassLoader를 통해 JVM에 로드 될 때 바이트 코드 조작을 통해 위빙이 되는 방식 RTW와 마찬가지로 소스코드와 클래스파일에 조작이 없다. 하지만 오브젝트가 메모리에 올라가는 과정에서 위빙이 일어나기 때문에 런타임 시, 시간은 CTW보다 상대적으로 느리다\n장점 : 소스파일, 클래스파일의 변형이 없다. 단점 : performance가 저하, 설정의 복잡.\n  스프링 프레임워크에서 지원하는 3가지 AOP 기술\n JDK dynamic proxy, CGLIB, AspectJ  AOP 적용 방식에 따른 분류\n 프록시 기반 : JDK dynamic proxy, CGLIB 타깃 오브젝트 조작 : AspectJ  JDK Dynamic Proxy \u0026amp; CGLIB\nAspect 프레임워크와는 달리 스프링에서는 간단한 설정만으로 JDK Dynamic Proxy와 CGLIB 방식을 사용할 수 있도록 되어 있습니다. 두 방식의 차이는 인터페이스의 유무로서, AOP의 타깃이 되는 클래스가 인터페이스를 구현했다면 JDK Dynamic Proxy를 사용하고, 구현하지 않았다면 CGLIB 방식을 사용합니다\n[출처] [Spring AOP에 관하여 - 2] JDK Dynamic Proxy \u0026amp; CGLIB\nAspect란?\n도메인 로직에 필요한 다양한 부가기능을 추상화 시킨것.\n어노테이션 기반으로 AOP를 구현은 런타임이 아닌 Compile 시점에 Aspect를 적용하는 것이다.\n@Aspect @Component public class TestAspect { private static final Logger logger = LoggerFactory.getLogger(TestAspect.class); @Before(\u0026#34;execution(* com.example.aop_example.service.*.test(..))\u0026#34;) public void onBeforeHandler(JoinPoint joinPoint) { logger.info(\u0026#34;=============== onBeforeThing\u0026#34;); } @After(\u0026#34;execution(* com.example.aop_example.service.*.test(..))\u0026#34;) public void onAfterHandler(JoinPoint joinPoint) { logger.info(\u0026#34;=============== onAfterHandler\u0026#34;); } @AfterReturning(pointcut = \u0026#34;execution(* com.example.aop_example.service.*.test(..))\u0026#34;, returning = \u0026#34;str\u0026#34;) public void onAfterReturningHandler(JoinPoint joinPoint, Object str) { logger.info(\u0026#34;@AfterReturning : \u0026#34; + str); logger.info(\u0026#34;=============== onAfterReturningHandler\u0026#34;); } @Pointcut(\u0026#34;execution(* com.example.aop_example.service.*.test(..))\u0026#34;) public void onPointcut(JoinPoint joinPoint) { logger.info(\u0026#34;=============== onPointcut\u0026#34;); } } "});index.add({'id':111,'href':'/docs/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/springboot/spring_basic/','title':"Spring Basic",'content':"Anotation 어노테이셔 : 소스코드에 메타데이터를 표현하는것 Built-in Annotation @Override - 메소드 오버라이드 검증\n@Deprecated - 메소드를 사용하지 않도록 유도.\n@SuppressWarnings - 컴파일 경고를 무시하도록 함.\n@SafeVarargs - 제너릴 같은 가변인자 매개변수를 사용할 때 경고 무시 (자바 7 이상)\n@FunctionalInterface - 람다 함수등을 위한 인터페이스를 지정. 메소드가 두개 이상 되면 컴파일 오류 (자바 8 이상)\nMeta Annotations @Retention - 어노테이션 영향 범위 결정.\n@Documented - 어노테이션 정보 출력.\n@Target - 어노테이션 적용 위치 결정.\n@Inherited - 자식클래스 어노테이션 상속 여부 결정.\n@Repeatable - 반복적으로 어노테이션을 선언\n"});index.add({'id':112,'href':'/docs/shortcodes/buttons/','title':"Buttons",'content':"Buttond Buttons are styled links that can lead to local page or external link.\nExample {{\u0026lt; button relref=\u0026#34;/\u0026#34; [class=\u0026#34;...\u0026#34;] \u0026gt;}}Get Home{{\u0026lt; /button \u0026gt;}} {{\u0026lt; button href=\u0026#34;https://github.com/alex-shpak/hugo-book\u0026#34; \u0026gt;}}Contribute{{\u0026lt; /button \u0026gt;}}  Get Home  Contribute  "});index.add({'id':113,'href':'/docs/shortcodes/columns/','title':"Columns",'content':"Columns Columns help organize shorter pieces of content horizontally for readability.\n{{\u0026lt; columns \u0026gt;}} \u0026lt;!-- begin columns block --\u0026gt; # Left Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!-- magic sparator, between columns --\u0026gt; # Mid Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!-- magic sparator, between columns --\u0026gt; # Right Content Lorem markdownum insigne... {{\u0026lt; /columns \u0026gt;}} Example Left Content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.  Mid Content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter!  Right Content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.   "});index.add({'id':114,'href':'/docs/shortcodes/expand/','title':"Expand",'content':"Expand Expand shortcode can help to decrease clutter on screen by hiding part of text. Expand content by clicking on it.\nExample Default {{\u0026lt; expand \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /expand \u0026gt;}}  Expand ↕  Markdown content Lorem markdownum insigne\u0026hellip;    With Custom Label {{\u0026lt; expand \u0026#34;Custom Label\u0026#34; \u0026#34;...\u0026#34; \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /expand \u0026gt;}}  Custom Label ...  Markdown content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.    "});index.add({'id':115,'href':'/docs/shortcodes/hints/','title':"Hints",'content':"Hints Hint shortcode can be used as hint/alerts/notification block.\nThere are 3 colors to choose: info, warning and danger.\n{{\u0026lt; hint [info|warning|danger] \u0026gt;}} **Markdown content** Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa {{\u0026lt; /hint \u0026gt;}} Example Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa  Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa  Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa  "});index.add({'id':116,'href':'/docs/shortcodes/katex/','title':"Katex",'content':"KaTeX KaTeX shortcode let you render math typesetting in markdown document. See KaTeX\nExample {{\u0026lt; katex [display] [class=\u0026#34;text-center\u0026#34;] \u0026gt;}} x = \\begin{cases} a \u0026amp;\\text{if } b \\\\ c \u0026amp;\\text{if } d \\end{cases} {{\u0026lt; /katex \u0026gt;}}     Display Mode Example Here is some inline example: \\(\\pi(x)\\)  , rendered in the same line. And below is display example, having display: block \\[ x = \\begin{cases} a \u0026\\text{if } b \\\\ c \u0026\\text{if } d \\end{cases} \\]  Text continues here.\n"});index.add({'id':117,'href':'/docs/shortcodes/mermaid/','title':"Mermaid",'content':"Mermaid Chart Mermaid is library for generating svg charts and diagrams from text.\nExample {{\u0026lt; mermaid [class=\u0026#34;text-center\u0026#34;]\u0026gt;}} sequenceDiagram Alice-\u0026gt;\u0026gt;Bob: Hello Bob, how are you? alt is sick Bob-\u0026gt;\u0026gt;Alice: Not so good :( else is well Bob-\u0026gt;\u0026gt;Alice: Feeling fresh like a daisy end opt Extra response Bob-\u0026gt;\u0026gt;Alice: Thanks for asking end {{\u0026lt; /mermaid \u0026gt;}}     "});index.add({'id':118,'href':'/docs/shortcodes/tabs/','title':"Tabs",'content':"Tabs Tabs let you organize content by context, for example installation instructions for each supported platform.\n{{\u0026lt; tabs \u0026#34;uniqueid\u0026#34; \u0026gt;}} {{\u0026lt; tab \u0026#34;MacOS\u0026#34; \u0026gt;}} # MacOS Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026#34;Linux\u0026#34; \u0026gt;}} # Linux Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026#34;Windows\u0026#34; \u0026gt;}} # Windows Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; /tabs \u0026gt;}} Example MacOS  MacOS This is tab MacOS content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nLinux  Linux This is tab Linux content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nWindows  Windows This is tab Windows content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n "});index.add({'id':119,'href':'/docs/shortcodes/task/','title':"Task",'content':"Task Tabs let you organize content by context, for example installation instructions for each supported platform.\n{{\u0026lt; tabs \u0026#34;uniqueid\u0026#34; \u0026gt;}} {{\u0026lt; tab \u0026#34;MacOS\u0026#34; \u0026gt;}} # MacOS Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026#34;Linux\u0026#34; \u0026gt;}} # Linux Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026#34;Windows\u0026#34; \u0026gt;}} # Windows Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; /tabs \u0026gt;}} Example MacOS  MacOS This is tab MacOS content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nLinux  Linux This is tab Linux content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nWindows  Windows This is tab Windows content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n "});index.add({'id':120,'href':'/posts/build-location/','title':"Build Location",'content':"sudo ls -al /root/.jenkins/workspace/중랑구_스마트시티/iot-api/build/asciidoc/html5/admin\nsudo ls -al /root/.jenkins/workspace/중랑구_스마트시티/iot-api/build/libs/\n/root/.jenkins/workspace/중랑구_스마트시티/iot-api/build/libs\n"});index.add({'id':121,'href':'/posts/cloud/aws/database/chapter01/','title':"Chapter01",'content':"Databases 101 Relational databases on AWS\n SQL Server Oracle MySql PostgreSql Aurora MariaDB  Multi-AZ vs Read Replicas\n Multi-AZ - For Disaster Recovery Read Replicas - For Performance  Non Relational databases on AWS\n Collection = Table Document = Row Key Value Pairs = Fields  OLTP vs OLAP\nElasticCache\n web service that makes it easy to deploy, operate, and scale an in memory cache in the cloud.  ElasticCache supports two open-source in memory caching engines:\n Memcached Redis  Tips\n RDS (OLTP)  SQL MySQL PostgreSQL Oracle Aurora MariaDB   DynamoDB (NoSQL) Red Shift OLAP  "});index.add({'id':122,'href':'/posts/cloud/aws/database/chapter03/','title':"Chapter03",'content':"RDS backups, Multi-AZ \u0026amp; Read Replicas Multi-AZ Support  SQL Server Oracle MySql Server PostgreSQL MariaDB  Read Replicas  Oracle MySql Server PostgreSQL MariaDB Aurora  "});index.add({'id':123,'href':'/posts/cloud/aws/database/chapter04/','title':"Chapter04",'content':"DynamoDB "});index.add({'id':124,'href':'/posts/cloud/aws/database/chapter5/','title':"Chapter5",'content':"Redshift OLTP vs OLAP\nTips   Amazon Redshift efficient storage and optimum query performance through a combination of massively parallel processing, columnar data storage, and very efficient, targeted data compression encoding schemes.\n  Columnar storage\n optimizing analytic query performance  reduce disk I/O reduces the amount of data you need to load from disk.      "});index.add({'id':125,'href':'/posts/cloud/aws/database/summary/','title':"Summary",'content':"Databases Summary RDS (OLTP)  SQL MySQL PostgreSQL Oracle Aurora MariaDB  DynamoDB (NoSQL) Red Shift OLAP Elasticache   Memcached\n  Redis\n  Remember  RDS runs on virtual machines You cannot log in to these operating systems however. Patching of the RDS Operating System and DB is Amazon\u0026rsquo;s responsiblilty RDS is NOT Serverless Aurora Serverless IS Serverless  Two different types of Backups for RDS  Automated Backups Databases Snapshots  Read Replicas  Can be multi-az Used to increase performance. Must have backups turned on. Can be in different regions. Can be MySQL, PostgreSQL, MariaDB, Oracle, Aurora Can be promoted to master, this will break the Read Replica  MultiAZ  Used For DR. You can force a failover from one AZ to another by rebooting the RDS instance.  DynamoDB  Storead on SSD storage Spread Across 3 geographically distinct data centres Eventual Consistent Reads (Default) Strongly Consistent Reads  Redshift Backups  Enabled by default with a 1 day retnetion period. Maximun retention period is 35 days. Redshift always attempts to maintain at least three copies of your data (the original and replica on the compute nodes and a backup in amazon S3) Redshift can also asynchronously replicate your snapshots to S3 in another region for disaster recovery  Aurora  2 copies of your data is contained in each availablity zone. with minu  EFS (Elastic File System)  AWS 클라우드 서비스와 온프레미스 리소스에서 사용할 수 있는, 간단하고 확장 가능하며 탄력적인 완전관리형 NFS 파일 시스템을 제공 애플리케이션을 중단하지 않고 온디맨드 방식으로 페타바이트 규모까지 확장하도록 구축되어, 파일을 추가하고 제거할 때 자동으로 확장 수천 개의 Amazon EC2 인스턴스에 대한 병렬 공유 액세스를 대규모로 제공하도록 설계되었으므로, 애플리케이션은 일관되게 낮은 지연 시간을 유지하면서 높은 수준의 집계 처리량과 IOPS를 달성할 수 있습니다.  EBS (Elastic Block Storage)  대규모로 처리량과 트랜잭션 집약적인 워크로드 모두를 지원하기 위해 Amazon Elastic Compute Cloud(EC2)에서 사용하도록 설계된 사용하기 쉬운 고성능 블록 스토리지 서비스입니다  "});index.add({'id':126,'href':'/posts/cloud/aws/ec2/chaper01/','title':"Chaper01",'content':"EC2 101 Elastic compute cloud What is EC2\nEC2 is a web service that provide resizable compute capacity in the cloud.\n장점 : EC2는 서버 인스턴스 구성시 간편하고, 스케일 업/다운 방식에 상관없이 빠르게 변경 가능하다.\nPricing Models\n On Demand Reserved  Standard Reserved instances Convertible Reserved Instances Scheduled Reserved Instances   spot  etc   Dedicated Hosts  etc    EC2 Instance Types\n F1, I3, G3, H1, T3\u0026hellip;.. tips [Fight DR.MC PXZ AU]  "});index.add({'id':127,'href':'/posts/cloud/aws/ec2/chaper02/','title':"Chaper02",'content':"Lanuch EC2 Instance lab1 "});index.add({'id':128,'href':'/posts/cloud/aws/ec2/chaper03/','title':"Chaper03",'content':"Lanuch EC2 Instance lab2 Tips\n Terminate Protection Turned off by default On an EBS-backed instance, the default action is for the root EBS volume to be deleted when the instance is terminated. EBS Root Volumes of your DEFAULT AMI\u0026rsquo;s can be encrypted Additional volumnes can be encypted.  "});index.add({'id':129,'href':'/posts/cloud/aws/ec2/chaper04/','title':"Chaper04",'content':"Security Group Tips\n  All inbound traffic is blocked by default\n  All Outbountd traffic is allowed.\n  Change to Security groups take effect immediatly.\n  You can have any number of EC2 instances within a security group\n  You can have multiple security groups attached to Ec2 instances.\n  Security Groups are STATEFUL.\n  If you create an inbound rule allowing traffic in, that traffic is automatically allowed back out again\n  You cannot block specific IP address using security groups, instead use Network Access Control Lists.\n  "});index.add({'id':130,'href':'/posts/cloud/aws/ec2/chaper05/','title':"Chaper05",'content':"EBS101 EBS (Elastic Block Storage)  대규모로 처리량과 트랜잭션 집약적인 워크로드 모두를 지원하기 위해 Amazon Elastic Compute Cloud(EC2)에서 사용하도록 설계된 사용하기 쉬운 고성능 블록 스토리지 서비스입니다  What is EBS\nElastic Block Store\n5 diff type of EBS storage;\n General Purpose (SSD) Provisioned IOPS (SSD) Throughput Optimized HDD   The data streams are typically large and sequential  Cold HDD EBS Magnetic  "});index.add({'id':131,'href':'/posts/cloud/aws/ec2/chaper06/','title':"Chaper06",'content':"EBS1 Volumne EBS 스토리지는 ec2 인스턴스와 같은 가용공간에 있어야함.\n추가적인 볼륨들은 Ec2인스턴스 삭제를 해도 지워지지 않는다.\nTips\n  EBS : virtual hard disk\n  Snapshots exist on S3. Think of snapshots as a photograph of the disk\n  Snapshots are point in time copies of Volumes.\n  Snapshots are incremental - this means that only the blocks that have changed since your last snapshot are moved to S3.\n  To create a snapshot for Amazone EBS volumes that serve as root devices, you should stop the instance before taking the snapshot.\n  however you can snap while instance running.\n  You can create AMI\u0026rsquo;s from both Volumes and Snapshots\n  You can change EBS volume size on the fly, including changing the size the type.\n  Volume will ALWAYS be in the same availability zone as the EC2 instance.\n  To move an EC2 volume from one AZ to another, take a snapshot of it, create an AMI from the snapshot and then use the AMI to launch the EC2 instance in a new AZ.\n  To move an EC2 volume from one region to another. EC2 -\u0026gt; snapshot -\u0026gt; AMI -\u0026gt; copy AMI to another zone.\n  "});index.add({'id':132,'href':'/posts/cloud/aws/ec2/chaper07/','title':"Chaper07",'content':"AMI types (EBS vs Instance store)  Select AMI based on:   Region Operating system. Architecture (32-bit or 64-bit) Launch Permissions Storage for Root device  All AMIs are categorized as either backed by EBS or Instance store   For EBD Volume : The root device for an instance launched from the AMI is an Amazon EBS volume created from an Amazon EBS snapshot\n  For Instance Store Volumes : The root device for an instance launched from the AMI is an instance store volume created from a template stored in Amazon S3.\n  tips\n Instance Store Volume are somethimes called Ephemeral Storage Instance store volume cannot be stopped If the underlying host fails, you will lose your data. EBS backed instances can be stopped. You will not lose the data on this instance if it is stopped. You can reboot both, you will not lose your data. By default, both ROOT volumes will be deleted on termination. However, with EBS volumes, you can tell aws to keep the root device volume  "});index.add({'id':133,'href':'/posts/cloud/aws/ec2/chaper08/','title':"Chaper08",'content':"Encryped Root Device Volumes \u0026amp; Snapshots  Snapshots of encrypted volumes are encrypted automatically Volumes restored from encrypted snapshots are encrypted automatically You can share snapshots, but only if they are unencrypted. These snapshots can be shared with other AWS accounts or made public  Process\n Create a Snapshot of the unencrypted root device volume Create a copy of the Snapshot and select encrypt option Create an AMI from the encrypted Snapshot Use that AMI to launch new encryted instances  "});index.add({'id':134,'href':'/posts/cloud/aws/ec2/chaper09/','title':"Chaper09",'content':"CloudWatch 101 What is Cloud watch\n monitoring service  cloudWatch monitors performance\n Compute  EC2 Autoscaling Groups Elastic Load Balancers Route53 Health Checks   Storage \u0026amp; Content Delivery  EBS Volumes Storage Gateways CloudFront    Host Level Metrics Consist of\n CPU Network Disk Status Check  Cloud Trail compare with CloudWatch\nCloud Trail like CCTV\n CloudWatch monitors performance. CloudTrail monitors API calls in the AWS platform.  Remember;\n CW is used for monitoring performance CW can monitor most of AWS as well as your applications that run on AWS. CW with ec2 will monitor events every 5 minutes by default. You can have 1 minute intervals by turning on detailed monitoring. You can create CW alarms whi ch trigger norification. CW is all about performance. CloudTrail is all about auditing.  "});index.add({'id':135,'href':'/posts/cloud/aws/ec2/chaper10/','title':"Chaper10",'content':"CloudWatch 101 Tips\n Standard Monitoring = 5 min Detailed Monitoring = 1 min  What can i do with CloudWatch\n  Dashboard - Creates awesome dashboards to see what is happening with your AWS env\n  Alarms - Allows you to set Alarms that norify you when particular threshold are hit.\n  Events - CloudWatch Events helps you to respond to state changes in your AWS resources.\n  Logs - CloudWatch Logs helps you to aggregate, monitor, and store logs.\n   CloudWatch monitors performance CloudTrail monitors API calls in AWS platform.  "});index.add({'id':136,'href':'/posts/cloud/aws/ec2/chaper11/','title':"Chaper11",'content':"AWS Command Line (CLI) Tips\n You can interact with AWS from anywhere in the world just by using command line(CLI) You will need to set up access in IAM Commands themselves are not in the exam but some bacis command will be useful to know for real life  "});index.add({'id':137,'href':'/posts/cloud/aws/ec2/chaper12/','title':"Chaper12",'content':"Identity Access Management Roles Tips\n Roles are more secure than storing your access key and secret access key on individual EC2 instances. Roles are easier to manager. Roles can ve assigned to an EC2 intance after it is created using both the console \u0026amp; command line. Roles are universal - you can use them in any region.  "});index.add({'id':138,'href':'/posts/cloud/aws/ec2/chaper13/','title':"Chaper13",'content':"Instancde Metadata Tips\n Used to get information about an instance (such as public ip) curl http://(ip_address)/latest/meta-data/ curl http://(ip_address)/latest/user-data/  "});index.add({'id':139,'href':'/posts/cloud/aws/ec2/chaper14/','title':"Chaper14",'content':"EFS (Elastic File System) What is EFS\nFile storage service for ec2 instances.\nIt is easy to use and provides a simple interface that allows you to create and configure file systems quickly and easily.\nTips\n Supports the Network File System version 4 (NFSv4) protocol You only pay for the storage you use(no pre-provisioning required) Can scale up to the petabytes Can support thousands of concurrent NFS connections Data is stored across multiple AZ\u0026rsquo;s within a region Read After Write Consistency  "});index.add({'id':140,'href':'/posts/cloud/aws/ec2/chaper15/','title':"Chaper15",'content':"EC2 Placement Groups Three Types of placement Groups;\n Clustered Placement Group  Low Network Latency / High Network Throughput   Spread Placement Group  Individual Critical EC2 instances   Partitioned  Multiple EC2 instances HDFS, HBase, and Cassandra    Tips\n A clustered placement group can\u0026rsquo;t span multiple Avilability Zones. A spread placement and partitioned group can The name you specify for a placement group must be unique within your AWS account. Only certain types of instances can be launched in a placement group(Compute Optimized, GPU, Memory Optimized, Storage Optimized) AWS recomment homogenous instances within clustered placement groups. You can\u0026rsquo;t merge placement groups You can\u0026rsquo;t move a existing instance into a placement group. You can create an AMI from your exisiing instance, and then launch a new instance from the AMI into a placement group.  "});index.add({'id':141,'href':'/posts/cloud/aws/ec2/summary/','title':"Summary",'content':"Summary Tips\nPricing model  on Demand Reserved Spot  If the Spot instance is terminated by EC2, you will not be charged for a partial hour of usage, However if you terminate the instance yourself, you will be charged for any hour in which the instance ran   Dedicated Hosts  Instance Type EBS  Terminatin Protection is turned off by default, you must turn it omn On an EBS-backed instance, the default action is for the root EBS volume to be deleted whe the instance is termicated. EBS Root Volumes of your DEFAULT AMI\u0026rsquo;s can be encrypted. You can also use a third party tool(such as bit locker etc) to encrypt the root volume, or this can be done when creating AMI\u0026rsquo;s (remember the lab) in the AWS console or using the API. Additional volumes can be encrypted.  Security Groups  All inbound traffic is blocked by defailt. All Outbound traffic is allowed. Changes to Security Groups take effect immediately. You can have any number of EC2 instances within a security group. You can have multiple security groups attached to EC2 instances. Security Groups are STATEFUL. If you create an inbound rule allowing traffic in, that traffic is automatically allowed back out again. You cannot block specific IP address using Security Groups, instead use Network Access Control Lists. You can specify allow rules, but not deny rules.  Compare EBS Types  SSD  General Purpose SSD Provisioned IOPS SSD   HDD  Throughput Optimized HDD Cold HDD EBS Magnetic    EBS snapshots  Volumes exist on EBS, Think of EBS as a virtual hard disk. Snapshots exist on S3. Think of snapshots as a photograph of the disk. Snapshots are point in time copies of Volumes. Snapshots are incremental : this mean that only the blocks that have changed since your last snapshot are moved to S3 If this is your first snapshots, it may take some time to create. To create a snapshots for amazon EBS volumes that serve as root devices, you should stop the instance before taking the snapshot. However you can take a snap while the instance is running. You can create AMI\u0026rsquo;s from both volumes and snapshots You can change EBS volume sizes on the fly, including changing the size and storage type. Volumes will ALWAYS be in the same availability zone as EC2 instance  Migrating EBS  To move an ev2 volume from one AZ to another, take a snapshot of it, create an AMI from the snapshot and then use AMI to launch the EC2 instance in a new AZ. To move an EC2 volume from one region to another, take a snapshot of it, create an AMI from the snapshot and then copy the AMI from one region to the other. Then use the copied AMI to launch the new EC2 instance in the new region.  EBS Encryption   Snapshots of encrypted volumes are encrypted automatically.\n  Volumes restored from encrypted snapshots are encrypted automatically.\n  You can share snapshots, but only if they are unencrypted.\n  These snapshots can be shared with other AWS accounts or made public.\n  Q1 Root Device Volumes can now be encrypted. If you have an unencrypted root device volume that needs to be encrypted do th follwing;\n Create a Snapshot of the unencrypted root device volume Create a copy of the snapshot and select the encrypt option Create an AMI from the encrypted Snapshot Use that AMI to launch new encrypted instances    EBS vs Instance Store\n Instance Store Volumes are sometimes called Ephemeral Storage. Instance store volumes cannot be stoppted. If the underlying host fails, you will lose your data. EBS backed instances can be stopped. You will not lose the data on this instance if it is stopped. You can reboot both, you will not lose your data. By default, both ROOT volumes will be deleted on termincation. However, with EBS volumes, you can tell AWS to keep the root device volume.    Encrypting Root Device Volumes  Create a Snapshot of the unencrypted root device volume. Create a copy of the Snapshot and select the encrypt option. Create an AMI from encypted Snapshot Use that AMI to launch new encypted instances.  CloudWatch   CloudWatch is used for monitoring performance\n  CloudWatch can monitor most of AWS as well as your applications that run on AWS.\n  CloudWatch with EC2 will monitor events every 5minutes by default.\n  You can have 1 minute intervals by turning on detailed monitoring.\n  You can create CloudWatch alarms which trigger notifications.\n  CloudWatch is all about performance, CloudTrail is all about auditing.\n  What can i do with CloudWatch?\n Dashboards - creates awsome dashboards to see what is happening with your AWS environment. Alarms - Allows you to set Alarms that notify you when particular thresholds are hit. Events - CloudWatch Events helps you to respond to state changes in your AWS resources. Logs - CloudWatch Logs helps you to aggregate, monitor, and store logs.    CloudWatch vs CloudTrail\n CloudWatch monitors performance CloudTrail monitors API calls in the AWS platform.    CLI  You can interact with AWS from anywhere in the world just by using ther command line(CLI) You will need to set up access in IAM Commands themselves are not in the exam, but some basic commands will be useful to know for real life.  Roles  Roles are more secure than storing your access key and secret access key on individual EC2 instances. Roles are easier to manage. Roles can be assigned to an EC2 instance after it is created using both the console \u0026amp; command line. Roles are universal - you can use then in any region.  Bootstrap scripts  Bootstrap scrips run when an EC2 isntance first boots. Can be powerful way of automating software installs and updates.  Instance meta data \u0026amp; User data  Used to get information about an instance (Such as public IP) curl http://123.123.123.123/latest/meta-data/ curl http://123.123.123.123/latest/user-data/  EFS  Supprots the Network FIle System version 4 (NFSv4) Protocol You only pay for the storage you use (no pre-provisioning required) Can scale up to the petabytes Can support thousands of concurrent NFS connections Data is stored across multiple AZ\u0026rsquo;s within a region Read After Write Consistency  EC2 Placement Groups Three types placement groups\n Clusterd Placement Group  Low Network Latency / High Network Throughput   Spread Placement Group  Individual Critical EC2 instances   Partitioned  Multiple EC2 instances HDFS, HBase, and Cassandra     Tips  A clusted placement group can\u0026rsquo;t span multiple Availabilty zones. A spread placement and partitioned group can. The name you specify for a placement group must be unique within your AWS accout Only certain types of instances can be launched in a placement group(Compute Optimized, GPU, Memory Optimized, Storage Optimized) AWS recommend homogenous instances within clustered placement groups. You can\u0026rsquo;t merge placement groups. You can\u0026rsquo;t move an exising instance into a placement group. You can create an AMI from your exiting instance, and then launch a new intance from the AMI into a placement group    "});index.add({'id':142,'href':'/posts/cloud/aws/exam/part1/','title':"Part1",'content':"영역 1: 복원력을 갖춘 아키텍처 설계 AWS 인프라 구성  전 세계 21개의 지리적 리전 내에 66새의 가용영역을 운용  Region 의미  리전은 개별 지역 내 존재하는 지리적 위치  AZ (가용역역) 의미  가용영역은 리전 내 있는 구분된 가용성 영역 의미 전용선으로 연결되어 있어 한 클러스터처럼 동작  Amazon CloudFront 글로벌 엣지 네트워크  유저에게 짧은 지연시간으로 콘텐츠를 전송 할 수 있도록 해줌  특징  여러공격으로부터 네트워크 및 어플리케이션 계층을 보호 AWS Edge역할 가용성 향상을 위해 콘텐츠 캐싱 오리진 서버 부하 줄임 여러 오리진을 설정, 소스오리진 사용불가시 자동으로 백업 오리진 사용하도록 라우팅 프로그래밍 가능한 정식 API 제공      클라우드 서비스를 설계하는 방법  설계 포인트  보안 : 전송 및 보관시 암호화, IAM으로 권한 관리, VPC로 인프라 보호, CloudWatch로 감시 제어 활동 안정성: 복구 절차 테스트 및 자동 복구 설정, 수평확장이 가능하도록 구성 성능 효율화: AWS에서 최신 기술 쉽게 사용하도록 지원, 글로벌 어플리케이션 지원 및 서버리스 아키텍처를 이용한 새로운 아이디어 실험 비용 최적화: 오토 스케일링을 통한 필요한 자원만 사용, 비용 효율적인 지원 사용    AWS 기반 마이크로 서비스 아키텍쳐 구현 방안  마이크로서비스란?  작은 빌딩 블록, 높은 비결합성, 작은 작업 수행, 머듈식의 접근, 디자인 스타일 고려사항  리소스관리: EC2 컨테이너를 사용해서 유연하고 AWS 응용이 쉬운 상태로 설계, Lamda를 사용하여 Serverless이벤트 처리 방식의 컴퓨팅 서비스 사용 모니터링: AWS CloudWatch 서비스 Discovery: EC2 와 Route53 사용 배포: Blue-green 배포, Lambda 배포 사용      느슨한 결합을 구현하기 위한 서비스들  ELB  로드밸런서 선택 시 : 애플리케이션에 맞는 로드 밸런서 선택 Application load Balancer, Network load Balancer, Classic load balancer 를 적절히 사용 Application load balancer : HTTP, HTTPS, Websocket등 다양한 프로토콜 지원 하이브리드 로브 밸런싱 지원   SQS  메시지 대기열 시스템을 손쉽게 구축 가능, FIFO 대기열 사용 Amazon SNS와 차이점 - SNS는 폴링할 필요 하없이 푸쉬 메커니즘으로 메세지 전송, SQS에서는 폴링 모델로 메세지 교환 무조한 최초 1번은 전송을 한다.    복원력을 갖춘 스토리지 선택하기  EC2 - Amazon EBS  Amazon EBS : EC2에서 사용하는 일종의 하드 디스크로 다른 물리적 하드 드라이브처럼 사용가능, 다른 인스턴스에 EBS를 분리한 후 다른 인스턴스에 연결하는 것도 가능 인스턴스 스토어 : 휘발성 스토리지, 인스턴스가 활성화 되어 있는 동안 유지되는 스토리지, 상대적으로 성능이 낮으니 데이터 분석용으로 주로 사용 Amazon EFS : 인스턴스에 사용할 수 있는 간단하고 확장 가능한 파일 스토리지. 파일이 추가되고 제거됨에 따라 자동으로 증가하고 줄어든다. 저장 사용량만큼만 비용이 발생하기 때문에, 전체적인 Cost를 아낄 수 있다. Amazon S3 : 파일서버의 역할을 하는 서비스, 일반적인 파일 서버는 트래픽이 증가함에 따라서 장비를 증설하는 작업을 해야하는데 S3는 이와 같은 것을 대행한다. 저장할 수 있는 파일 갯수의 제한이 없으며, 데이터 손실이 발생할 경우 자동으로 복구하며, 정보에 중요도에 따라 보호 수준을 설정해 비용을 절감 할 수 있다.    AWS 사용 모범 사례  EC2 모범사례  보안 및 네트워크 : 자격증명 연동 및 IAM 역할을 사용해서 리소스 및 API 액세스를 관리한다. 스토리지: 운영체제에 대해 별도의 EBS 볼륨을 사용하고, 임시데이터를 저장할 수 있는 인스턴스 스토어를 사용한다. 리소스관리, 백업 및 복구: AWS EBS 스냅샷을 이용해 EBS 볼륨을 정기적으로 백업, 개인 AMI를 만들어 추후 인스턴스 시작을 위한 템플릿으로 구성 저장.   RDS 모범 사례  메모리, CPU 사용 모니터링 필수 DB 인스턴스 확장 DB 작업량이 늘어났을 경우, 프로비저닝 된 IOPS 스토리지로 변환 RAM을 충분히 할당하여 작업 집합이 메모리에 상주하도록 한다. CloudWatch모니터링을 사용하여 DB인스턴스에 대한 측정치를 확인    Amazon EC2 요금  온디맨드 : 실행하는 인스턴스에 따라 시간당 혹은 초당 비용 지불  유연하고 저렴하게 인스턴스를 사용하거나, 단기간 혹은 첫 개발, 시험중인 경우 사용하면 좋다.   스팟 인스턴스 : 입찰 가격을 정해두고 저렴할 때 이용가능  시작과 종료시간이 자유롭거나, 컴퓨팅 가격이 매우 쌀 때 수익이 나는 애플리케이션 경우에 사용   예약 인스턴스 : 계약 기간에 따라 60%까지 저렴하게 이용 가능  수요가 꾸준하거나, 예약 용량이 필요할 수 있는 애플리케이션에 사용    Amazone RDS?  아마존 클라우드에서 관계형데이터베이스를 사용할 수 있는 서비스 DB 관리 작업을 대신해줌 - 각 서버 구성 요소 독립적 확장, 백업 및 복구, 스냅샷 관리 및 보조 인스턴스로 가용성 향상 각 DB 인스턴스당 Mysql, MariaDB, PostgreSQL, Oracle 등등 엔진 사용가능 VPC를 사용하여 가상 사설 클라우드에서 인스턴스 실행 가능 다중 AZ: 데이터 중복 및 장애 조지 지원, 다른 가용 영역에서 자동으로 프로비저닝하고 유지하는 기능  AWS 클라우드에서의 웹 어플리케이션 호스팅 AWS CloudWatch를 사용하여 Auto Scaling 인스턴스 및 그룹 모니터링  모든 EC2 지표 인스턴스를 통계로 사용하여 시스템이 예상대로 수행되는지 확인 가능 주로 평균 CPU 사용률에 대해 지표를 생성하여 감시하는게 가능 무료는 5분 단위로 가능, 비용을 더 지불하면 1분 단위로 감시가능  "});index.add({'id':143,'href':'/posts/cloud/aws/exam/part2/','title':"Part2",'content':"영역2 : 성능이 뛰어난 아키텍처 정의 AWS ElastCache  클라우드 상에 메모리 기반으로 구성된 데이터 스토어 또는 캐시를 쉽게 운영할 수 있는 서비스 - In Memory 방식 Memcached 및 Redis와 호환되는 프로토콜이므로 기존 Memcached 또는 Redis환경에서 현재 사용하는 코드, 애플리케이션 및 주요도구를 Amazon ElasticCache에서 문제없이 사용 할 수 있다.  Amazon Machine Image : AMI  AMI란?  인스턴스를 시작할 때 필요한 정보를 제공 AMI 생성 및 등록한 후 새 인스턴스 시작할 때 그 이미지를 사용할 수 있으며, 동일 리전 및 다른 리전에서도 사용할 수 있음 AMI를 퍼블릭으로 설정하여 외부와 공유할 수 있으며, AMI marketplace에서 AMI를 판매할 수 있다.    사용자 인프라를 고려한 아키텍쳐 설계   사용자 \u0026gt; 100\n 기능에 따라 인스턴스 역할을 나눈다.  웹 서버용 인스턴스 DB용 인스턴스  편리한 DB 운영을 위해 Amazon RDS이용        사용자 \u0026gt; 1000\n Elastic Load Balaning : 확장성 높은 부하 분산 서비스 Multi AZ 서버 구성 데이터베이스 이중화  RDS 의 기본 예비 복제본 Multi AZ에 구성      사용자 : 10,000 - 100,0000+\n  기본 복제본과 읽기 전용 복제본(Read Replica)를 사용하여 데이터 접근 부하를 줄인다. 또한 정적 컨텐츠를 S3와 CloudFront로 이동하여 부하를 분산시킨다.    "});index.add({'id':144,'href':'/posts/cloud/aws/exam/part3/','title':"Part3",'content':"영역3: 안전한 애플리케이션 및 아키텍처 클라우드 보안 모범 백서  IAM 서비스 이용 : IAM으로 사용자가 어떤 AWS 서비스와 리소스에 액세스 할 수 있는지를 제어하는 암호, 액세스 키 및 사용권한 정책과 같은 보안 자격 증명을 한 곳에서 관리할 수 있다.  인프라 서비스의 책임 분담 모델  AWS 보안 글로벌 인프라를 바탕으로 자체 데이터 센터에서 온프레미스로 하는 것과 같은 방식으로 AWS클라우드에서 운영체제와 플랫폼을 설치 및 구성 불투명 계층에서 데이터 암호화, 인증 등 추가로 보안을 요구할 수 있다. AMI에서 EC2접속 키를 발급받으면 사용자는 이를 안전하게 보관해야 하며, AWS 내에서는 Private key가 저장되지 않는다.  컨테이너 서비스의 책임 분담 모델  AWS 가 플랫폼 및 애플리케이션 관리까지 함. AWS 컨테이너 서비스의 경우 컨테이너 서비스 액세스를 위한 데이터와 방화벽 규칙에 대한 책임은 고객에게 있다.  AWS에서 자산정의 및 분류  자산, 카테고리, 비용을 결정한 후, AWS에서 정보 보안 관리 시스템(ISMS)를 구현, 운영, 모니터링, 검토, 유지 보수, 개선하기 위한 표준을 설정 비즈니스 요건과 목표, 사용하는 프로세스, 조직의 크기와 구조에 따라 달라짐  AWS에서 계정, IAM 사용자, 그룹 역할 관리  Root 계정은 매우 강력한 권한이 있기 때문에 일반 업무시 사용하지 않는 것을 권장. IAM 사용자로 개별적인 사용자와 보안 그룹은 분리해 각 개인 그룹별 사용자로 구분하여 권한 제한을 하는 것이 좋음  AWS 인프라 보안  물리적 환경적 보안 : AWS직원의 데이터 센터에 대한 물리적 접근은 모두 기록되며 정기적으로 감사를 받으며, 여러 안전 대책에 의해 데이터 센터가 안전하게 보호됨. 연속성 관리 : 모든 데이터 센터는 온라인으로 고객에게 서비스를 제공하며, 어떤 데이터 센터도 정지 되지 않음. 또한 전 세계에 데이터 센터가 분산되어 있어 높은 가용성을 가진다. 보안 네트웤 아키텍처 : AWS는 DDOS, MITM, IP Spoofing, 포토 스캐닝, 패킷 스니핑 등의 공격 방어를 위해 강력한 보안 결함 차단 방식을 지원.  AWS 계정 보안 기능  AWS IAM : AWS 계정 내에서 여러 사용자를 생성하고, 이러한 사용자 각각의 권한을 관리, 임시 보안 자격 증명을 사용하여 제한된 시간 동안만 유효한 보안 자격 증명을 통해 보안 AWS리소스에 대한 임시 액세스를 사용자에게 제공 AWS MFA : 표준 사용자 이름과 암호 자격 증명 외에 6자리 일회용 코드를 입력해야 고객의 AWS계정 설정 또는 AWS 서비스 및 리소스 액세스 권한이 부여됨, 하드웨어 토큰 및 가상 MFA 디바이스의 사용을 모두 지원  AWS 서비스별 보안   AWS EC2 의 보안\n 하이퍼바이저를 이용하며, 리눅스 게스트의 경우는 반가상화를 활용, 고급 권한에 대한 통제를 한다. 하이퍼바이저를 통해 인스턴스는 물리적으로 상호 격리되어 보안성을 올린다.  가상 인스턴스는 오직 고객만 제어 할 수 있으며 전체 루트 액세스 또는 관리 제어 권한을 가진다. AWS는 고객의 인스턴스 또는 게스트 OS에 대한 어떤 액세스 권한도 접근할 수 없다. 방화벽 : EC2의 인바운드 방화벽은 기본적으로 모두 거부 모드로 구성되며, 사용자가 인바운드 트래픽을 허용하는 데 필요한 포트를 임의로 개방해야함. 예시: 웹 서버 그룹에는 인터넷에 개방된 포트 80(HTTP) 및/또는 포트 443(HTTPS)을 개방 애플리케이션 서버 그룹에는 웹서버 그룹에만 액세스 할 수 있는 8000번 포트로 구성 데이터베이스 서버 그룹에는 애플리케이션 서버 그룹에만 개방된 3006번 포트로 구성 세그룹 모두 22에 대한 관리 액세스는 허용하나, 고객의 기업 네트워크에서만 가능하게 특정 IP 대역만 잡속하도록 함.    AWS EBS 보안\n AWS EBS 볼륨에 대한 접근은 해당 볼륨을 생성한 AWS계정 및 IAM을 이용해 만든 AWS 계정 사용자로 제한되므로, 다른 모든 AWS계정 및 사용자에게는 볼륨을 보거나 접근하는 권한이 거부된다. AWS EBS에 저장된 데이터는 정상적인 서비스를 위해 물리적으로 여러 지점에 중복 보관된다.    AWS Elastic Load Balancing 보안\n Elastic Load Balancing은 온프레미스 로드 벨런서의 모든 장점 이외에 여러 가지 보안상 이점을 제공한다. EC2 인스턴스를 대신해 암호화 및 복호화 작업을 수행 및 로드 밸런서에서 중앙집중식으로 관리 가능 클라이언트에 단일 접점을 제공하며 네트워크 공격에 대한 1차 방어선 역할도 수행 AWS VPC를 사용하는 경우, ELB에 연결된 보안 그룹의 생성 및 관리를 지원하여 추가적인 네트워킹 및 보안 옵션을 제공 보안(HTTPS/SSL) 연결을 사용하는 네트워크에서 종단 간 트래픽 암호화를 지원    AWS VPC 보안\n AWS VPC를 사용하면 AWS 클라우드의 격리된 부분을 만들고, 선택한 범위에 프라이빗 주소가 있는 AWS　EC2 인스턴스를 시작 할 수 있다. 각 AWS VPC에서의 네트워크 트래픽은 다른 모든 AWS VPC와 격리됨. AWS　VPC는 인스턴스의 진출입 트래픽을 모두필터링 할 수 있는 완전한 방화벽 솔루션을 지원 네트워크 ACL: AWS VPC내 서브넷에서 인바운드 또는 아웃바운드하는 모든 트래픽에 적용되는 상태 비저장 트래픽 필터, 이러한 ACL은 IP 프로토콜, 서비스 포트, 원본/대상 IP 주소에 따라 트래픽을 허용 또는 거부하는 규칙을 포함함    AWS S3 보안\n 기본적으로 저장된 데이터에 대한 액게스는 제한됨, 버킷 및 객체 소유자에게만 자신이 생성한 AWS S3 리소스에 접근할 수 있다. 객체 접근에 대한 액세스 제어는 IAM, ACL, 버킷정책으로 할 수 있으며, 특정 조건을 기준으로 특정 리소스에 대한 액세스를 추가로 제한 할 수 있다.  데이터 저장시 S3 암호화 클라이언트와 같은 클라이언트 암호화 라이브러리를 사용하여 데이터를 암호화 한 후에 업로드 할 수 있으며, 장기 저장시 S3버킷의 콘텐츠를 Glacier에 자동으로 보관 할 수 있다. Amazon S3는 연간 99.999999999%의 객체 내구성과 99.99%의 가용성을 제공하도록 설계되었으며, 버전 관리 및 액세스 로그 열람으로 추가적인 보안을 제공한다.    AWS Glacier 보안\n AWS Glacier는 파일을 아카이브 단위로 볼트 내에 저장. 특정한 간격으로 Glacier에 데이터를 전송하도록 S3를 설정 할 수 있으며, 더 높은 수준의 보안을 달성하기 위해 SSL암호화 엔드포인트를 통해 AWS Glacier에 안전하게 데이터를 업로드 하거나 다운로드 할 수 있다.    AWS RDS 보안\n AWS RDS내에서 처음 DB인스턴스를 생성할 경우 DB 인스턴스에 대한 액세스를 제어하기 위해 AWS RDS안에서만 사용되는 사용자 계정을 만든다. 이후 추가로 계정 생성 가능 AWS VPC에 배포된 DB인스턴스는 VPN 또는 퍼블릭 서브넷에서 실행 할 수 있는 베스천 호스트를 통해 VPC 외부의 AWS EC2 인스턴스에서 액세스 할 수 있다. SSL을 사용하여 애플리케이션과 DB인스턴스 사이의 연결을 암호화 하여 보안수준을 높일 수 있지만, DB 연결 지연시간을 늘리는 단점 이있다. AWS RDS는 DB인스턴스 백업 및 복구를 위한 자동 백업 및 데이터베이스 스냅샷(DB스냅샷)을 제공한다.    Amazon CloudFront 보안\n Amazon CloudFront는 대상 API에 대한 모든 요청에 대해 인증을 요구하며 허가 받은 사용자만 Amazon CloudFront에서 배포하는 정보를 생성, 변경, 또는 삭제할 수 있도록 한다. Amazon CloudFront 로부터 콘텐츠를 다운로드 할 수 있는 사람들을 제한하고자 할 경우, 서비스의 콘텐츠 비공개 기능을 사용하도록 설정할 수 있다. Amazon CloudFront엣지에서 Amazon S3에 있는 고객 소유 객체에 액세스하는 방법을 제어하거나, 두번째　Amazon CloudFront엣지에서 인터넷의 최종 사용자에게 콘텐츠를 전달하는 방법을 제어한다. 또한 웹 어플리케이션에 지리적 제한 로직을 추가함으로써 최종 사용자의 지리적 위치에 따라 콘텐츠에 대한 액세스를 차단하도록 사용자 지정 할 수 있다. Amazon CloudFront는 사용자에게 전달되는 콘텐츠를 인증할 수 있도록 암호화된 연결 (HTTPS)을 통해 콘텐츠를 전달하는 기능을 제공한다. Amazon CloudFront 기본적으로 HTTP 및 HTTPS프로토콜을 통해 요청을 수락하며, 필요한 경우 모든요청에 대해 HTTPS를 요구하고 HTTP요청은 모두 허용하지 않도록 Amazon CloudFront를 설정할 수도 있다. Amazon CloudFront에서 고유의 도메인 이름을 사용하려면 SSL인증서를 AWS IAM인증서 스토리지에 업로드한 후 해당 인증서를 Amazon CloudFront 배포에 연결해야 한다.    AWS Security by Design  Security by Design?  여러 산업계, 표준 및 보안 기준 전체에서 대규모의 보안 및 규정 준수를 유지하기 위한 4단계 접근법  수정 권한이 없는 사용자가 재정의할 수 없는 강제 기능 생성. 안정적인 제어 작업 구축 지속적인 실시간 감사 기능. 거버넌스 정책을 스크립팅하는 기술      AWS 환경에서의 보안  AWS 클라우드에서 시스템을 배포할 때는 AWS 및 고객이 보안 책임을 공동으로 부담한다. AWS는 기반 인프라에 대한 보안을 담당하는 반면, 사용자는 AWS에 배포된 IT리소스에 대한 보안을 담당한다. Security by Design 접근법은 4단계로 구성되어 있다.  1단계 : 요구사항 확인 2단계 : 요구사항 및 구현 조건에 맞는 \u0026ldquo;골드환경\u0026rdquo; 구축. 3단계 : 템플릿 사용설정. 4단계 : 검증작업 수행.   1단계 - 요구사항 확인  먼저 보안 제어 합히화 작업을 수행하며, 현재 고객 아키택처에 최적화되어 운영중인 제어를 식별하고, 기존 AWS인증내역, 승인 및 보고서로 부터도 참조할 내역을 식별하여 보안 Controls Implementation Matrix(CIM)를 생설 할 수 있다.   2단계 - \u0026ldquo;골드환경\u0026rdquo; 구축  이단게는 사용자가 AWS가 제공하는 광범위한 보안 및 감사 서비스와 기능을 서로 연결하고, 보안, 규정 준수 및 감사 담당자에게 보안 및 규정 준수 환경을 구성하는 간단한 방법을 제공하도록 한다. IAM으로 액세스 관리, VPC나 subnet을 이용한 네트워크 분할, 리로스 제약 조건 및 모니터링, 데이터 암호화를 통해 기능을 연결 할 수 있다. AWS GoldBase : AWS GoldBase는 특정 보안/규정 준수 요구 사항 내에서 사전 점검되고 자동화된 참조 아키텍처를 제공한다. AWS GoldBase 사용 사례 패키지는 기준 CloudFormation 템플릿으로 구성되는데, 사용자는 이를 고객 환경 내 배포용으로 사용자 지정할 수 있다. 자세한 내용은 “AWS GoldBase 소개” 백서 참조   3단계 - 템플릿 사용 설정  “골드 환경”을 만든 후에는 AWS에서 이를 사용할 수 있도록 설정해야 하는데, 서비스 카탈로그를 설정하여 이를 수행할 수 있다. 서비스 카탈로그를 설정하면 계정에 액세스하는 모든 사용자가 만들어진 CloudFormation 템플릿을 사용하여 자신의 환경을 만들어야 한다. 사용자가 환경을 사용할 때마다 이러한 “골드 환경” 규칙이 모두 적용되어, 제어의 나머지 고객 계정 보안 구성을 효과적으로 조작할 수 있으므로 감사에 대비할 수 있다   4단계 - 검증작업 수행  이 단계의 목표는 AWS 고객이 일반적으로 용인되는 공공 감사 표준을 기준으로 독립적인 감사를 지원할 수 있도록 하는 것. AWS는 규정을 준수하지 않는 인스턴스가 실제로 있는지 여부를 감지하는 AWS Config를 제공하며, AWS Config는 아키텍처의 현재 시점 설정정보를 제공한다. 또한 AWS는 보안된 읽기 액세스를 통해 여러 감사 증거 수집 기능과 증거 모음을 자동으로 감사하는 고유 API 스크립트를 함께 제공한다.    AWS IAM 모범사례 AWS 계정 루트 사용자 액세스 키 잠금  AWS 계정 루트 사용자 액세스 키는 사용하면 안된다. 만약 그 계정의 루트 액세스 키카 탈취 되면 계정과 연관된 모든 정보, 신용카드정보 유출  개별 IAM 사용자 만들기  루트 자격 증명을 사용하여 액세스 하는 것은 안되며, 관리자 IAM을 생성하여 액세스해야하는 계정에 별도의 사용자 계정을 만드는 것이 권장된다. 또한 그룹을 사용하여 사용자 그룹에 대한 정의를 만들어 그룹권한을 설정하는 것이 관리하기 더 편하다. IAM정책을 개인이나 그룹에 적용 할 때는 작업 수행에 필요한 최소한의 권한을 주어 다른 서비스 접근을 못하게 한다.  엑세스 레밸을 이용한 IAM 권한 검토  AWS은 작업 내용에 따라 각 서비스 작업을 다섯개의 액세스 레밸 즉, List, Read, Write, Permissions management, Tagging 중 하나로 분류한다. 이러한 액세스 레벨을 사용하여 어떤 작업을 정책에 포함할지 결정 할 수 있다.  권한있는 사용자에 대해 MFA 활성화  보안을 강화하기 위해 중요한 리소스 또는 API작업에 대해 액세스 권한이 부여된 IAM 사용자에 대해 멀티 팩터 인증을 적용 가상 핸드폰이나 실제 디바이스가 코드 생성하면 그번호를 입력해야 로그인 할 수 있다.  AWS 게정의 활동 모니터링  AWS의 로깅 기능을 사용하여 사용자가 계정에서 수행한 작업과 사용한 리소스를 확인하여 보안 수준을 올린다. 로그 파일에는 작업 시간 및 날짜, 작업의 소스 IP, 부족한 권한으로 인해 실패한 작업등이 나와 있다. 이러한 기록을 통해 비 정상적인 접근이 있는지 확인 가능하다.  보안 서비스 - Amazon VPC VPC 개념  VPC는 사용자의 AWS계정 전용 가상 네트워크 VPC는 AWS 클라우드에서 다름 가상 네트워크와 논리적으로 분리되어 있으며, Amazon EC2 인스턴스와 같은 AWS 리소스를 VPC에서 실행 할 수 있다. 서브넷: VPC의 IP 주소 범위, 지정된 서브넷으로 AWS리소스를 시작할 수 있다. 인터넷에 연결되어야 하는 리소스에는 퍼블릭 서브넷을, 인터넷에 연결되지 않는 리소스에는 프라이빗 서브넷을 사용한다.  인터넷 액세스  기본적으로 기본이 아닌 서브넷에서 시작한 인스턴스 프라이빗 Ipv4 주소가 있으며, 시작 시 특별히 지정하지 않는 한 퍼블릭 IPv4주소는 없다. 이러한 인스턴스는 서로 통신 할 수는 있지만 인터넷 액세스 할 수는 없다.   기본이 아닌 서브넷에서 시작한 인스턴스에 대해 해당 VPC에 인터넷 게이트웨이를 추가하고(해당 VPC가 기본 VPC가 아닐 경우)인스턴스에 탄력적 IP 주소를 연결하여 인터넷 액세스를 가능하게 할 수 있다.   원할 경우 IPsec AWS Site-to-Site VPN연결을 사용하여 VPC를 회사의 데이터 선터에 연결함으로써 회사 데이터 센터를 AWS 클라우드로 확장 할 수 있다. Site-to-Site VPN 연결은 VPC에 추가된 가상 프라이빗 게이트웨이와 데이터 센터에 위치하는 고객 게이트 웨이로 구성된다.  \u0026lsquo;핵심\u0026rsquo; Amazon EC2 및 S3 보안 기능 집합 Amazon S3 리소스에 대한 액세스 권한 관리  기본적으로 버킷, 객체 및 관련 하위 리소스를 비롯한 모든 아마존 s3리소스는 비공개이다. 즉, 리소스를 만든 AWS 계정인 리소스 소유자만 해당 리소스에 액세스 가능하다. 리소스 기반 정책, 사용자 정책 또한 이러한 정책의 조합을 사용하도록 선택하여 Amazon S3 리소스에 대한 권한을 관리 할 수 있다. ACL : 각 버킷과 객체마다 연결된 ACL이 존재, ACL로 다른 AWS 계정에 기본적인 읽기/쓰기 권한을 부여한다.  버킷정책 : 본인의 버킷에 한해 다른 AWS 계정이나 IAM 사용자에게 버킷과 버킷에 포함된 객체에 대한 권한을 부여하는 버킷 정책을 추가 할 수 있다. 버킷정책은 ACL기반 액세스 정책을 보완하여 대부분의 경우 액세스 정책을 대신한다.  사용자 정책 : IAM로 Amazon S3 리로스에 대한 액세스를 관리 할 수 있다. 내 계정으로 IAM 사용자, 그룹, 역할을 만들고 액세스 정책을 연결하면 Amazon S3등 AWS리소스에 액세스 가능하다.  DDos 완화 DDos 대응을 위한 AWS 모범 사례  DDos 공격 : 최종 사용자(End User)가 여러분의 웹 사이트나 어플리케이션을 이용할 수 없도록 만드는것, 대표적으로 네트워크나 다른 자원들을 고갈시켜 사용자의 정당한 요청을 처리할 수 없게끔 만들어 버림.  DDos 완화 기법들  ELB와 EC2와 같은 AWS리전 내부의 서비스들은 해당 리전 내에서 예상치 못한 트래픽의 볼륨을 다룰 수 있게끔, 확장하는 방식으로 DDos대응력을 확볼 할 수 있다. Amazon CloudFront, AWS WAF, Amazon Route 53, Amazon API Gateway 같은 엣지 로케이션에 제공되는 서비스를 이용하면, 글로벌 네트웍 커버리지를 이용하여 장애 대응력을 확보 할 수 있다. 인스턴스 사이즈 조절 : 필요한 만큼 인스턴스들을 어플리케이션 환경에 추가하는 방식으로 수평적으로 확장하거나, 좀더 큰 인스턴스로 수직 확장시키는 방법을 선택할수있다. 엣지에서 도메인 이름 변환하기 : Amazon Route53은 셔플 샤딩과 애니캐스트 스트라이핑 기능을 사용하여, Route53이 DDos공격을 받더라도, 사용자가 여러분의 어플리케이션에 접근 할 수 있게 해준다. 셔플샤딩: 위임 집합(delegation set) 내의 각 네임 서버들에 대해 엣지 로케이션들과 인터넷 경로들을 묶은 집합을 대응시켜주는 기능 공격 지점 줄이기: 리소스이 전혀 최종 사용자들과 직접적인 상호 작용을 하지 않는다면, 해당 리소스들이 인터넷과의 직접적인 접근을 갖지 않도록 해야함. AWS 리소스 감추기: 대부분의 어플리케이션에서는 AWS 리소스들이 인터넷 상에 완전히 노출될 필요가 없다. 예를 들어, ELB 뒷 단에 있는 Amazon EC2 인스턴스들은 인터넷 상에서 바로 접근할 필요가 없다. 이런 구성은 Amazon Virtual Private Cloud(VPC) 내부의 보안 그룹(Security Group)과 네트웍 접근제어 목록(NCAL)을 설정하면 된다. 보안 그룹: 인터넷으로부터 보안 그룹으로의 모든 트래픽들은 여러분들이 명시적으로 해당 트래픽을 허용해주지 않으면 기본적으로 차단된다. 예를 들어, 하나의 ELB 와 여러 대의 Amazon EC2 인스턴스들로 웹 어플리케이션을 구성했을 때, ELB 에 적용할 단일 보안 그룹(‘ELB 보안 그룹’)을 적용할 지, 인스턴스 별로 여러 개의 서로 다른 보안 그룹(‘웹 어플리케이션 서버 보안 그룹’)을 적용할 지는 결정해야 한다 API 엔드 포인트를 보호하기: Amazon API Gateway 를 이용하게 되면, API 의 앞 단에 별도의 서버를 구성할 필요가 없으며, 어플리케이션 구성 요소들을 외부에서 잘 안보이도록 감출 수 있게 된다. Amazon API Gateway 는 Amazon CloudFront 와 연계되어 있으며, 서비스가 자체적으로 DDoS 대응력을 갖출 수 있게끔 해주는 이점을 줄 수 있다. 운영 기법들- 가시성: Amazon CloudWatch 를 통해, AWS 상에서 운영되고 있는 어플리케이션들을 모니터링 할 수 있다. VPC Flow logs: VPC Flow Logs 를 이용한다면, VPC 내의 네트웍 인터페이스들을 통해 주고받는 IP 트래픽에 대한 정보를 얻을 수 있다.  암호화 솔루션 AWS에서의 저장 데이터 암호화  암호화에 필요한 3가지 요소  암호화할 데이터 데이터를 암호화하는 방법 데이터 및 알고리즘과 함께 사용될 키   AWS 의 암호화 방법 3가지 사용자가 암호화 방법 및 전체 KMI 제어 사용자가 암호화 방법을 제어하고 AWS가 KMI 스토리지 구성요소를 제공, 사용자가 KMI관리 계층을 제공 AWS가 암호화 방법 및 전체 KMI 를 제어   사용자가 암호화 방법 및 전체 KMI 제어  Amazon S3 : 사용자가 원하는 모든 암호화 방법을 사용하여 데이터를 암호화한 다음, Amazon Simple Storage Service(S3) API를 사용하여 암호화된 데이터를 업로드 AWS SDK에 포함되어 있는 오픈 소스 API 세트를 활용하여 암호화 가능 Amazon EBS: 인스턴스에 블록 디바이스로 제공되므로 파일 시스템 수준 또는 블록 수준 암호화를 위해 대부분의 표준 암호화 도구를 활용할 수 있다.  사용자가 암호화 방법 제어, AWS가 KMI 스토리지 구성 요소 제공 및 사용자가 KMI 관리 계층 제공  사용자가 암호화 방법을 관리한다는 점에서 모델 A와 유사하지만, 키를 사용자가 온프레미스에서 관리하는 키 스토리지 시스템이 아닌 AWS CloudHSM 에 저장한다는 점이 모델 A와 다르다 HSM은 키 구성 요소를 생성하고 저장하는 데 사용할 수 있으며, 암호화 및 복호화 작업을 수행하지만, 키 수명 주기 관리 기능(예: 액세스 제어 정책, 키 로테이션)을 수행하지는 않는다.  AWS가 암호화 방법 및 전체 KMI 제어  KMS: 관리형 암호화 서비스로, 키를 프로비저닝하고 사용하여 AWS 서비스에서 데이터 및 애플리케이션을 암호화하도록 해준다. AWS KMS 및 데이터를 직접 암호화하는 기타 서비스는 봉투 암호화라는 방법을 사용하여 성능과 보안 간 균형을 유지  "});index.add({'id':145,'href':'/posts/cloud/aws/exam/part4/','title':"Part4",'content':"영역4 - 비용에 최적화된 아키텍처 설계 비용 최적화 단계  가장 낮은 비용으로 용량 요구 사항을 충족하도록 적절하게 서비스 규모 조정 예약시 비용 절감 스팟 시장 사용 서비스 사용 모니터링 및 추적 Cost Explorer를 사용하여 비용 절감 최적화  서비스의 올바른 크기 조절 유형  EC2는 각 사용 사례에 맞게 최적화된 다양한 인스턴스 유형을 제공 인스턴스 유형은 CPU, 메모리 스토리지 및 네트워킹 용량의 다양한 조합으로 구성되며, 애플리케이션에 따라 적합한 리소스 조합 선택  인스턴스 유형 - 범용  범용 인스턴스는 균형있는 컴퓨팅, 메모리 및 네트워킹 리소스 제공 다양한 여러 워크로드에 사용 웹 서버 및 코드 리포지토리와 같이 이러한 리소스를 동등한 비율로 사용하는 어플리케이션에 적합   인스턴스 유형 - 컴퓨팅 최적화  고성능 프로세서를 활용하는 컴퓨팅 집약적인 애플리케이션에 적합 배치 처리 워크로드, 미디어 트랜스코딩, 고성능 웹 서버, HPC(고성능 컴퓨팅), 과학적 모델링, 전용 게임 서버 및 광고 서버 엔진, 기계 학습 추론 및 기타 컴퓨팅 집약적인 애플리케이션에 매우 적합   인스턴스 유형 - 메모리최적화  메모리 최적화 인스턴스는 메모리에서 대규모 데이터 세트를 처리하는 워크로드를 위한 빠른 성능을 제공하기 위해 설계되었습니다.   인스턴스 유형 - 가속화된 컴퓨팅  가속화된 컴퓨팅 인스턴스는 하드웨어 액셀러레이터 또는 코프로세서를 사용하여 부동 소수점 수 계산이나 그래픽 처리, 데이터 패턴 일치 등의 기능을 CPU에서 실행되는 소프트웨어보다 훨씬 효율적으로 수행합니다.   인스턴스 유형 - 스토리지 최적화  로컬 스토리지에서 매우 큰 데이터 세트에 대해 많은 순차적 읽기 및 쓰기 액세스를 요구하는 워크로드를 위해 설계되었습니다. 이러한 인스턴스는 애플리케이션에 대해 지연 시간이 짧은, 수만 단위의 무작위 IOPS(초당 I/O 작업 수)를 지원하도록 최적화되었습니다.   스토리지 클래스  Amazon S3는 전체 수명 주기 동안 데이터를 관리할 수 있는 기능도 제공합니다. S3 수명 주기 정책을 설정한 후에는 애플리케이션 변경 없이 데이터가 다른 스토리지 클래스로 자동으로 전송됩니다.  Amazon S3 Standard(S3 Standard)  자주 액세스하는 데이터를 위해 높은 내구성, 가용성 및 성능을 갖춘 객체 스토리지를 제공 짧은 지연 시간과 많은 처리량을 제공하므로 클라우드 애플리케이션, 동적 웹 사이트, 콘텐츠 배포, 모바일 및 게임 애플리케이션, 빅 데이터 분석 등의 다양한 사용 사례에 적합 S3 수명 주기 정책을 사용하여 애플리케이션 변경 없이 자동으로 스토리지 클래스 간에 객체를 전환할 수 있습니다.  Amazon S3 Intelligent-Tiering(S3 Intelligent-Tiering)  성능 영향 또는 운영 오버헤드 없이 가장 비용 효과적인 액세스 계층으로 데이터를 자동으로 이동하여 비용을 최적화하기 위해 설계 두 개의 액세스 계층에 객체를 저장  한 계층은 빈번한 액세스에 맞게 최적화 다른 한 계층은 빈번하지 않은 액세스에 맞게 최적화   수명이 길고 액세스 패턴을 알 수 없거나 예측할 수 없는 데이터에 이상적  Amazon S3 Standard-Infrequent Access(S3 Standard-IA)  S3 Standard-IA는 자주 액세스하지 않지만 필요할 때 빠르게 액세스해야 하는 데이터에 적합 낮은 비용과 높은 성능의 조합을 제공하는 S3 Standard-IA는 장기 스토리지, 백업 및 재해 복구 파일용 데이터 스토어에 이상적  Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)  S3 Standard 또는 S3 Standard-IA 스토리지와 같은 가용성 및 복원력이 필요 없는 고객에게 적합 온프레미스 데이터 또는 쉽게 다시 생성할 수 있는 데이터의 보조 백업 복사본을 저장하는 경우  Amazon S3 Glacier(S3 Glacier)  온프레미스 솔루션과 비슷하거나 더 저렴한 비용으로 원하는 양의 데이터를 안정적으로 저장  Amazon S3 Glacier Deep Archive(S3 Glacier Deep Archive)  Amazon S3에서 가장 저렴한 비용의 스토리지 클래스 1년에 한두 번 정도 액세스할 수 있는 데이터의 장기 보관 및 디지털 보존을 지원 백업 및 재해 복구 사용 사례에도 사용할 수 있으며 온프레미스 라이브러리든 오프프레미스 서비스든 상관없이 자기 테이프 시스템에 대한 비용 효과적이고 관리하기 쉬운 대안  예약을 통한 비용 절감  예약 인스턴스는 전체 선결제(AURI), 부분 선결제(PURI) 또는 선결제 없음(NURI)이라는 3가지 옵션으로 제공 예약 용량을 사용함으로써 조직은 위험을 최소화하고, 예산을 좀 더 예측 가능하게 관리하며, 장기 약정을 요구하는 정책을 준수  스팟 시장 사용  Amazon EC2 컴퓨팅 예비 용량에 입찰 같은 예산으로 애플리케이션의 컴퓨팅 파워와 처리 속도를 높이며, 새로운 유형의 클라우드 컴퓨팅 애플리케이션을 실행  Cloud Watch  Amazon CloudWatch를 사용하여 지표를 수집 및 추적하고, 로그 파일을 모니터링하며, 경보를 설정하고, AWS 리소스 변경에 자동으로 대응할 수 있습니다. 또한 Amazon CloudWatch를 사용하여 시스템 전반의 리소스 사용률, 애플리케이션 성능, 운영 상태 파악  Trusted Advisor  리소스를 프로비저닝하여 시스템 성능과 안정성을 높이고, 보안을 강화하며, 비용을 절감할 기회를 모색할 수 있습니다. 또한 늘어나거나 줄어드는 수요를 충족하기 위해 비프로덕션 인스턴스를 끄고 Amazon CloudWatch 및 Auto Scaling을 사용할 수도 있습니다.  Cost Explorer "});index.add({'id':146,'href':'/posts/cloud/aws/exam/part5/','title':"Part5",'content':"영역5 : 운영 면에서 탁월한 아키텍처 정의 CloudWatch 이벤트를 사용한 Amazon EC2 자동화  CloudWatch Events를 사용하여 AWS 서비스를 자동화하고 애플리케이션 가용성 문제나 리소스 변경 같은 시스템 이벤트에 자동으로 응답  CloudWatch 이벤트에서 자동으로 트리거 할수 있는 서비스  AWS Lambda 함수 호출 Amazon EC2 Run Command 호출 Amazon Kinesis Data Streams로 이벤트 릴레이 AWS Step Functions 상태 머신 활성화 Amazon SNS 주제 또는 Amazon SQS 대기열 알림  CloudWatch 이벤트를 Amazon EC2에 사용하는 몇 가지 예  새로운 Amazon EC2 인스턴스를 시작할 때마다 Lambda 함수를 활성화합니다. Amazon EBS 볼륨을 생성하거나 수정할 때 Amazon SNS 주제를 알립니다. 다른 AWS 서비스에서 특정 이벤트 발생 시 Amazon EC2 Run Command를 사용하여 명령을 하나 이상의 Amazon EC2 인스턴스에 전송합니다.  AWS CloudTrail을 사용하여 Amazon EC2 및 Amazon EBS API 호출 로깅  cloudTrail은 콘솔의 호출 및 API 코드 호출 등 Amazon EC2 및 Amazon EBS에 대한 모든 API 호출을 이벤트로 캡처  일반적인 문제 해결 정보 및 질문 "});index.add({'id':147,'href':'/posts/cloud/aws/iam/chapter01/','title':"Chapter01",'content':"IAM 정리  IAM   Users Groups Policies Roles    Root account is simply the account created when first setup your aws account it has complete admin access\n  Always setup MFA on your root account.\n  password customise.\n  "});index.add({'id':148,'href':'/posts/cloud/aws/iam/chapter03/','title':"Chapter03",'content':"S3 What is S3?\n S3 is a safe place to store your files. It is Object-based storage. The data is spread across multiple devices and facilities.  Basic of S3\n S3 is Object-based - i.e. allows you to upload files. Files can be from 0 Bytes to 5 TB. There is unlimited storage. Files are stored in Buckets. S3 is a universal namespace That is names must be unique globally. ex\u0026gt; httpL//s3-eu-west-1.amazoneaws.com/aaaa When you upload a file to S3, you will receive a Http 200 code if the upload was sucessful.  Object\n Key Value Version ID Metadata Subresources;  Access Control lists    How does data consistency work for S3?\n Read after Write consistency for PUTs of new Objects Eventual Consistency for overwrite PUTS and DELETES (can take some time to propagate)  In other words;\n If you write a new file and read if immediately afterward, you will be able to view that data. If you update AN EXISTING file or delete a file and read it immediately, you may get the older version, or you may not, Basically changes to objects can take a little bit of time to propagate.  S3 features;\n Tiered Storage Available Lifecycle Management Versioning Encryption MFA delete Secure your data using Access Control lists and Bucket Policies  S3 Storage classes\n S3 Standard S3 - IA(Infrequently Accessed) S3 One Zone - IA S3 - Intelligent Tiering S3 Glacier S3 Glacier Deep Achive  S3 Transfer Acceleration\n"});index.add({'id':149,'href':'/posts/cloud/aws/iam/summary/','title':"Summary",'content':"S3 \u0026amp; IAM Identiti Access Management Consists of the follwing;\n Users Groups Roles Policies  IAM summary\n IAM is universal. if does not apply to regions at this time. The \u0026ldquo;root account\u0026rdquo; is simply the account created when first setup your AWS account. It has complete Admin access. New Users have NO permissions when first created. New Users are assigned Access Key ID \u0026amp; Secret Access Keys when first created. These are not the same as a password. You cannot use the Access Key ID \u0026amp; Secret Access Key to Login in to the console. You can use this to access AWS via the APIs and CLI You only get to view these once. If you lose them, you have to regenerate them, so save them in a secure location. Always setup Multifactor Authentication on your root account. You can create and customise your own password rotation policies.  S3 summary\n  Rememver that S3 is Object-based; i.e.allows you to upload files.\n  Files can be from 0 Bytes to 5 TB.\n  There is unlimited storage.\n  Files are stored in Buckets.\n  S3 is a universal namespace. That is, names must be unique globally.\n  Not suitable to install an operating system on.\n  By default, all newly created buckets are PRIVATE. You can setup access control to your buckets using;\n Bucket Policies Access Control Lists    S3 buckets can be configured to create access logs which log all requests made to the S3 bucket. This can be sent to another bucket and even another bucket in another account.\n  The Key fundamentals of S3\n Key Value Version ID Metadata Subresources Read after consistency for PUTS of new Objects Eventual Consistency for overwrite PUTS and DELETES (can take some time to propagate)  Exam Tips\n S3 standard S3 - IA S3 One zone - IA S3 - intelligent Tiering S3 Glacier S3 Glacier Deep Archive  Encryption In Transit is achieved by\n SSL/TLS Encryption At Rest (Server Side) is achieved by S3 managed Keys - SSE-S3 AWS Key Management Service, Managed Keys - SSE-KMS Server Side Encryption With Customer Provided Keys SSE-C Client Side Encryption  Cross Region Replication\n Versioning must be enabled on both the source and destination buckets. Regions must be unique. Files in an existing bucket are not replicated automatically All subsequent updated files will be replicated automatically. Delete markers are not replicated. Deleting individual versions or delete markers will not be replicated. Understand what Cross Region Replication is at a high level.  Lifecycle Policies\n Automates moving your objects between the different storage tiers. Can be used in conjunction with versioning. Can be applied to current versions and previous versions.  CloudFront\n Edge Location : This is the location where content will be cached. This is separate to an AWS Region/AZ.  Edge location are not just READ only \u0026ndash; you can write to them too.(ie. put an object on to them) Objects are cached for the life of the life of the TTL (Time To Live) You can clear cached objects, but you will be charged.   Origin : This is the origin of all the files that the CDN will distribute. This can be either an S3 Bucket, an EC2 instance, an Elastic Load Balancer, or Route53 Distribution : This is the name given the CDN which consists of a collection of Edge Locations. Web Distribution : Typically used for Websites. RTMP : Used for Media Streaming.  Snowball\n Understand what snowball is Snowball can Import to S3 Export from S3  Storage Gateway\n File Gateway   For flat files, stored directly on S3.  Volume Gateway   Stored Volumes - Entire Dataset is stored on site and is asynchronuly backed up to S3. Cached Volumes - Entire Dataset is stored on S3 and the most frequently accesed data is cached on site  Gateway Virtual Tape Libary   Used for backup and uses popular backup applications like NetBackup, Backup Exec, Veem etc.  Tips\n Read the S3 FAOs before taking the exam, It comes up a LOT !!!!!  "});index.add({'id':150,'href':'/posts/framework/mybatis/mybatis-%EB%AC%B8%EC%9E%90%EC%97%B4-%ED%95%B4%EA%B2%B0/','title':"Mybatis 문자열 해결",'content':"Mybatis 사용시 쿼리문에 문자열 비교연사자나 부등호를 사용할 때 가 있다.\nselect * from user where salary \u0026gt; 100;\n일때 \u0026lsquo;\u0026gt;'와 같은 기호가 괄호인지 비교연산자인지 모르는데,\n이럴때 '\u0026lt;![CDATA[\u0026rsquo; 을 사용하면 CDATA 안에 들어가는 문장을 문자열로 인식하게 된다.\n"});index.add({'id':151,'href':'/posts/framework/springboot/java-reflection/','title':"Java Reflection",'content':""});index.add({'id':152,'href':'/posts/framework/springboot/jwt_authenticate_process/','title':"J W T Authenticate Process",'content':"Spring Security 필요개념  접근주체(Principal) : 접근 사용자 인증(Authenticate) : 접근 주체 확인 인가(Authorize) : 접근 주체의 권한 검사  스프링의 구조는 필터와 필터된 Authentication객체를 가지고 실질적인 Validation을 하는 Provider로 나뉜다.\nFilter chain 스프링 시큐리티 역시 Filter가 구성이 되어있다.\n기본적으로 11개의 Filter로 구성이 되어있고, Filter를 커스터마이징 하여 추가 확장 시킬수 있다.\n이때 중요한것은 필터간의 순서가 중요하다.\nProvider 프로바이더는 실질적인 검증을 하는 클래스로 AuthenticationProvider를 구현하고\nAuthenticationManagerBuilder에 커스터마이징하여 등록이 가능하다.\n@Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.authenticationProvider(authenticationProvider); auth.authenticationProvider(jwtAutenticationTokenProvider); } "});index.add({'id':153,'href':'/posts/framework/springboot/spring-aop/','title':"Spring a O P",'content':"스프링 AOP를 구현하는 방법 기술. AOP 개념\nAspect : 공통 기능을 말합니다.\nAdvice : Aspect의 기능 자체를 말합니다.\nJointpoint : Advice를 적용해야 하는 부분입니다. 필드나 메소드이고, 스프링에서는 메소드만\n해당됩니다.\nPointcut : Jointpoint의 부분, 실제로 Advice가 적용된 부분\nWeaving : Advice를 핵심 기능에 적용하는 행위를 말합니다.\n  RTW (Runtime Weaving) 스프링 AOP에서 사용하는 위빙 방식. Proxy를 생성하여 실제 타깃 오브젝트의 변형없이 위빙을 수행. 실제 런타임 시, 메소드 호출과 동시에 위빙이 이루어 지는 방식이다.\n장점 : 소스파일, 클래스파일의 변형이 없다. 단점 : 포인트 컷에 대한 어드바이스 적용 갯수가 늘어 날수록 성능이 떨어진다.\n  CTW (Compile time Weaving) AspectJ에는 AJC (AspectJ Compiler)라는 컴파일러가 있는데 Java Compiler를 확장한 형태의 컴파일러이다. AJC를 통해 java파일을 컴파일 하며, 컴파일 과정에서 바이트 코드 조작을 통해 Advisor 코드를 직접 삽입하여 위빙을 수행\n장점 : 위빙중 가장 빠른 퍼포먼스 (JVM상에 올라 갈때 메소드 내에 이미 advice 코드가 삽입 되어있기 때문에..) 단점 : 컴파일 과정에서 lombok과 같이 컴파일 과정에서 코드를 조작하는 플러그인과 충돌이 발생할 가능성이 아주 높다. (거의 같이 사용 불가)\n  LTW (Load time Weaving) ClassLoader를 통해 JVM에 로드 될 때 바이트 코드 조작을 통해 위빙이 되는 방식 RTW와 마찬가지로 소스코드와 클래스파일에 조작이 없다. 하지만 오브젝트가 메모리에 올라가는 과정에서 위빙이 일어나기 때문에 런타임 시, 시간은 CTW보다 상대적으로 느리다\n장점 : 소스파일, 클래스파일의 변형이 없다. 단점 : performance가 저하, 설정의 복잡.\n  스프링 프레임워크에서 지원하는 3가지 AOP 기술\n JDK dynamic proxy, CGLIB, AspectJ  AOP 적용 방식에 따른 분류\n 프록시 기반 : JDK dynamic proxy, CGLIB 타깃 오브젝트 조작 : AspectJ  JDK Dynamic Proxy \u0026amp; CGLIB\nAspect 프레임워크와는 달리 스프링에서는 간단한 설정만으로 JDK Dynamic Proxy와 CGLIB 방식을 사용할 수 있도록 되어 있습니다. 두 방식의 차이는 인터페이스의 유무로서, AOP의 타깃이 되는 클래스가 인터페이스를 구현했다면 JDK Dynamic Proxy를 사용하고, 구현하지 않았다면 CGLIB 방식을 사용합니다\n[출처] [Spring AOP에 관하여 - 2] JDK Dynamic Proxy \u0026amp; CGLIB\nAspect란?\n도메인 로직에 필요한 다양한 부가기능을 추상화 시킨것.\n어노테이션 기반으로 AOP를 구현은 런타임이 아닌 Compile 시점에 Aspect를 적용하는 것이다.\n@Aspect @Component public class TestAspect { private static final Logger logger = LoggerFactory.getLogger(TestAspect.class); @Before(\u0026#34;execution(* com.example.aop_example.service.*.test(..))\u0026#34;) public void onBeforeHandler(JoinPoint joinPoint) { logger.info(\u0026#34;=============== onBeforeThing\u0026#34;); } @After(\u0026#34;execution(* com.example.aop_example.service.*.test(..))\u0026#34;) public void onAfterHandler(JoinPoint joinPoint) { logger.info(\u0026#34;=============== onAfterHandler\u0026#34;); } @AfterReturning(pointcut = \u0026#34;execution(* com.example.aop_example.service.*.test(..))\u0026#34;, returning = \u0026#34;str\u0026#34;) public void onAfterReturningHandler(JoinPoint joinPoint, Object str) { logger.info(\u0026#34;@AfterReturning : \u0026#34; + str); logger.info(\u0026#34;=============== onAfterReturningHandler\u0026#34;); } @Pointcut(\u0026#34;execution(* com.example.aop_example.service.*.test(..))\u0026#34;) public void onPointcut(JoinPoint joinPoint) { logger.info(\u0026#34;=============== onPointcut\u0026#34;); } } "});index.add({'id':154,'href':'/posts/framework/springboot/spring_basic/','title':"Spring Basic",'content':"Anotation 어노테이셔 : 소스코드에 메타데이터를 표현하는것 Built-in Annotation @Override - 메소드 오버라이드 검증\n@Deprecated - 메소드를 사용하지 않도록 유도.\n@SuppressWarnings - 컴파일 경고를 무시하도록 함.\n@SafeVarargs - 제너릴 같은 가변인자 매개변수를 사용할 때 경고 무시 (자바 7 이상)\n@FunctionalInterface - 람다 함수등을 위한 인터페이스를 지정. 메소드가 두개 이상 되면 컴파일 오류 (자바 8 이상)\nMeta Annotations @Retention - 어노테이션 영향 범위 결정.\n@Documented - 어노테이션 정보 출력.\n@Target - 어노테이션 적용 위치 결정.\n@Inherited - 자식클래스 어노테이션 상속 여부 결정.\n@Repeatable - 반복적으로 어노테이션을 선언\n"});index.add({'id':155,'href':'/posts/home/','title':"Home",'content':" Home Toy-project  마이그레이션   Category  Linux  Shell   AWS BigData  Kafka  Kafka(카프카) Kafka(카프카) 실행 Kafka(카프카) 인텔리제이 빌드 디버깅환경 구성     hexo  명령어   Database  Mysql  SQL 튜닝     Spring  Security  JWT 토큰          "});index.add({'id':156,'href':'/posts/language/java/environment/','title':"Environment",'content':"Mac JDK 설치 및 환경변수 설정 Default 설치 위치는 /usr/libexec/java_home -V  로 확인 가능하다.\n"});index.add({'id':157,'href':'/posts/language/javascript/react/','title':"React",'content':"React Context React + Redux flow "});index.add({'id':158,'href':'/posts/language/shell/configuration_env_with_intellij/','title':"Configuration Env With Intellij",'content':"인텔리제이 쉘스크립트 개발환경 구성 Linux/Mac라면 굳이 쉘스크립트 작성을 위한 개발환경이 필요하지 않아도 되지만,\n제품 빌드 스크립트등을 작성 할 시, 각종 환경변수와 컨피그 파일 로드를 포함하여 복잡한 스크립트를 작성해야 할 수도 있다.\n이 때, 조금이라도 더 편하게 스크립트를 작성 할 수 있을 것 같다\u0026hellip;ㅎㅎ\nEmpty project 생성 단지 쉘스크립트를 위한 환경이니 빈프로젝트를 생성. 개인 취향에 맡게 개발 환경을 만들자. 나는 아래와 같은 폴더구조를 만들었다.\n테스트 프로그램 실행. 아래의 코드를 실행해보자 .\n인텔리제이에서는 아래에서 보이듯이 여러가지 언어 또는 프레임워크를 지원한다. 쉘스크립트 실행 환경을 선택하자.\n그리고 실행할 script path를 입력하고\n아래와 같이 인터프리터를 설정하면 실행 준비 끝.\n일단 기본 Bash쉘로 설정하였다.\nMac 기준 Ctrl + R 로 그때그때 실행하며 편하게 개발시작.\n"});index.add({'id':159,'href':'/posts/language/shell/shellscript/','title':"Shellscript",'content':"쉘스크립트 문법 정리  쉘스크립트 첫라인 #!/bin/bash 의미?\n  스크립트파일을 bash로 실행시킨다는 의미\n  기재하지 않으면 리눅스 배포판의 경우 디폴트가 bash이므로 무리 없이 작동하지만 다른 쉘간의 오류를 방지를 위함.\n   기본 문법  echo, printf $# : 스크립트에 전달되는 인자들의 수(C언어에서 argc) $0 : 실행하는 스크립트의 파일명으로 실행했을 때 경로를 포함한다면 경로를 포함해서 나옵니다. $1, $2 … : 스크립트로 전달된 인자들(C언어에서 argv[0], argv[1]…)  echo \u0026#34;Echo Test\u0026#34; printf \u0026#34;printf Test\\n\u0026#34; printf \u0026#34;Name of script : %s\\n\u0026#34; $0 printf \u0026#34;%d arguments %s %s\\n\u0026#34; $# $1 $2 exit exit 100 # 스크립트 종료후 echo $? 로 확인. # 관습적으로 'exit 0'은 성공을 의미합니다. # 0이 아닌 값은 에러나 예외상황을 나타냅니다. $?는 스크립트에서 실행시키 명령어의 결과를 확인하는데 특별히 유용\n특수문자 # : 주석\n# 주석 뒤에는 명령어가 올수 없다. \\# 이스케이프된 #은 주석을 나타내지 않는다. ; : 명령어 구분자, 두개 이상의 명령어를 한 줄에서 같이 사용할 수 있다.\n부분쿼우팅[이중쿼우트] \u0026ldquo;content\u0026rdquo; 문자열 대부분 특수문자 해석을 막는다.\n완전쿼우팅[단일쿼우트] \u0026lsquo;content\u0026rsquo; 문자열에 들어 있는 모든 특수 문자를 해석하지 못하도록 막아줍니다\n명령어치환[백틱(backticks)] ``명령어` 라고 하면 명령어의 결과를 변수값으로 설정할 수있다.\n"});index.add({'id':160,'href':'/posts/menu/','title':"Menu",'content':" Home Toy-project  마이그레이션   Category  Linux  Shell 스크립트 개발환경 만들기   AWS  Exam  FAQ Part1 Part2 Part3 Part4 Part5 Summary 용어     BigData  Kafka  Kafka(카프카) Kafka(카프카) 실행 Kafka(카프카) 인텔리제이 빌드 디버깅환경 구성     hexo  명령어   Database  Mysql  SQL 튜닝     Spring  AOP  개념 및 원리   Security  JWT 토큰          "});index.add({'id':161,'href':'/posts/seminar/agile/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%A6%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%83%E1%85%B3-%E1%84%8B%E1%85%A2%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF-%E1%84%91%E1%85%B3%E1%84%85%E1%85%A6%E1%84%8B%E1%85%B5%E1%86%B7%E1%84%8B%E1%85%AF%E1%84%8F%E1%85%B3/','title':"스케일드 애자일 프레임워크",'content':"PI "});index.add({'id':162,'href':'/posts/seminar/google/gcp_seminar/','title':"G C P S E M I N a R",'content':"Google Cloud seminar Google vs AWS\n 가격모델  더 합리적인듯 (할인(?)) 자체 머신러닝으로 사용 리소스 분석 -\u0026gt; 합리적인 스팩 추천   커스텀 머신 타입  GPU 등등   네트워크  A사의 경우 전통적인 모델 Each Region vpn set 하나의 VPC로 관리 -\u0026gt; 모든 리전 접근 가능    데이터베이스  Nosql , cansandra  bigtable : 분산저장처리 시작된 이유 -\u0026gt; 논문 한번 보자.\n보안  Forrester  "});index.add({'id':163,'href':'/posts/tools/vscode/shortcut/','title':"Shortcut",'content':""});})();